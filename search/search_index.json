{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Archive","text":"<p>This is my digital garden where I archive everything I learn during my time in NUS. Files are organized by semesters:</p> <p>Year 1 Semester 2 <p></p>"},{"location":"#before-you-adventure","title":"Before you adventure","text":"<p>Please note that this website was generated by converting Obsidian markdown files into\u00a0Obsidian-MkDocs style, which means that some styles may not be accurate or visually consistent; for any files that are not viewable on the website (e.g <code>.java</code>), please feel free to check out my\u00a0Github page and post problems/improvements.</p> <p>Notice</p> <p>Due to GitHub's file size limit, it is not possible to upload every files. I am currently working on migrating the site to a dedicated server.</p>"},{"location":"#if-you-are-interested","title":"If you are interested","text":"<p>Notes file structure</p> <p>I organize my notes by creating a dedicated folder for each module, ensuring a streamlined and easily navigable structure. Within each module folder, I establish a main page that contains essential module information and is divided into two primary sections: Resources and My Notes. The Resources section compiles all the relevant reference materials, while the My Notes section houses my personal insights and summaries. When crafting my notes, I begin with a call-out section with a link to the resources used, ensuring traceability and ease of access. My approach to note-taking emphasizes long-term utility, as I strive to create comprehensive guides that remain understandable and useful even after an extended period of time.</p> <p>Mortimer J. Adler</p> <p>The purpose of learning is growth, and our minds, unlike our bodies, can continue growing as we continue to live.</p> <p>iyioon </p>"},{"location":"Year%201%20Semester%202/Year%201%20Semester%202/","title":"Year 1 Semester 2","text":"Code Module CS2040S Data Structures and Algorithms MA2001 Linear Algebra I CFG1002 Career Catalyst DTK1234 Design Thinking GEC1036 Radiation-Scientific Understanding and Public Perception CS2100 Computer Organisation"},{"location":"Year%201%20Semester%202/CFG1002/CFG1002/","title":"CFG1002","text":"<p>NUS MODS NUS IAAS NUS ConnectUS Canvas Website Vmock</p> <p>Career Catalyst will establish an important first touch point as part of a three/four-year roadmap to engage and prepare students in creating multiple pathways for themselves. Students will be equipped with essential skills and knowledge to make informed decisions on specialisations, develop soft skills as well as gain overseas exposure and real-world industry experience. This module consists of four lectures and two e-seminars spread across the first six weeks of the freshmen academic year, aimed to provide an early introduction to the concepts of career planning, personal branding and industry awareness. Students will learn to develop a strategy to maximise their time and resources while in University, be confident in mapping out a career plan and work towards strengthening their fit to achieve their career aspirations.</p> <p>Workload -\u00a05\u00a0hrs</p>"},{"location":"Year%201%20Semester%202/CFG1002/CFG1002/#about-the-course","title":"About the course","text":"<p>Descriptions Assessment Instructions</p>"},{"location":"Year%201%20Semester%202/CFG1002/Notes/Assessment%20Instructions/","title":"Assessment Instructions","text":"<p>All assessment components for this CS/CU graded course must be completed and submitted for review by the instructors by the end of Week 6 (final week) of the course. If you miss the stated deadline for any assessment component, no late submissions will be allowed and you will score 0 marks for that component.</p>"},{"location":"Year%201%20Semester%202/CFG1002/Notes/Assessment%20Instructions/#grading-components","title":"Grading Components:","text":"Assessment Task Weightage Completion of quizzes on Canvas (20 questions in total) 20% Creation of Account on NUS ConnectUS (https://connectus.nus.edu.sg/) 10% Creation of Account on NUS IAAS (Internship-As-A-Service) (https://iaas.nus.edu.sg/) 10% Uploading of Elevator Pitch on VMock (www.vmock.com/nus\u00a0Links to an external site.) 20% Uploading of Resume on VMock (www.vmock.com/nus\u00a0Links to an external site.) 40% Total Module Score 100%"},{"location":"Year%201%20Semester%202/CFG1002/Notes/Assessment%20Instructions/#passing-criteria-for-cfg1002","title":"Passing Criteria for CFG1002:","text":"<p>To obtain a CS grade in this course, you must satisfy\u00a0all\u00a0of the following requirements:</p> <ol> <li>Attend all face-to-face classes and complete all 5 assessment components.</li> <li>View all the contents on Canvas and obtain a minimum of 12/20 for quizzes after each session (one mark will be allocated to each correct answer for 20 questions).</li> <li>Attempt at least one recording of your elevator pitch upload on VMock Interview (video score is immaterial)</li> <li>Obtain a minimum of 60/100 for your resume upload on VMock Resume\u00a0</li> </ol> <p>One Deadline for all assessments: 17 Feb 2023 (Fri), 2359hrs</p>"},{"location":"Year%201%20Semester%202/CFG1002/Notes/Descriptions/","title":"Descriptions","text":""},{"location":"Year%201%20Semester%202/CFG1002/Notes/Descriptions/#about","title":"About","text":"<p>It consists of 2 face-to-face classes (Weeks 1 and 4) and online contents/videos to read through and watch. For these 6 weeks, you will be receiving email reminders from us with instructions on key milestones and the assessment deadline of\u00a017 Feb (Fri), 2359 hrs.</p> <p>This 2-MC unrestricted elective course aims to provide an early introduction to the concepts of career planning, personal branding and industry awareness. Through this course, you will be equipped with essential skills and knowledge to make informed decisions on career choices, develop soft skills, and plan for industry experience through internships. You will also learn to develop a strategy to maximize your time and resources while in University, be confident in mapping out a career plan, and work towards strengthening your fit to achieve your career aspirations.</p>"},{"location":"Year%201%20Semester%202/CFG1002/Notes/Descriptions/#course-objectives","title":"Course Objectives","text":"<ul> <li>Learn about tools and techniques to assess your own values, interests and skills, and how they relate to future career pathways</li> <li>Discover how to secure and excel at internships</li> <li>Build an employer-ready resume, cover letter and online\u00a0profile</li> <li>Learn how to respond to common interview questions</li> <li>Hear about hiring trends, interview skills, and workplace competencies from actual employers</li> </ul>"},{"location":"Year%201%20Semester%202/CS2040S/CS2040S/","title":"CS2040S Data Structures and Algorithms","text":"<p>NUS MODS Coursemology Archipelago</p> <p>This module introduces students to the design and implementation of fundamental data structures and algorithms. The module covers basic data structures (linked lists, stacks, queues, hash tables, binary heaps, trees, and graphs), searching and sorting algorithms, and basic analysis of algorithms.</p> <p>Prerequisite: CS1231</p>"},{"location":"Year%201%20Semester%202/CS2040S/CS2040S/#notes","title":"Notes","text":"Week Notes Summary Recitation Tutorial 1 CS2040_01.Introduction - - - 1 CS2040_02.Java-OOP 02.Algorithm Analysis - - 2 CS2040_03.Searching 03.Searching - - 2 CS2040_04.PeakFinding - - - 3 CS2040_05.SortingA 05.Sorting CS2040_Recitation+01CS2040_Rec01Solution CS2040S_tut01CS2040S_tut01solutionCS2040_tut1_soln 4 CS2040_06.SortingB - CS2040_Recitation+02CS2040_Rec02Solution CS2040S_tut02CS2040S_tut02solutionCS2040_tut2_soln 4 CS2040_07.SortingC.QuickSort - - - 5 CS2040_08.Trees 08.Trees CS2040_Recitation+03CS2040_R3 CS2040S_tut03CS2040S_tut3_soln 5 CS2040_09.BalancedTrees - - - 6 CS2040_10.MoreTrees - CS2040_Recitation+04CS2040_R4 CS2040S_tut4CS2040S_tut4_soln 6 CS2040_11.AugmentedTrees - - - 7 CS2040_12.TreesandHeaps 12.Heaps CS2040_Recitation+05CS2040_R5 CS2040S_tut5CS2040S_tut5_soln 7 CS2040_13.UnionFind 13.UnionFind - - 8 CS2040_14.Hashing1 14.Hashing CS2040_Recitation+06R6 CS2040S_tut06CS2040S_tut6_soln 9 CS2040_15.Hashing2 - CS2040_Recitation+07CS2040_R7 CS2040S_tut07CS2040S_tut7_soln 9 CS2040_16.Hashing3 - - - 10 CS2040_17.Hashing4GraphsIntro 17.Graphs - CS2040S_tut8CS2040S_tut8_soln 10 CS2040_18.Graphs2 - - - 11 CS2040_19.SSSP - CS2040_Recitation+08CS2040_R8 CS2040S_tut9CS2040S_tut9_soln 11 CS2040_20.SSSP+DAGs - - - 12 CS2040_21.MST 21.Minimum_Spanning_Tree CS2040_Recitation+09CS2040_R9 CS2040S_tut10Not given 12 CS2040_22.DynamicProgrammingIntro 22.Dynamic_Programming - - 13 CS2040_23.DynamicProgramming2 - - CS2040S_tut11CS2040S_tut11_soln 13 24.Conclusion - - -"},{"location":"Year%201%20Semester%202/CS2040S/CS2040S/#additional-resources","title":"Additional Resources","text":"<ul> <li>Past Lecture Video</li> <li>cs2040sSummary </li> <li>Textbook: Algorithms, Robert Sedgewick and kevin Wayne</li> <li>Textbook: Introduction to Programming in Java, Robert Sedgewick and kevin Wayne</li> <li>Algorithm visuals: Visualgo</li> </ul>"},{"location":"Year%201%20Semester%202/CS2040S/CS2040S/#mid-term-past-papers","title":"Mid term past papers","text":"Past paper Answer CS2040_midterm_2021_questions CS2040_2021 ans CS2040_midterm_2022_questions CS2040_2022 ans"},{"location":"Year%201%20Semester%202/CS2040S/CS2040S/#final-past-papers","title":"Final past papers","text":"Past paper Answer CS2040S_2020-21-S1_Final CS2040S_2020-21-S1_Final_sample_ans CS2040S_2019_20_S1_Final CS2040S_2019_20_S1_Final_sample_ans CS2040S_2017_18_S1_WQ2 CS2040S_2017_18_S1_WQ2_sample_ans CS2040S_2017_18_S1_WQ1 CS2040S_2017_18_S1_WQ1_sample_ans CS2040S_2015-16-S1-WQ2 - CS2040S_2015-16-S1-WQ1 CS2040S_2015-16-S1-WQ1-sample_ans CS2040S_2014-15-S1-WQ1 - CS2040S_2013-14-S1-Final - CS2040S_2013-14-S1-WQ2 - CS2040S_2012-13-S1-WQ2 - CS2040S_2012-13-S1-WQ1 - CS2040S_2011-12-S1-Final - CS2040S_2011-12-S1-WQ2 -"},{"location":"Year%201%20Semester%202/CS2040S/CS2040S/#additional-practice","title":"Additional Practice","text":"Practice Solution CS2040_TF_Practice_1 CS2040_TF_Practice_1_Solutions CS2040_TF_Practice_2 CS2040_TF_Practice_2_Solutions CS2040_TF_Practice_3 CS2040_TF_Practice_3_Solutions"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/02.Algorithm%20Analysis/","title":"Algorithm Analysis","text":"Resources <p>CS2040_03.Searching - Video</p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/02.Algorithm%20Analysis/#motivation","title":"Motivation","text":"<p>In theoretical analysis of algorithms, it is common to estimate their complexity in the asymptotic sense, i.e., to estimate the complexity function for arbitrarily large input.</p> <p>Analysis of algorithm is the process of analyzing the problem-solving capability of the algorithm in terms of the time and size required (the size of memory for storage while implementation). However, the main concern of analysis of algorithms is the required time or performance. Generally, we perform the following types of analysis </p> <ul> <li>Worst-case\u00a0\u2212 The maximum number of steps taken on any instance of size\u00a0a.</li> <li>Best-case\u00a0\u2212 The minimum number of steps taken on any instance of size\u00a0a.</li> <li>Average case\u00a0\u2212 An average number of steps taken on any instance of size\u00a0a.</li> </ul>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/02.Algorithm%20Analysis/#notations","title":"Notations","text":"Big Oh\u00a0(O) Big Omega\u00a0(\u03a9) Big Theta\u00a0(\u0398) Rate of growth of an algorithm is less than or equal to a specific value. Rate of growth is greater than or equal to a specified value. Rate of growth is equal to a specified value. Upper Bound Lower Bound Tight Bound \\(T(\\mathrm{n})=\\mathrm{O}(f(n))\\) if \\(T\\) grows no faster than \\(f\\) \\(T(n)=\\Omega(f(n))\\) if \\(T\\) grows no slower than \\(\\mathrm{f}\\) \\(T(n)=\\Theta(f(n))\\) if \\(T\\) grows at the same rate as \\(\\mathrm{f}\\) \\(T(n) \\leq c f(n)\\) \\(T(n) \\geq c f(n)\\) \\(T(n)=\\mathrm{O}(f(n)) \\text { and }\\) \\(T(n)=\\Omega(f(n))\\)"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/02.Algorithm%20Analysis/#general-rules","title":"General Rules","text":"Notation Example If \\(T(n)\\) is a polynomial of degree \\(k\\) then:\\(T(n)=\\mathrm{O}\\left(n^k\\right)\\) \\(10 n^5+50 n^3+10 n+17=\\mathrm{O}\\left(n^5\\right)\\) \\(T(n)+S(n)=O(f(n)+g(n))\\) \\(10 n^2=\\mathrm{O}\\left(n^2\\right)\\)\\(5 n \\log (n)=\\mathrm{O}(n \\log (n))\\)\\(10 n^2+5 n \\log (n)=\\mathrm{O}\\left(n^2+n \\log (n)\\right)=\\mathrm{O}\\left(n^2\\right)\\) \\(T(n) \\times S(n)=\\mathrm{O}\\left(f(n) \\times g(n)\\right)\\) \\(10 n^2=\\mathrm{O}\\left(n^2\\right)\\)\\(5 n=\\mathrm{O}(n)\\)\\(\\left(10 n^2\\right)(5 n)=50 n^3=\\mathrm{O}\\left(n^* n^2\\right)=\\mathrm{O}\\left(n^3\\right)\\) <p>Difficult Example: \\(\\log (n !)= O(n \\log n)\\)</p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/02.Algorithm%20Analysis/#algorithm-analysis_1","title":"Algorithm Analysis","text":"Model of computation <p>In computer science, and more specifically in computability theory and computational complexity theory, a model of computation is a model which describes how an output of a mathematical function is computed given an input. A model describes how units of computations, memories, and communications are organized.</p> <p>In this course, we will be focusing on Sequential Computer where all operations and executed one at a time, taking a constant time.</p> <p>Here are the general rules for analyzing the time complexity of a given code:</p> <ul> <li>Loops: <code>cost = (# iterations)x(max cost of one iteration)</code></li> <li>Nested Loops: <code>cost = (# iterations)(max cost of one iteration)</code></li> <li>Sequential statements: <code>cost = (cost of first) + (cost of second)</code></li> <li>if / else statements: <code>cost = max(cost of first, cost of second)</code> or in general just add the two: <code>(cost of first) + (cost of second)</code></li> </ul>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/02.Algorithm%20Analysis/#recurrences","title":"Recurrences","text":"<p>For recursive cals, it is best to understand how to calculate the time complexity with examples:</p> <p>$$ T(n) = 1+T((n-1)+T(n-2)) $$ <pre><code>int fib(int n) {\nif(n &lt;= 1)\nreturn n;\nelse\nreturn fib(n-1) + fib(n-2); // T(n-1) + T(n-1)\n}\n</code></pre></p> <p>We will not be going to the mathematics of calculating such formulas, but it is best to calculate such equations using a tree. Refer to CS2040_tut01 for asymptotic analysis questions.</p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/02.Algorithm%20Analysis/#precondition-and-postcondition","title":"Precondition and Postcondition","text":"<p>Precondition:</p> <ul> <li>Fact that is true when the function begins.</li> <li>Usually important for it to work correctly.</li> </ul> <p>Postcondition:</p> <ul> <li>Fact that is true when the function ends.</li> <li>Usually useful to show that the computation was done correctly.</li> </ul>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/02.Algorithm%20Analysis/#invariants","title":"Invariants","text":"<p>Invariant:</p> <ul> <li>relationship between variables that is always true.</li> </ul> <p>Loop Invariant:</p> <ul> <li>relationship between variables that is true at the beginning (or end) of each iteration of a loop.</li> </ul>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/03.Searching/","title":"Searching","text":"Resources <p>CS2040_03.Searching </p> <p>Video Binary Search, Video Peak Finding</p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/03.Searching/#binary-search","title":"Binary Search","text":"<p>Binary search is\u00a0an efficient algorithm for finding an item from a sorted list of items. It works by repeatedly dividing in half the portion of the list that could contain the item, until you've narrowed down the possible locations to just one.</p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/03.Searching/#using-recursion","title":"Using recursion","text":"<pre><code>public static int binarySearch(int[] array, int target, int low, int high) {\nif (low &gt; high) {\nreturn -1;\n}\nint mid = (low + high) / 2;\nif (array[mid] == target) {\nreturn mid;\n}\nif (array[mid] &gt; target) {\nreturn binarySearch(array, target, low, mid - 1);\n} else {\nreturn binarySearch(array, target, mid + 1, high);\n}\n}\n</code></pre>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/03.Searching/#using-iterative-method","title":"Using iterative method","text":"<pre><code>public static int binarySearch(int[] array, int target) {\nint low = 0;\nint high = array.length - 1;\nwhile (low &lt;= high) {\nint mid = (low + high) / 2;\nif (array[mid] == target) {\nreturn mid;\n} else if (array[mid] &lt; target) {\nlow = mid + 1;\n} else {\nhigh = mid - 1;\n}\n}\nreturn -1;\n}\n</code></pre>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/03.Searching/#peak-finding","title":"Peak finding","text":"<p>Problem: Given a function \\(f(x)\\) we want to find the maximum value of the function. </p> <p>A modified version of binary search can be used to solve this problem:</p> <pre><code>FindPeak(A,n)\nif A[n/2 + 1] &gt; A[n/2] then\nFindPeak (A[n/2 + 1 . . n], n/2)\nelse if A[n/2 - 1] &gt; A[n/2] then\nFindPeak (A[1 . . n/2 - 1], n/2)\nelse A[n/2] is a peak; return n/2\n</code></pre> <p>Key Invariants</p> <ol> <li>There exists a peak in the range <code>[begin,end]</code></li> <li>Every peak in <code>[begin,end]</code> is a peak in <code>[1,n]</code></li> </ol>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/05.Sorting/","title":"Sorting","text":""},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/05.Sorting/#bubble-sort","title":"Bubble Sort","text":"<pre><code>BubbleSort(A, n)\nrepeat (until no swaps): for j = 1 to n-1\nif A[j] &gt; A[j+1] then swap(A[j], A[j+1])\n</code></pre> <p>Best: \\(O(n)\\) Average &amp; Worst: \\(O(n^2)\\) Stable</p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/05.Sorting/#selection-sort","title":"Selection Sort","text":"<pre><code>SelectionSort(A, n)\nfor j = 1 to n-1:  find minimum element A[j] in A[j..n] swap(A[j], A[k])\n</code></pre> <p>Best &amp; Worst &amp; Average: \\(O(n^2)\\) Not stable</p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/05.Sorting/#insertion-sort","title":"Insertion Sort","text":"<pre><code>InsertionSort(A, n)\nfor j = 2 to n key = A[j]\ni = j-1  while (i &gt; 0) and (A[i] &gt; key)\nA[i+1] = A[i]\ni = i-1 A[i+1] = key\n</code></pre> <p>Best: \\(O(n)\\) Worst &amp; Average: \\(O(n^2)\\) Stable</p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/05.Sorting/#merge-sort","title":"Merge Sort","text":"<p>Best &amp; Worst, Average: \\(O(n\\log n)\\) Stable</p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/05.Sorting/#quick-sort","title":"Quick Sort","text":"<p>Best, Average: \\(O(n\\log n)\\) Worst: \\(O(n^2)\\) Not stable</p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/08.Trees/","title":"Trees","text":"Resources <p>CS2040_08.Trees</p> <p>CS2040_09.BalancedTrees</p> <p>CS2040_10.MoreTrees</p> <p>CS2040_11.AugmentedTrees</p> <p>CS2040_12.TreesandHeaps</p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/08.Trees/#binary-search-trees","title":"Binary Search Trees","text":"<p>The binary search tree property states that all keys in the left sub-tree are less than the parent key, and all keys in the right subtree are greater than the parent key.</p> <p>The height of a BST is the number of edges on the longest path from the root to the leaf:</p> <p>The minimum and maximum keys are found by traversing the left and right subtrees respectively.</p> <p>Inserting is akin to searching, but instead adding a new node at a leaf.</p> <p>Deleting is trivial if if the node to be deleted has one or no children. Otherwise, the node to be deleted is replaced by the minimum of the right subtree (its successor).</p> <p>All these operations are O(h). If balanced this will be \\(O(\\log n)\\).</p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/08.Trees/#traversal","title":"Traversal","text":"<p>In-order: Visit left subtree \\(\\to\\) self \\(\\to\\) right subtree Pre-order: Visit self \\(\\to\\) left subtree \\(\\to\\) right subtree Post-order: Visit left subtree \\(\\to\\) right subtree \\(\\to\\) self</p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/08.Trees/#avl-tree","title":"AVL Tree","text":"<p>Augmented BST which stores the tree height  in each node. This augmented height must be updated with every insert and deleted.</p> <p>A binary search tree is balanced iff \\(h=O(\\log n)\\), such that all operations take \\(O(\\log n)\\) time.</p> <p>A node \\(v\\) is height-balanced iff \\(\\mid v\\). left. height - v.right. height \\(\\mid \\leq 1\\). A height-balanced tree with \\(n\\) nodes has height \\(h&lt;2 \\log n\\), and one with height \\(h\\) has at least \\(n&gt;2^{\\frac{h}{2}}\\) nodes.</p> <p>balancing: Perform in-order traversal on BST (\\(O(n)\\)) . Construct an AVL tree in \\(O(n)\\) time by picking the middle element as the root recursively do the same for sublists.</p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/08.Trees/#rotations","title":"Rotations","text":"<p>Case 1: \\(A\\) is left-heavy but \\(B\\) is balanced \\(\\rightarrow\\) right-rotate.</p> <p></p> <p>Case 2: \\(A\\) is left-heavy but \\(B\\) is left-heavy \\(\\rightarrow\\) right-rotate.</p> <p></p> <p>Case \\(3: A\\) is left-heavy but \\(B\\) is right-heavy \\(\\rightarrow\\) left-rotate \\(B\\) \\(\\to\\) right-rotate about \\(A\\).</p> <p></p> <p></p> <p>After an insert, at most 2 rotations are needed, but delete may require up to O(log n) rotations. This is because delete reduces height and rotations reduce height, so it is not sufficient to only fix the lowest imbalanced node in the tree.</p> <ul> <li>Delete key from BST.</li> <li>Walk up tree:</li> <li>At every step, check for balance.</li> <li>If out-of-balance, use rotations to rebalance.</li> <li>Continue to root.</li> </ul>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/08.Trees/#trie","title":"Trie","text":"<p>End of the word can be marked with a wildcards.</p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/12.Heaps/","title":"Heaps","text":"Resources <p>PDF</p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/12.Heaps/#basics","title":"Basics","text":"<p>A binary heap is a heap data structure that takes the form of a binary tree. Two properties holds for a binary heap:</p> <ol> <li>\\(\\text { priority[parent] &gt;= priority[child] }\\)</li> <li>Complete binary tree <ol> <li>Every level is full, except possibly the last</li> <li>All nodes are as far left as possible</li> </ol> </li> </ol> <p></p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/12.Heaps/#heap-operations","title":"Heap Operations","text":"<p>Insert: Adds the node to the end of the tree (as far left as possible). To put the node in the correct position, bubble up (swap with parent) if the node is greater than the parent. \\(O(\\log n)\\). Example.</p> <p>Increase key: Update the priority. Bubble up. \\(O(\\log n)\\).  Example.</p> <p>Decrease Key: Update the priority. Bubble down to the LEFT. \\(O(\\log n)\\).  Example.</p> <p>Delete: Swap the node with the last node. Bubble down the swapped node to the correct location.  \\(O(\\log n)\\). Example.</p> <p>Extract Max: Perform the Delete operation on the root. \\(O(\\log n)\\). Example.</p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/12.Heaps/#store-tree-in-an-array","title":"Store Tree in an Array","text":"<p>Binary heap can be implemented with an implicit data structure without pointers, using a heap array. Building  the array can be done in \\(O(n)\\) time. Visit PDF.</p> <p></p> <p>To access a children of node \\(i\\), we use index arithmetic: </p> <ul> <li>Left child index: \\(2i+1\\)</li> <li>Right child index: \\(2i+2\\)</li> </ul> <p>To access the parent: \\(\\frac{{i-1}}{2}\\).</p> <p>Building a Heap from a unsorted list: Start at the end of the array. For all items, perform a bubble down operation. Cost = \\(O(n)\\). Example.</p> <p>To obtain a sorted list from a heap array: Perform a extract max operation for \\(n\\) items. Cost: \\(O(n\\log n)\\). Example.</p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/12.Heaps/#summary","title":"Summary","text":"<ul> <li>\\(O(n \\log n)\\) time worst-case</li> <li>In-place: only need n space.</li> <li>Fast:<ul> <li>Faster than MergeSort</li> <li>A little slower than QuickSort.</li> </ul> </li> <li>Deterministic: always completes in \\(\\mathrm{O}(n \\log n)\\)</li> <li>Unstable (Come up with an example!)</li> <li>Ternary (3-way) HeapSort is a little faster.</li> </ul>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/13.UnionFind/","title":"UnionFind","text":"<p>Video</p> Algorithm Find Union quick-find \\(O(1)\\) \\(O(n)\\) quick-union \\(O(n)\\) \\(O(n)\\) weighted-union \\(O(\\log n)\\) \\(O(\\log n)\\) path compression \\(O(\\log n)\\) \\(O(\\log n)\\) weighted-union with path compression \\(\\alpha(m,n)\\) \\(\\alpha(m,n)\\) ## Dynamic Connectivity <p>Given a set of objects:</p> <ul> <li>Union: connect two objects</li> <li>Find: is there a path connecting the two objects?</li> </ul> <p>visit PDF</p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/13.UnionFind/#quick-find","title":"Quick Find","text":"<p>This is a data structure using an array where each elements stores the component identifier. Two objects are connected if they have the same component identifier. PDF. </p> <ul> <li><code>find(p, q)</code>: Checking if <code>p</code> and <code>q</code> share the same component id. \\(O(1)\\).</li> <li><code>union(p, q)</code> : If \\(I_{p}\\) and \\(I_{q}\\) is the parent of <code>p</code> and <code>q</code>, literate through objects with \\(I_{q}\\) and change and update the id to \\(I_{p}\\). PDF. \\(O(n)\\)</li> </ul>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/13.UnionFind/#quick-union","title":"Quick Union","text":"<p>Quick Union uses a a array where each elements stores the parent. Two objects are connected if they are part of the same tree. PDF.</p> <ul> <li><code>find(p, q)</code>: Walk up the parent of both <code>p</code> and <code>q</code>. Check if their final parent are equal.  \\(O(n)\\).</li> <li><code>union(p, q)</code> : Walk up the parent of both <code>p</code> and <code>q</code>. If \\(P_{p},P_{q}\\) are the final parent of <code>p</code> and <code>q</code>, update the parent of \\(P_{p}\\) to \\(P_{q}\\) . \\(O(n)\\).</li> </ul>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/13.UnionFind/#weighted-union","title":"Weighted Union","text":"<p>Weighted Union is a augmented version quick union where each object stores its size (weight inclusive). PDF. Union links smaller tree to the larger one. Resulting in maximum depth: \\(O(\\log n)\\). Explanation PDF</p> <ul> <li><code>find(p, q)</code>: Walk up the parent of both <code>p</code> and <code>q</code>. Check if their final parent are equal.  \\(O(\\log n)\\) because the height is at most \\(\\log n\\).</li> <li><code>union(p, q)</code> : Walk up the parent of both <code>p</code> and <code>q</code>. Link the smaller set to the larger set. PDF. \\(O(\\log n)\\) .</li> </ul>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/13.UnionFind/#path-compression","title":"Path Compression","text":"<p>The final optimization adds path compression. After each time the root is found, every node on the path is linked to the root. Both union and find take \\(O(\\alpha(m,n))\\) amortized time each for \\(m\\) operations, and \\(\\log(n)\\) in the worst case.. Visit PDF</p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/14.Hashing/","title":"Hashing","text":"Resources. <p>Video Part 1 PDF</p> <p>Video Part 2 PDF</p> <p>Video Part 3 PDF</p> <p>Video Part 4PDF</p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/14.Hashing/#introduction","title":"Introduction","text":"<p>Hashing implements a abstract datatype called a Symbol Table.</p> <pre><code>public interface SymbolTable\nvoid insert(Key k, Value v) //insert(k,v) into table\nValue search(Key k)         //get balue paired with k\nvoid delete(Key k)          //remove key k (and value)\nboolean contains(Key k)     // is there a value for k?\nint size()                  //number of (k,v) pairs\n</code></pre> <p>These are symbol table used throughout computer science. PDF</p> <ul> <li>Dictionary</li> <li>Phone Book</li> <li>Internet DNS</li> <li>Java compiler</li> </ul> <p>Suppose you implement a symbol table with an AVL tree. </p> <ul> <li>Cost of insertion \\(C_{I}=O(\\log n)\\) </li> <li>Cost of search \\(C_{s}=O(\\log n)\\)</li> </ul> <p>The objective is to implement a symbol table with a constant cost.</p> <ul> <li>\\(C_{I}=O(1)\\) </li> <li>\\(C_{s}=O(1)\\)</li> </ul> <p>However, this means that the sorting cost takes \\(O(n^2)\\) unlike an AVL tree that takes \\(O(n\\log n)\\). Symbol table is not comparison based.</p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/14.Hashing/#direct-access-tables","title":"Direct Access Tables","text":"<p>One of the most obvious method of constructing such data structure is through Direct Access Table.</p> <p>Example: (2, item1), (8, item2), (5, item3)</p> <p></p> <p>Assume keys are distinct.</p> <p>Problem:</p> <ul> <li>Keys are integers</li> </ul> <p>This cannot be solved by treating everything as a sequence of bits as the size of the array will become too large. For example, to store english words:</p> <ul> <li>26 letters -&gt; 5 bits/letter</li> <li>Longest word = 34 letters</li> <li>34 * 5 bits = 170 bits</li> <li>Size of the array required to store all english words  = \\(2^{170}\\) \\(\\approx\\) number of atoms in observable universe</li> </ul> <p>This is why Hash Tables are used.</p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/14.Hashing/#hash-functions","title":"Hash Functions","text":"<p>Objective: Given \\(U\\) possible keys (eg \\(2^{170}\\) ) and \\(n\\) number of actual keys, map \\(n\\) keys to \\(m \\approx n\\)buckets.</p> <p></p> <p>Define hash function \\(\\mathrm{h}: \\mathrm{U} \\rightarrow\\{1 . . m\\}\\)</p> <ul> <li>Store key \\(k\\) in bucket \\(\\mathrm{h}(k)\\)</li> <li>Time complexity:<ul> <li>Time to compute \\(\\mathrm{h}\\) + Time to access bucket (time to access the location in memory)</li> </ul> </li> <li>Usually: assume hash function has cost 1 to compute.</li> </ul>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/14.Hashing/#collisions","title":"Collisions","text":"<p>We say that two distinct keys \\(k_1\\) and \\(k_2\\) collide if: $$ \\mathrm{h}\\left(k_1\\right)=\\mathrm{h}\\left(k_2\\right) $$</p> <p>Collision is unavoidable when using a hash function:</p> <ul> <li>The table size is smaller than the universe size</li> <li>The pigeonhole principle says:<ul> <li>There must exist two keys that map to the same bucket</li> <li>Some keys must collide!</li> </ul> </li> </ul>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/14.Hashing/#coping-with-collision","title":"Coping with Collision","text":"<p>Idea: choose a new, better hash functions</p> <ul> <li>Hard to find.</li> <li>Requires re-copying the table.</li> <li>Eventually, there will be another collision.</li> </ul> <p>Idea: Chaining </p> <ul> <li>Put both items in the same bucket!</li> </ul> <p>Idea: open addressing</p> <ul> <li>Find another bucket for the new item.</li> </ul>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/14.Hashing/#chaining","title":"Chaining","text":"<p>Each bucket contains a linked list of items:</p> <p></p> <p>Total space: \\(O(m+n)\\) where \\(m\\) is the number of slots in the hash table and \\(n\\) is the number of keys inserted.</p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/14.Hashing/#operations","title":"Operations","text":"<p><code>insert(key,value)</code></p> <ul> <li>Calculate <code>h(key)</code></li> <li>Lookup <code>h(key)</code> and add <code>(key,value)</code> to the linked list.</li> <li>worst-case cost: \\(O(1+\\operatorname{cost}(\\mathrm{h}))\\) where \\(\\operatorname{cost}(\\mathrm{h})\\) is the cost of computing the hash function. Note that the element is added to the head of the linked list.</li> </ul> <p><code>search(key)</code></p> <ul> <li>Calculate <code>h(key)</code></li> <li>Search for <code>(key,value)</code> in the linked list </li> <li>Expected search time: \\(O\\left( 1+\\frac{n}{m} \\right)=O(1)\\).  Calculation</li> <li>worst-case cost: \\(O(n+\\operatorname{cost}(\\mathrm{h}))\\). When all the keys are in the same bucked in the linked list.</li> </ul> <p><code>Delete(key)</code></p> <ol> <li>Calculate hash of key.</li> <li>Let L be the linked list in the specified bucket.</li> <li>Search for item in linked list L.</li> <li>Delete item from linked list L.</li> <li>Cost = \\(O\\left( 1+\\frac{n}{m} \\right)\\)</li> </ol>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/14.Hashing/#analysis-of-chaining","title":"Analysis of chaining","text":"<p>Visit CS2040_14.1 Analysis of chaining</p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/14.Hashing/#java-hashing","title":"Java hashing","text":"<p>How do we implement Hashing in Java? Java provides a interface:</p> <p><code>java.util.Map&lt;Key,Value&gt;</code> (Refer to java documentation)</p> <ul> <li>No duplicate keys are allowed</li> <li>No mutable keys<ul> <li>If you use an object as a key, then you can't modify that object later</li> </ul> </li> </ul> <p>Note that <code>Map</code> is a interface. Hence it cannot be instantiated. Instead, <code>HashMap</code> can be used.</p> <pre><code>Map&lt;String,Integer&gt; ageMap = new HashMap&lt;String,Integer&gt;();\n</code></pre>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/14.Hashing/#how-is-hash-value-calculated-from-the-key","title":"How is hash value calculated from the key?","text":"<p>Java Object supports the method <code>int hashCode()</code>. The integer returned by this method is used by Java to calculate the hash value (<code>hash = hashcode % buckets.length</code>). Hence, the subclass must modify the <code>hashCode()</code> method to obey the following rules:</p> <ul> <li>Always returns the same value, if the object hasn't changed</li> <li>If two objects are equal, then they return the same hashCode (Other way around is recommended)</li> </ul> <p>Overriding the <code>hashCode()</code> method is necessary as default java implementation <code>hashCode</code> returns the memory location of the object, hence every object hashes to a different location.</p> <p>Furthermore, you must override <code>.equals</code> to be consistent with hashCode. This is because the <code>get</code> method in HashMap returns the value from the key only if <code>key.equals(k)</code> where k is the object found in the HashMap. Refer to PDF</p> <p>Visit PDF for how Java Library Classes calculates hashCode.</p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/14.Hashing/#designing-hash-functions","title":"Designing Hash Functions","text":"<p>Goal: find a hash function whose values look random. There are two techniques</p> <ul> <li>Division Method</li> <li>Multiplication Method</li> </ul>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/14.Hashing/#division-method","title":"Division Method","text":"<p>The hash value is calculated by \\(\\mathrm{h}(k)=k \\bmod m\\)</p> <p>To minimize the collision:</p> <ul> <li>Choose prime number</li> <li>Not too close to a power of 2</li> <li>Not too close to a power of 10</li> </ul> <p>Advantage: Easy Disadvantage: Not always the most effective, Division is slow</p> <p>Visit PDF for bad \\(m\\) values. </p> <p>If all keys and \\(m\\) is divisible by \\(d\\), then the value returned by the hash function will always be divisible by \\(d\\). Hence only the slots divisible by \\(d\\) will be occupied ie every 1 out of \\(d\\) slots will be filled.</p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/14.Hashing/#multiplication-method","title":"Multiplication Method","text":"<ul> <li>Fix table size: \\(m=2^r\\), for some constant \\(r\\).</li> <li>Fix word size: \\(w\\), size of a key in bits.</li> <li>Fix (odd) constant A. $$ h(k)=(A k) \\bmod 2^w \\gg(w-r) $$</li> </ul> <p>Visit PDF for explanation</p> <p>Advantage: </p> <ul> <li>Faster than Division method. <ul> <li>Multiplication, shifting faster than division</li> </ul> </li> <li>Works reasonably well when A is an odd integer \\(&gt;2^{w-1}\\)<ul> <li>Odd: if it is even, then lose at least one bit's worth</li> <li>Big enough: use all the bits in A.</li> </ul> </li> </ul>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/14.Hashing/#table-resizing","title":"Table Resizing","text":"<p>CS2040_16.Hashing3</p> <p>We showed that the expected search time: \\(\\mathrm{O}(1+n / m)\\) and the optimal size: \\(m=\\Theta(n)\\)</p> <ul> <li>if \\((\\mathrm{m}&lt;2 \\mathrm{n})\\) : too many collisions.</li> <li>if \\((\\mathrm{m}&gt;10 \\mathrm{n})\\) : too much wasted space.</li> </ul> <p>In general we don't know \\(n\\) in advance. Hence we grow and shrink the table as necessary:</p> <ol> <li>Choose new table size \\(m\\)</li> <li>Choose new hash function \\(h\\)<ol> <li>Hash function depends on table size!</li> <li>Remember: \\(h: \\mathrm{U} \\rightarrow\\{1 . . m\\}\\)</li> </ol> </li> <li>For each item in the old hash table<ol> <li>Compute new hash function</li> <li>Copy item to new bucket</li> </ol> </li> </ol>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/14.Hashing/#growing-the-table","title":"Growing the table","text":"<ul> <li>Let \\(m_1\\) be the size of the old hash table.</li> <li>Let \\(m_2\\) be the size of the new hash table.</li> <li>Let \\(n\\) be the number of elements in the hash table.</li> </ul> <p>Then the cost:</p> <ul> <li>Scanning old hash table: \\(\\mathrm{O}\\left(m_1\\right)\\)</li> <li>Creating new hash table: \\(\\mathrm{O}\\left(m_2\\right)\\)</li> <li>Inserting each element in new hash table: \\(\\mathrm{O}(1)\\)</li> <li>Total: \\(\\mathrm{O}\\left(m_1+m_2+n\\right)\\)</li> </ul> <p>What is the cost of inserting \\(n\\) items by incrementing \\(m\\) by 1? \\(O(n^2)\\) PDF</p> <p>This is to large. Hence we double the table size instead given us \\(O(n)\\) PDF</p> <ul> <li>Most insertions: \\(\\mathrm{O}(1)\\)</li> <li>Some insertions: linear cost (expensive)</li> <li>Average cost: \\(\\mathrm{O}(1)\\)</li> </ul> <p>How about squaring table size. Visit PDF</p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/14.Hashing/#shrinking-the-table","title":"Shrinking the table","text":"<p>Occurs during deletion of many items. </p> <ul> <li>If (n == m), then m = 2m.</li> <li> <p>If (n &lt; m/4), then m = m/2.</p> </li> <li> <p>After every change: the table is half full, half empty.</p> </li> <li>Every time you double a table of size m, at least m/2 new items were added since last change.</li> <li>Every time you shrink a table of size m, at least m/4 items were deleted since last change.</li> </ul>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/14.Hashing/#summary","title":"Summary","text":"<ul> <li>When table is full, double the size.</li> <li>When table is 3\u20444 empty, half the size.</li> <li>Most operations areO(1).</li> <li>Some operations costO(n).</li> <li>On average, operations costO(1).</li> </ul>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/14.Hashing/#sets","title":"Sets","text":"<p>Goal is to store a collection of keys. Abstract Data Type. This interface can be implemented with a hash table. Example. </p> <p>Disadvantage: Too much space (buckets)</p> <p>Solution: Use a fingerprint - only store/send \\(m\\) bits. Example. </p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/14.Hashing/#fingerprint-hash-table","title":"Fingerprint Hash Table","text":"<p>If there are Collisions, it may sometimes report true. False Positive.</p> <p>Spam example: it is better to store in the Fingerprint Hash Table:</p> <ol> <li>The set of good e-mail addresses.</li> <li>The set of bad e-mail addresses</li> <li>It does not matter.</li> </ol> <p>It may be better to mistakenly accept a few SPAM e-mails than to accidentally reject an e-mail from my mother!</p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/14.Hashing/#bloom-filter","title":"Bloom Filter","text":"<p>Bloom Filter is used to solve the problem above by using two hash functions.</p> <p></p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/14.Hashing/#open-addressing","title":"Open Addressing","text":"<p>On collision Probe a sequence of buckets until you find an empty one.  Unlike chaining, we cannot insert more items if the bucket is already full.</p> <p>Example: Linear Probing - Find the next empty bucket linearly.</p> <p>To achieve this, the hash function has to be re-defined:</p> \\[ \\mathrm{h}(\\mathrm{key}, \\mathrm{i}): \\mathrm{U} \\rightarrow\\{1 . . \\mathrm{m}\\} \\] <p>In the case of Linear Probing:</p> \\[ \\mathrm{h}(\\mathrm{k}, i)=\\mathrm{h}(\\mathrm{k}, 1)+(i-1) \\bmod m \\] <p>Note that \\((i-1)\\operatorname{mod}m\\) is used start again from index 0 when \\((i-1)&gt;m\\) Code</p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/14.Hashing/#searchkey","title":"Search(key)","text":"<p>Code</p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/14.Hashing/#deletekey","title":"Delete(key)","text":"<ul> <li>Find the key to delete</li> <li>Remove it from the table</li> <li>Set the bucket to Deleted (Tombstone value)</li> </ul> <p>Searching literates until it finds a empty bucket. Setting the bucket to null breaks the searching algorithm, hence the bucket is set to deleted.</p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/14.Hashing/#hash-functions_1","title":"Hash Functions","text":"<p>Uniform Hashing Assumption:</p> <ul> <li>Every key is equally likely to be mapped to every permutation, independent of every other key.</li> </ul>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/14.Hashing/#linear-probing","title":"Linear Probing","text":"<p>Problem: If there is a cluster, then there is a higher probability that the next \\(h(k)\\) will hit the cluster. PDF.</p> <p>Advantages: Faster. Easier to access nearby array cells. PDF.</p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/14.Hashing/#double-hashing","title":"Double Hashing","text":"<ul> <li>Start with two ordinary hash functions \\(\\mathrm{f}(k), \\mathrm{g}(k)\\).</li> <li>Define new hash functions:<ul> <li>\\(\\mathrm{h}(k, i)=\\mathrm{f}(k)+i \\cdot \\mathrm{g}(k) \\bmod m\\)</li> </ul> </li> </ul> <p>Proof</p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/14.Hashing/#performance","title":"Performance","text":"<p>Claim: For \\(n\\) items, in a table of size \\(m\\), assuming uniform hashing, the expected cost of an operation is: $$ \\frac{1}{1-\\alpha} $$</p> <p>Proof</p> <p>Advantages &amp; Disadvantages</p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/17.Graphs/","title":"Graphs","text":"Resources <p>Video Part 1PDF</p> <p>Video Part 2 PDF</p> <p>Video Part 3 PDF</p> <p>Video Part 4 PDF</p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/17.Graphs/#introduction","title":"Introduction","text":"<p>What is a graph?</p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/17.Graphs/#graph-terminology","title":"Graph Terminology","text":"Type Explanation Connected Every pair of nodes is connected by a path.  Disconnected Some pair of nodes is not connected by a path.  Cycle \"Path\" where first and last nodes are the same.  Unrooted Tree Connected graph with no cycles.  Forest Graph with no cycles   <p>Degree of a graph: Maximum number of adjacent edges. Example Connected Components: Example Path: Set of edges connecting two nodes. Path intersects each node at most once Diameter: Maximum distance between two nodes, following the shortest path. Example</p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/17.Graphs/#special-graphs","title":"Special Graphs","text":"<p>Star: Example Clique Example Line: Example Cycle: Example Bipartite Graph: Example</p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/17.Graphs/#representing-a-graph","title":"Representing a graph","text":"<p>Adjacency List: Nodes are stored in an array and Edges are stored as Linked list per node. PDF</p> <p>Adjacency Matrix: PDF: Graph represented as: $$ \\mathrm{A}[\\mathrm{v}][\\mathrm{w}]=1 \\text { iff }(\\mathrm{v}, \\mathrm{w}) \\in \\mathrm{E} $$ To find out if \\(c\\) and \\(d\\) are \\(n\\) hop neighbors, use \\(A^n\\) matrix: Example</p> <p>Trade-offs: Visit PDF</p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/17.Graphs/#searching-a-graph","title":"Searching a Graph","text":"<p>Breadth-First Search</p> <ul> <li>Add the starting node to the queue. </li> <li>Loop until queue is empty: dequeue a node \\(\\to\\) mark visited \\(\\to\\) Add all unvisited outgoing edges of the node.</li> <li>Code</li> <li>Alternative using a queue.</li> <li>Running time: \\(O(V+E)\\) - Analysis</li> </ul> <p>Depth-First Search</p> <ul> <li>Follow a path until the end</li> <li>Backtrack along visited path until the current vertex has a explored edges</li> <li>Recursively explore</li> <li>Code : Shortest path graph is a tree. </li> <li>Alternative using stack</li> <li>\\(O(V+E)\\) using a adjacency list Analysis</li> <li>\\(O(V^2)\\) using a adjacency matrix Analysis</li> </ul>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/17.Graphs/#directed-graph","title":"Directed Graph","text":"<p>Each edge is directed: Definition.</p> <p>In-degree: The number of incoming edges Out-degree: The number of outgoing edges Diagram</p> <p>Representing a Directed Graph:</p> <ul> <li>Adjacency List</li> <li>Adjacency Matrix</li> </ul>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/17.Graphs/#directed-acyclic-graphs","title":"Directed Acyclic Graphs","text":"<p> DAG are useful for such situations</p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/17.Graphs/#topological-ordering","title":"Topological Ordering","text":"<p>A topological sort imposes a total ordering on all vertices, such that edges only point forward. Only directed acyclic graphs have a topological order. Topological order is not unique.</p> <ul> <li>We aim to assign a linear ordering of the tasks.</li> <li>Example</li> <li>Sequential total ordering of all nodes where edges only point forward.</li> <li>Depth-first search (post order) is best used for finding topological order. <code>O(V+E)</code>. Alternative.</li> <li>Example of pre order depth-first search. Case where it cannot find a topological order </li> </ul> <p>Pre-Order Depth first Search</p> <ul> <li>Process each node when it is first visited</li> <li>Code</li> </ul> <p>Post-Order Depth first Search</p> <ul> <li>Process each node when it is last visited. Think of it like a post order traversal in binary tree.</li> <li>Code</li> <li>Example</li> </ul>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/17.Graphs/#single-source-shortest-path","title":"Single-source shortest path","text":""},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/17.Graphs/#shortest-paths-algorithm","title":"Shortest Paths Algorithm","text":"<ul> <li>Set each vertex (distance from the source) to infinity </li> <li>Start from first vertex. Relax the next vertex by comparing if the vertex is greater than the distance + starting vertex.</li> <li>Continue.</li> <li>PDF</li> </ul>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/17.Graphs/#bellman-ford","title":"Bellman-Ford","text":"<ul> <li>PDF</li> <li>Shortest Path algorithm running V times.</li> </ul>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/17.Graphs/#dijkstras-algorithm","title":"Dijkstra's Algorithm","text":"<ul> <li>PDF Consider the node with minimum estimate.</li> <li>Data type required: Priority Queue</li> </ul>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/21.Minimum_Spanning_Tree/","title":"MST","text":"Resources <p>CS2040_21.MST, Video</p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/21.Minimum_Spanning_Tree/#definition","title":"Definition","text":"<p>Spanning tree:. Acyclic subset of the edges that connects all nodes. PDF</p> <p>minimum spanning tree: Is a subset of the edges of a connected, edge-weighted undirected graph that connects all the vertices together, without any cycles and with the minimum possible total edge weight. That is, it is a spanning tree whose sum of edge weights is as small as possible.</p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/21.Minimum_Spanning_Tree/#properties","title":"Properties","text":"<p>PDF</p> <ol> <li>No cycles: Acyclic</li> <li>If you cut an MST, the two pieces are both MSTs.</li> <li>Cycle property<ul> <li>For every cycle, the maximum weight edge is not in the MST.</li> <li>Note that smallest edge will not always be in the MST.</li> </ul> </li> <li>Cut property<ul> <li>For every partition of the nodes, the minimum weight edge across the cut is in the MST.</li> <li>In other words, for all outgoing edge of a vertex, the minimum edges will be in the MST</li> </ul> </li> </ol>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/21.Minimum_Spanning_Tree/#generic-mst-algorithm","title":"Generic MST Algorithm","text":"<p>PDF</p> <p>Red rule: If C is a cycle with no red arcs, then color the max-weight edge in C red. Blue rule: If D is a cut with no blue arcs, then color the min-weight edge in D blue.</p> <p>Apply red rule or blue rule to an arbitrary edge until no more edges can be colored.</p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/21.Minimum_Spanning_Tree/#prims-algorithm","title":"Prim's Algorithm","text":"<p>PDF</p> <p>Algorithm to find the minimum spanning tree using property 4:</p> <ul> <li>Start with vertex. Add it to the set. </li> <li>Find the minimum weight outgoing edge in the set to the remaining vertices. Add the vertex to the set</li> <li>Repeat until all vertex is added.</li> </ul> <p>Data structure: Priority queue.  PDF Time Complexity: \\(O(E\\log V)\\) PDF</p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/21.Minimum_Spanning_Tree/#kruskals-algorithm","title":"Kruskal's Algorithm","text":"<p>PDF</p> <p>Algorithm to find the minimum spanning tree using property 3,4:</p> <p>Sort the edges by ascending weights. Beginning with the smallest weight edge, for each edge: - If the two vertices are not in the same set, union the two vertices. - If the two vertices are already in the same set, don't add.</p> <p>Data structure: Union-Find</p> <p>Performance: </p> <ul> <li>Sorting: \\(O(E \\log E)=O(E \\log V)\\)</li> <li>For E edges:</li> <li>Find: \\(O(\\alpha(n))\\) or \\(O(\\log V)\\)</li> <li>Union: \\(O(\\alpha(n))\\) or \\(O(\\log V)\\)</li> </ul>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/21.Minimum_Spanning_Tree/#directed-minimum-spanning-tree","title":"Directed Minimum Spanning Tree","text":"<p>PDF</p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/21.Minimum_Spanning_Tree/#maximum-spanning-tree","title":"Maximum Spanning Tree","text":"<ol> <li>Multiply each edge weight by -1 .</li> <li>Run MST algorithm.</li> <li>MST that is \"most negative\" is the maximum.</li> </ol>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/22.Dynamic_Programming/","title":"Dynamic Programming","text":"Resources <p>Video - CS2040_22.DynamicProgrammingIntro </p> <p>video - CS2040_23.DynamicProgramming2 </p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/22.Dynamic_Programming/#basics","title":"Basics","text":"<p>Dynamic programming is just a fancy name for:</p> <ul> <li>Breaking up a problem into smaller sub-problems</li> <li>Optimal solution to sub-problems should be components of the optimal solution to the original problem</li> <li>Build the optimal solution iteratively by filling in a table of sub-solutions</li> <li>Take advantage of overlapping sub-problems</li> </ul> <p>Overlapping sub-problems: The same smaller problem is used to solve multiple different bigger problems.</p> <p></p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/22.Dynamic_Programming/#basic-strategy-bottom-up-dynamic-programming","title":"Basic Strategy: Bottom up dynamic programming","text":""},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/22.Dynamic_Programming/#basic-strategy-top-down-dynamic-programming","title":"Basic Strategy: Top down dynamic programming","text":"<p>These are just brief concepts. We will understand them with various examples in the upcoming sections.</p> <ul> <li>Longest Increasing Subsequence</li> <li>Bounded Prize Collecting</li> <li>Vertex Cover on a Tree</li> <li>All-Pairs Shortest Paths</li> </ul>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/22.Dynamic_Programming/#longest-increasing-subsequence","title":"Longest Increasing Subsequence","text":"<p>Problem:. You are give an sequence of integers. Your goal is to find the increasing subsequence of maximum length.</p> <p>{8,3,6,4,5,7,7} </p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/22.Dynamic_Programming/#dag-solution","title":"DAG Solution","text":"<p>One way to find such maximum length is with Directed Acyclic Graphs. For each nodes, draw a directed array to any other nodes with greater value.</p> <p></p> <p>STEP 1: Topological sort STEP 2:  Calculate longest path - DAG_SSSP. LIS = max(LP)+1 Performance: Longest path takes \\(O(V+E)=O(n^2)\\) , Run longest path \\(n\\) times \\(O(n^3)\\)</p> <p>This is inefficient. We don't have to run it n times because to find the maximum path for a node, the maximum path for other connected node have to be solved. This is a example of a overlapping subproblems.</p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/22.Dynamic_Programming/#using-a-bottom-up-approach","title":"Using a bottom up approach","text":"<p>Start with the smallest sub-problem:</p> <p></p> <p>Move to the next node and examine all outgoing edges and find the maximum. Its largest path will be 1 +  the maximum of the outgoing edge:</p> <p></p> <p>Continue for all nodes:</p> <p></p> <p>Performance: \\(O(n^2)\\)</p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/22.Dynamic_Programming/#dynamic-programming-recipe","title":"Dynamic Programming Recipe","text":"<p>In summary the dynamic programming recipe consist of the following steps:</p> <ul> <li>Step 1: Identify optimal substructure<ul> <li>E.g, LIS can be built from suffix LIS</li> </ul> </li> <li>Step 2: Define sub-problems<ul> <li>E.g., \\(S[i]=\\operatorname{LIS}(A[i . . n])\\) starting at \\(A[i]\\)</li> </ul> </li> <li>Step 3: Solve problem using sub-problems<ul> <li>E.g., \\(S[i]=\\left(\\max _{(i, j) \\in E} S[j]\\right)+1\\)</li> </ul> </li> <li>Step 4: Write (pseudo)code<ul> <li>E.g. Code</li> </ul> </li> </ul>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/22.Dynamic_Programming/#bounded-prize-collecting","title":"Bounded Prize Collecting","text":"<p>Problem:. You are given a Directed Graph <code>G=(V,E)</code> and edges weights <code>w</code> which represents the prizes on each edges. Your goal is to find a path that maximizes the total collected by crossing at most <code>k</code> edges. </p> <p></p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/22.Dynamic_Programming/#idea-1","title":"Idea 1:","text":"<ul> <li>Transform G into a DAG</li> <li>Make k copies of every note. For a simple case for 3 node, it may look like:</li> <li>Solve prize collecting via DAG_SSSP (longest path)</li> <li>Running time = \\(O(kVE)\\) See PDF.</li> </ul> <p>To reduce the running time, instead of starting the SSSP algorithm for each node separately, you can create a super source node where edges are all 0. This gives a running time of <code>O(KE)</code></p> <p></p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/22.Dynamic_Programming/#idea-2","title":"Idea 2:","text":"<ul> <li>If you know the optimal solution for <code>(k-1</code>, then it is easy to compute the optimal solution for <code>k</code></li> <li>Define <code>P[v, k]</code> = maximum prize that you can collect starting at v and taking exactly k steps.</li> <li>Solve <code>P[v,k]</code> using subproblems:</li> </ul> \\[ \\begin{aligned} &amp; P[v, k]=\\operatorname{MAX}\\left\\{\\quad P\\left[w_1, k-1\\right]+w\\left(v, w_1\\right),\\right. \\\\ &amp; P\\left[w_2, k-1\\right]+w\\left(v, w_2\\right), \\\\ &amp; \\left.P\\left[w_3, k-1\\right]+w\\left(v, w_3\\right), \\ldots\\right\\} \\\\ &amp; \\end{aligned} \\] <p>Visit PDF for example. The cost is \\(O(kE)\\). See PDF </p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/22.Dynamic_Programming/#vertex-cover-on-a-tree","title":"Vertex Cover on a Tree","text":"<p>Problem:. You are given a undirected, unweighted tree <code>G=(V,E)</code>. Your goal is to find the size of a smallest set of nodes <code>C</code> where every edge is adjacent to at least one node in <code>C</code></p> <p></p> <p>Notation: </p> <ul> <li><code>S[V,0]</code> = size of vertex cover in subtree rooted at node v if v is NOT covered.</li> <li><code>S[V,1]</code> = size of vertex cover in subtree rooted at node v, if v IS covered.</li> </ul> <p></p> <p>Given these notations, the base case is starting at the leaves: </p> <ul> <li><code>S[leaf,0]</code> = 0</li> <li><code>S[leaf,1]</code> = 1</li> </ul> <p>Then,</p> <ul> <li>\\(S[v, 0]=S\\left[w_1, 1\\right]+S\\left[w_2, 1\\right]+S\\left[w_3, 1\\right]+\\ldots\\) where \\(w\\) are the children of \\(v\\). This is because if \\(v\\) is not in the vertex cover, then we need to cover all of \\(v\\)'s children.</li> <li>\\(S[v, 1]=1+\\mathrm{W}_1+\\mathrm{W}_2+\\mathrm{W}_3+\\ldots\\)<ul> <li>where \\(\\mathrm{W}_1=\\min \\left(S\\left[\\mathrm{w}_1, 0\\right], S\\left[\\mathrm{w}_1, 1\\right]\\right)\\) ...</li> </ul> </li> <li>See code </li> </ul> <p>Running time: </p> <ul> <li>2V sub-problems</li> <li><code>O(V)</code> time to solve all subproblems<ul> <li>Each edge explored once.</li> <li>Each sub-problem involves exploring children edges.</li> </ul> </li> </ul>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/22.Dynamic_Programming/#all-pairs-shortest-paths","title":"All-Pairs Shortest Paths","text":"<p>Problem: You are given a directed, weighted graph <code>G=(V,E)</code>. Your goal is to preprocess G to prepare for the query min-distance(v,w) </p> <p>Solution: On preprocessing: Use Dijkstra algorithm for a node and store the weight for each nodes. Repeat for every other node</p>"},{"location":"Year%201%20Semester%202/CS2040S/MyNotes/22.Dynamic_Programming/#floyd-warshall","title":"Floyd-Warshall","text":"<p>Let \\(S[v,w,P]\\) be the shortest path from \\(v\\) to \\(w\\) that only uses intermediate nodes in the set \\(P\\).</p> <p></p> <p>Solution: \\(S[v,w,P_{n+1}] =\\text{min}(S[v,w,P_{n}],S[v,n+1,P_{n}]+S[n+1,w,P_{n}])\\). Where \\(n\\) is the nth node in \\(P\\). For example, if you want to find \\(S[v,w,P_{8}]\\), the possible path of going to \\(w\\) will look like this:</p> <p></p>"},{"location":"Year%201%20Semester%202/CS2040S/Notes/CS2040_14.1%20Analysis%20of%20chaining/","title":"Analysis of chaining","text":"<p>Info</p> <p>This page covers the expected search time and the maximum chain length.</p>"},{"location":"Year%201%20Semester%202/CS2040S/Notes/CS2040_14.1%20Analysis%20of%20chaining/#expected-search-time","title":"Expected Search time","text":"<p>In this section, we try to derive the claim: </p> <ul> <li>Expected search time \\(= O(1)+\\) load(hash table) <ul> <li>\\(O(1)\\) : hash function + array access </li> <li>load(hash table): linked list traversal = \\(\\frac{n}{m}=\\) average number of items per bucket</li> </ul> </li> </ul>"},{"location":"Year%201%20Semester%202/CS2040S/Notes/CS2040_14.1%20Analysis%20of%20chaining/#the-simple-uniform-hashing-assumption-suha","title":"The Simple Uniform Hashing Assumption (SUHA)","text":"<p>Lets begin with the assumption</p> <ul> <li>Every key is equally likely to map to every bucket</li> <li>Keys are mapped independently</li> </ul>"},{"location":"Year%201%20Semester%202/CS2040S/Notes/CS2040_14.1%20Analysis%20of%20chaining/#probability-theory","title":"Probability Theory","text":"<p>Define \\(X(i, j)\\) such that: </p> \\[\\begin{aligned} X(i, j) &amp; =1 \\text { if } \\mathrm{i} \\text { 'th key is put in bucket } \\mathrm{j} \\\\ &amp; =0 \\text { otherwise }\\end{aligned}\\] <p>This can be used to represent the number of items in bucket b: \\(\\Sigma_{\\mathrm{i}} \\mathrm{X}(\\mathrm{i}, \\mathrm{b})\\)</p>"},{"location":"Year%201%20Semester%202/CS2040S/Notes/CS2040_14.1%20Analysis%20of%20chaining/#unsuccessful-search","title":"Unsuccessful Search","text":"<p>Suppose search is for key \\(k\\), and the hash table does not contain \\(k\\). Let \\(b=h(k)\\).</p> <p>The expected value of the chain length at bucket \\(b\\) is defined as: $$ \\begin{aligned} &amp; =\\mathbf{E}\\left(\\Sigma_{\\mathrm{i}} \\mathrm{X}(\\mathrm{i}, \\mathrm{b})\\right) \\ &amp; =\\Sigma_{\\mathrm{i}} \\mathbf{E}(\\mathrm{X}(\\mathrm{i}, \\mathrm{b})) \\end{aligned} $$</p> <p>By the linearity of expectation \\(E(A+B)=E(A)+E(B)\\). </p> <p>The expected value is equal to the weighted sum of the outcomes: </p> <p>\\(\\(\\begin{aligned} \\mathbf{E}(\\mathrm{X}(\\mathrm{i}, \\mathrm{b})) &amp; =\\operatorname{Pr}(\\mathrm{X}(\\mathrm{i}, \\mathrm{b})==1)\\times 1+\\operatorname{Pr}(\\mathrm{X}(\\mathrm{i}, \\mathrm{b})==0)\\times 0 \\\\ &amp; =\\operatorname{Pr}(\\mathrm{X}(\\mathrm{i}, \\mathrm{b})==1) \\\\ &amp; =1 / \\mathrm{m}\\end{aligned}\\)\\) The probability of finding \\(i^{th}\\) element in bucket \\(b\\) is \\(\\frac{1}{m}\\) as the element is in one of \\(m\\) buckets.</p> <p>Thus we get:</p> \\[\\begin{aligned} &amp; \\Sigma_{\\mathrm{i}} \\mathbf{E}(\\mathrm{X}(\\mathrm{i}, \\mathrm{b})) \\\\ =&amp;\\Sigma_{\\mathrm{i}} \\frac{1}{m}=\\frac{n}{m}=\\alpha \\end{aligned}\\]"},{"location":"Year%201%20Semester%202/CS2040S/Notes/CS2040_14.1%20Analysis%20of%20chaining/#successful-search","title":"Successful Search","text":"<p>Suppose search is for the \\(t^{th}\\)  inserted key, \\(k_t\\).</p> <p>Let \\(b=h\\left(k_t\\right)\\). We know that the \\(b^{th}\\)  bucket contains at least one key, \\(k_t\\). Therefore, the expected value of the chain length at bucket \\(b\\):</p> \\[ \\begin{aligned} &amp; \\leq 1+\\mathbf{E}\\left(\\sum_{i \\neq t} \\mathrm{X}(\\mathrm{i}, \\mathrm{b})\\right) \\\\ &amp; =1+\\sum_{i \\neq t} \\mathbf{E}(\\mathrm{X}(\\mathrm{i}, \\mathrm{b})) \\\\ &amp; =1+\\sum_{i \\neq t} \\frac{1}{m} \\\\ &amp; =1+\\frac{n-1}{m} \\leq 1+\\alpha \\end{aligned} \\]"},{"location":"Year%201%20Semester%202/CS2040S/Notes/CS2040_14.1%20Analysis%20of%20chaining/#maximum-chain-length","title":"Maximum chain length","text":"<p>Analogy:</p> <ul> <li>Throw \\(n\\) balls in \\(m=n\\) bins</li> <li>What is the maximum number of balls in a bin?</li> </ul> <p>Cost: \\(\\Theta(\\log n / \\log \\log n)\\) = \\(O(\\log n)\\)</p> <p>Derivation will not be covered in this module.</p>"},{"location":"Year%201%20Semester%202/CS2040S/Recitation/Rec1/CS2040_Rec01Solution/","title":"CS2040 Rec01Solution","text":"<p>My solution toRecitation 01</p>"},{"location":"Year%201%20Semester%202/CS2040S/Recitation/Rec1/CS2040_Rec01Solution/#problem-1-order-of-growth-review","title":"Problem 1. Order of Growth (Review)","text":"<p>Problem 1.a. Consider the following function isPrime for checking if an integer \\(n\\) is prime:</p> <pre><code>public static boolean isPrime(int n) {\nif (n &lt; 2) {\nreturn false;\n}\nfor (int i = 2; i &lt; n; i++) {\nif (isDivisible(n, i)) {\nreturn false;\n}\n}\nreturn true;\n}\n</code></pre> <p>What is the order of growth for isPrime given the following order of growths for isDivisible \\((n, i)\\) ?</p> <ol> <li>Time: \\(O(1)\\)<ol> <li>\\(O(n)\\)</li> </ol> </li> <li>Time: \\(O(n)\\)<ol> <li>\\(O(n^2)\\)</li> </ol> </li> <li>Time: \\(O(i)\\)<ol> <li>\\(O(n^2)\\)</li> </ol> </li> </ol> <p>Problem 1.b. Next, consider the following function isPrime2 for checking if an integer \\(n\\) is prime:</p> <pre><code>public static boolean isPrime2(int n) {\nif (n &lt; 2) {\nreturn false;\n}\nfor (int i = 2; i &lt; sqrt(n); i++) {\nif (isDivisible(n, i)) {\nreturn false;\n}\n}\nreturn true;\n}\n</code></pre> <p>What is the order of growth for isPrime2 given the following order of growths for isDivisible \\((n, i)\\) ?</p> <ol> <li>Time: \\(O(n)\\)<ol> <li>\\(O(n\\sqrt{ n })\\)</li> </ol> </li> <li>Time: \\(O(i)\\)<ol> <li>\\(O(n)\\)</li> </ol> </li> </ol> <p>However, the following code is not correct. Should be  \\(i \\leq \\sqrt{ n }\\).</p> <p>Problem 1.c. Consider yet another variant of an algorithm to check if an integer \\(n\\) is prime that we call isPrime3 below:</p> <pre><code>public static boolean isPrime3(int n) {\nif (n &lt; 2) {\nreturn false;\n}\nfor (int i = 2; i &lt;= sqrt(n); i++) {\nif (isPrime3(i) &amp;&amp; isDivisible(n, i)) {\nreturn false;\n}\n}\nreturn true;\n}\n</code></pre> <p>We are simulating an (inefficient) version of the Sieve of Eratosthenes. For this algorithm, express the time complexity expression as a concise recurrence relation (solving it is left as an optional challenge). Assuming the order of growth for isDivisible \\((n, i)\\) is \\(\\mathrm{O}(1)\\), how does isPrime3 compare against isPrime2?</p> <p>\\(O(n)\\)</p>"},{"location":"Year%201%20Semester%202/CS2040S/Recitation/Rec1/CS2040_Rec01Solution/#problem-2-how-much-do-you-make","title":"Problem 2. How Much Do You Make?","text":""},{"location":"Year%201%20Semester%202/CS2040S/Recitation/Rec1/CS2040_Rec01Solution/#problem-2a","title":"Problem 2.a.","text":"<p>Come up with an algorithm that will allow the students to determine the average pay of the group without revealing their own salaries to any of the other members in the group. If we want to evaluate how good our algorithm is, what metrics should we use? Realize that when evaluating an algorithm, it isn't always obvious what metrics we care about, and you have to think hard to make sure you are optimizing the right thing!</p> <p>As you come up with an algorithm, think about what invariants are being satisfied. Since the goal is related to average salary, maybe you want an invariant that relates the current state to the average salary being computed?</p> <p>ProTip: The choice of metrics should provide an good measure of how well the chosen objective is met. Metrics therefore drives the solution. You may be looking at multiple metrics at once, which is in the case where you are optimizing for multiple objectives. Often times, a single total metric can be obtained by linearly combining multiple metrics via weighing the relative importance of the objectives they correspond to.</p> <p>Solution:</p>"},{"location":"Year%201%20Semester%202/CS2040S/Recitation/Rec1/CS2040_Rec01Solution/#problem-2b","title":"Problem 2.b.","text":"<p>Now think about what happens if \\(k\\) members of the group decide to collude and share information. Is your algorithm still able to preserve the privacy of all the members, or could the salary for some of the members be leaked?</p> <p>If there is a possibility for privacy to be compromised, modify your proposed algorithm to \"fix\" this leak. (Think about the invariant that we used last time.)</p> <p>How well does your new algorithm perform? Is that the best we can do? Can you do even better? What is the best that we can do?</p> <p>Solution:</p>"},{"location":"Year%201%20Semester%202/CS2040S/Recitation/Rec1/CS2040_Rec01Solution/#problem-2c-optional-part","title":"Problem 2.c. Optional Part.","text":"<p>We had earlier assumed that all the participants in the group are all honest. Suppose that one of the group members is a saboteur who wants to mislead the rest by submitting a salary that is many times higher or lower than the actual salary. You can assume that the salaries have a normal distribution with a \"reasonable\" variance. This saboteur would introduce a salary point that will appear as an outlier in the full data set. What if instead of just 1 saboteur, we had a small number \\(s\\) of them?</p> <p>Given your proposed algorithm, how else could a saboteur decide to do to cause inaccuracies in the results?</p> <p>Solution:</p>"},{"location":"Year%201%20Semester%202/CS2040S/Tutorial/tut1/CS2040S_tut01solution/","title":"CS2040S tut01solution","text":"<p>My Solution to Week 3 Tutorial 1</p>"},{"location":"Year%201%20Semester%202/CS2040S/Tutorial/tut1/CS2040S_tut01solution/#problem-1-java-review","title":"Problem 1 Java Review","text":""},{"location":"Year%201%20Semester%202/CS2040S/Tutorial/tut1/CS2040S_tut01solution/#a-what-is-the-difference-between-a-class-and-an-object-illustrate-with-an-example","title":"(a) What is the difference between a class and an object? Illustrate with an example.","text":"<p>In Java, a class is a blueprint for creating objects, providing initial values for state (member variables or attributes), and implementations of behavior (member functions or methods). An object is an instance of a class and it contains the state and behavior defined in the class.</p>"},{"location":"Year%201%20Semester%202/CS2040S/Tutorial/tut1/CS2040S_tut01solution/#b-why-does-the-main-method-come-with-a-static-modifier","title":"(b) \u00a0Why does the main method come with a static modifier?","text":"<p>As soon as the Java runtime begins, there are no objects of the class present. The <code>main()</code> method must be static for the JVM to be able to load the class into memory and call the main function. JVM won't be able to call the main method if it's not static because the class's object isn't present.</p>"},{"location":"Year%201%20Semester%202/CS2040S/Tutorial/tut1/CS2040S_tut01solution/#c-give-an-example-class-or-classes-that-uses-the-modifier-private-incorrectly-ie-the-program-will-not-compile-as-it-is-but-would-compile-if-private-was-changed-to-public","title":"(c) \u00a0Give an example class (or classes) that uses the modifier private incorrectly (i.e., the program will not compile as it is, but would compile if private was changed to public)","text":"<pre><code>public class example1 {\nprivate int x = 1; }\n</code></pre> <pre><code>public class example2 {\nprivate example1 object = new example();\nprivate int val = object.x; // error \n}\n</code></pre>"},{"location":"Year%201%20Semester%202/CS2040S/Tutorial/tut1/CS2040S_tut01solution/#d-the-following-question-is-about-interfaces","title":"(d) \u00a0The following question is about Interfaces.","text":""},{"location":"Year%201%20Semester%202/CS2040S/Tutorial/tut1/CS2040S_tut01solution/#di-why-do-we-use-interfaces","title":"(d)(i) Why do we use interfaces?","text":"<p>Java interfaces are used to specify the set of methods that a class is required to implement. Interfaces are used to provide a common set of behaviors for different classes.</p>"},{"location":"Year%201%20Semester%202/CS2040S/Tutorial/tut1/CS2040S_tut01solution/#dii-give-an-example-of-using-an-interface","title":"(d)(ii) Give an example of using an interface.","text":"<pre><code>interface GetAreable { public abstract double getArea(); }\n</code></pre> <pre><code>public class Square {\nprivate int x = 10;\n@Override public double getArea() {\nreturn this.x*this.x;\n}\n}\n</code></pre>"},{"location":"Year%201%20Semester%202/CS2040S/Tutorial/tut1/CS2040S_tut01solution/#diii-can-a-method-return-an-interface","title":"(d)(iii) Can a method return an interface?","text":"<p>Yes, but the run time type of the object returned will be a subtype of the interface since interface cannot be instantiated.</p>"},{"location":"Year%201%20Semester%202/CS2040S/Tutorial/tut1/CS2040S_tut01solution/#e-refer-to-integerexaminationjava-which-can-be-found-in-the-same-folder-as-this-pdf-without-running-the-code-predict-the-output-of-the-main-method-can-you-explain-the-outputs","title":"(e) \u00a0Refer to IntegerExamination.java, which can be found in the same folder as this PDF. Without running the code, predict the output of the main method. Can you explain the outputs?","text":"<pre><code>I am in addOne. The value of i is 8\nI am in myIntAddOne. The value of j is 8\nI am in myOtherIntAddOne. The value of k is 8\nThe final value of i back in main is 7\nThe final value of j back in main is 8\nThe final value of k back in main is 7\n</code></pre>"},{"location":"Year%201%20Semester%202/CS2040S/Tutorial/tut1/CS2040S_tut01solution/#f-can-a-variable-in-a-parameter-list-for-a-method-have-the-same-name-as-a-member-or-static-variable-in-the-class-if-yes-how-is-the-conflict-of-names-resolved","title":"(f) \u00a0Can a variable in a parameter list for a method have the same name as a member (or static) variable in the class? If yes, how is the conflict of names resolved?","text":"<p>When a method is called, the values of the arguments passed to the method are assigned to the variables in the parameter list. If a variable in the parameter list has the same name as a member (or static) variable, the value of the member variable will be hidden by the value of the parameter variable within the scope of the method. The variable in the class can be accessed with <code>this</code> keyword.</p>"},{"location":"Year%201%20Semester%202/CS2040S/Tutorial/tut1/CS2040S_tut01solution/#problem-2-asymptotic-analysis","title":"Problem 2 Asymptotic Analysis","text":"<p>This is a good time for a quick review of asymptotic big-O notation. For each of the expressions below, what is the best (i.e. tightest) asymptotic upper bound (in terms of n)?</p> <p>(a) \\(f_1(n)=7.2+34 n^3+3254 n\\) \\(O(n^3)\\)</p> <p>(b) \\(f_2(n)=n^2 \\log n+25 n \\log ^2 n\\) \\(O(n^2 \\log n)\\)</p> <p>(c) \\(f_3(n)=2^{4 \\log n}+5 n^5\\) \\(O(n^5)\\)</p> <p>(d) \\(f_4(n)=2^{2 n^2+4 n+7}\\) \\(O(2^{2n^2+4n})\\) </p>"},{"location":"Year%201%20Semester%202/CS2040S/Tutorial/tut1/CS2040S_tut01solution/#problem-3-more-asymptotic-analysis","title":"Problem 3 More Asymptotic Analysis!","text":"<p>Let \\(f\\) and \\(g\\) be functions of \\(n\\) where \\(f(n)=O(n)\\) and \\(g(n)=O(\\log n)\\). Find the best asymptotic bound (if possible) of the following functions.</p> <p>(a) \\(h_1(n)=f(n)+g(n)\\) \\(O(n)\\)</p> <p>(b) \\(h_2(n)=f(n) \\times g(n)\\) \\(O(n \\log n)\\)</p> <p>(c) \\(h_3(n)=\\max (f(n), g(n))\\) \\(O(n)\\)</p> <p>(d) \\(h_4(n)=f(g(n))\\) \\(O(\\log n)\\)</p> <p>(e) \\(h_5(n)=f(n)^{g(n)}\\) The constant matters. Hence the problem cant be solved.</p>"},{"location":"Year%201%20Semester%202/CS2040S/Tutorial/tut1/CS2040S_tut01solution/#problem-4-application-of-binary-search","title":"Problem 4 Application of Binary Search","text":"<p>Given a sorted array of \\(n-1\\) unique integers in the range \\([1, n]\\), how would you find the missing element? Discuss possible naive solutions and possibly faster solutions.</p> <ol> <li> <p>Naive solution using a for loop:    We can iterate through the array using a for loop and compare each element with the expected value (i.e. the current index + 1). Time complexity: \\(O(n)\\).</p> </li> <li> <p>Using Binary search:    We can use binary search to find the missing element. We start by finding the middle element of the array and compare it with the middle element of the range \\([1, n]\\). If the middle element of the array is less than the middle element of the range, the missing element must be in the right half of the array. If the middle element of the array is greater than the middle element of the range, the missing element must be in the left half of the array. We continue the search in the half that the missing element could be in, until we find it. Time complexity: \\(O(\\log n)\\).</p> </li> </ol>"},{"location":"Year%201%20Semester%202/CS2040S/Tutorial/tut1/CS2040S_tut01solution/#problem-5-another-application-of-binary-search","title":"Problem 5. Another Application of Binary Search","text":"<ol> <li>Start by setting the lower bound k_min = 0 and upper bound k_max = sum of all the piles of homework.</li> <li>In each iteration, calculate the mid value of k_min and k_max and check if it is a valid k that allows you to complete all piles of homework within h hours.</li> <li>To check if k is a valid value, you can iterate through the piles of homework and check how many hours it would take to finish that pile with the current value of k. You can keep a running total of the hours and if that exceeds h hours, k is not a valid value.</li> <li>If k is a valid value, update k_max to mid-1, otherwise update k_min to mid+1.</li> <li>Repeat steps 2-4 until k_min is greater than or equal to k_max.</li> <li>The final value of k_min will be the minimum integer k that allows you to complete all your homework within h hours.</li> </ol>"},{"location":"Year%201%20Semester%202/CS2040S/Tutorial/tut1/CS2040S_tut01solution/#problem-6-yet-another-application-of-binary-search","title":"Problem 6. Yet Another Application of Binary Search","text":"<p>(Optional) Given an array of \\(n\\) \\(x\\) and \\(y\\)-coordinates of an \\(n\\)-sided convex polygon in clockwise order, find a bounding box around the polygon. Discuss possible naive solutions and possibly faster solutions. A convex polygon is a polygon where all interior angles are less than 180 degrees.</p> <ul> <li>Use peak finding.</li> </ul>"},{"location":"Year%201%20Semester%202/CS2040S/Tutorial/tut2/CS2040S_tut02solution/","title":"CS2040S tut02solution","text":"<p>My Solution to Week 4 Tutorial 2</p>"},{"location":"Year%201%20Semester%202/CS2040S/Tutorial/tut2/CS2040S_tut02solution/#problem-1-time-complexity-analysis","title":"Problem 1. Time Complexity Analysis","text":"<p>Analyze the following code snippets and find the best asymptotic bound for the time complexity of the following functions with respect to \\(n\\).</p> <p>(a) \\(O(n)\\)</p> <pre><code>public int niceFunction(int n) {\nfor (int i = 0; i &lt; n; i++) {\nSystem.out.println(\"I am nice!\");\n}\nreturn 42;\n}\n</code></pre> <p>(b) \\(O(n)\\)</p> <pre><code>public int meanFunction(int n) {\nif (n == 0) return 0;\nreturn 2 * meanFunction(n / 2) + niceFunction(n);\n}\n</code></pre> <p>(c) \\(O(n^2)\\)</p> <pre><code>public int strangerFunction(int n) {\nfor (int i = 0; i &lt; n; i++) {\nfor (int j = 0; j &lt; i; j++) {\nSystem.out.println(\"Execute order?\");\n}\n}\nreturn 66;\n}\n</code></pre> <p>(d) \\(O(n\\log n)\\)</p> <pre><code>public int suspiciousFunction(int n) {\nif (n == 0) return 2040;\nint a = suspiciousFunction(n / 2);\nint b = suspiciousFunction(n / 2);\nreturn a + b + niceFunction(n);\n}\n</code></pre> <p>(e) \\(O(2^n)\\)</p> <pre><code>public int badFunction(int n) {\nif (n &lt;= 0) return 2040;\nif (n == 1) return 2040;\nreturn badFunction(n - 1) + badFunction(n - 2) + 0;\n}\n</code></pre> <p>(f) \\(O(n\\log n)\\)</p> <pre><code>public int metalGearFunction(int n) {\nfor (int i = 0; i &lt; n; i++) {\nfor (int j = 1; j &lt; i; j *= 2) {\nSystem.out.println(\"!\");\n}\n}\nreturn 0;\n}\n</code></pre> <p>(g) \\(O(n)\\)</p> <pre><code>public String simpleFunction(int n) {\nString s = \"\";\nfor (int i = 0; i &lt; n; i++) {\ns += \"?\";\n}\nreturn s;\n}\n</code></pre>"},{"location":"Year%201%20Semester%202/CS2040S/Tutorial/tut2/CS2040S_tut02solution/#sorting-review","title":"Sorting Review","text":"<p>(a) How would you implement insertion sort recursively? Analyse the time complexity by formulating a recurrence relation.</p> <pre><code>void insertionSortRecursive(int arr[], int n)\n{\n// Base case\nif (n &lt;= 1)\nreturn;\n// Sort first n-1 elements\ninsertionSortRecursive( arr, n-1 );\n// Insert last element at its correct position\n// in sorted array.\nint last = arr[n-1];\nint j = n-2;\n/* Move elements of arr[0..i-1], that are\n    greater than key, to one position ahead\n    of their current position */\nwhile (j &gt;= 0 &amp;&amp; arr[j] &gt; last)\n{\narr[j+1] = arr[j];\nj--;\n}\narr[j+1] = last;\n}\n</code></pre> <p>Complexity \\(O(n^2)\\)</p> <p>(b) Consider an array of pairs \\((a, b)\\). Your goal is to sort them by \\(a\\) in ascending order. If there are any ties, we break them by sorting \\(b\\) in ascending order. For example, \\([(2,1),(1,4),(1\\), \\(3)\\) ] should be sorted into \\([(1,3),(1,4),(2,1)]\\).</p> <p>You are given 2 sorting functions, which are a MergeSort and a SelectionSort. You can use each sort at most once. How would you sort the pairs? Assume you can only sort by one field at a time.</p> <p>Use selection sort on \\(b\\) and merge sort on \\(a\\). Sort for \\(a\\) must be stable to maintain the order of \\(b\\)</p> <p>(c) We have learned how to implement MergeSort recursively. How would you implement MergeSort iteratively? Analyse the time and space complexity.</p> <p>Do it bottom up</p>"},{"location":"Year%201%20Semester%202/CS2100/CS2100/","title":"CS2100 Computer Organisation","text":"<p>NUS MODS Homepage Canvas</p> <p>The objective of this module is to familiarize students with the fundamentals of computing devices. Through this module students will understand the basics of data representation, and how the various parts of a computer work, separately and with each other. This allows students to understand the issues in computing devices, and how these issues affect the implementation of solutions. Topics covered include data representation systems, combinational and sequential circuit design techniques, assembly language, processor execution cycles, pipelining, memory hierarchy and input/output systems.</p>"},{"location":"Year%201%20Semester%202/CS2100/CS2100/#notes","title":"Notes","text":"Week Notes Summary Tutorial 1 Lect0_Welcome_22s2 - - 1 Lect01_Introduction 01 Introduction - 1 Lect02_Overview_of_C_Programming-1Lect02_Overview_of_C_Programming - 2Lect02_Overview_of_C_Programming - 3 02 Overview of C programming - 1 Lect03_Number_Systems - 1Lect03_Number_Systems - 2Lect03_Number_Systems - 3Lect03_Number_Systems - 4 03 Number Systems - 2 CS2100_Rec1ExtraCS2100_Recitation 1 - - 2 Lect4a_Pointers_and_Functions 1Lect4b_Pointers_and_Functions 2Lect4c_Pointers_and_Functions 3Lect4d_Pointers_and_Functions 4 04 Pointers and Functions - 2 Lect5a_Arrays_Strings_and_Structures 1Lect5b_Arrays_Strings_and_Structures 2Lect5c_Arrays_Strings_and_Structures 3Lect5d_Arrays_Strings_and_Structures 4 05 Arrays String and Structures - 3 CS2100_Recitation 2 - - 3 Lect07_MIPS1_full_annotated 07-9 MIPSMIPS_Reference_Data CS2100_tut1CS2100_tut1AnsCS2100_tut01ans_slides_for_tutors 3 Lect08_MIPS2_full_annotated - - 4 Lect09_MIPS3_full - CS2100_tut2 CS2100Tut2Ans-Release CS2100_tut02ans_slides_for_tutors 4 Lect10_ISA_full 10 ISA - 5 Lect11_Datapath_full 11 Datapath CS2100_tut3 CS2100_tut3Ans CS2100_tut03ans_slides_for_tutors 6 Lect12_Control 12 Control CS2100_tut4CS2100_tut4Ans CS2100_tut04ans_slides_for_tutors 7 Lect13_Boolean_Algebra_full Lect14_Logic_Circuits_full Lect15_Simplification_full 13 Boolean Algebra14 Logic Circuits15 Simplification CS2100_tut5CS2100_tut5Ans CS2100_tut05ans_slides_for_tutors 8 Lect17_Combinational_Circuits_full 17 Combinational Circuits CS2040_tut06CS2100-tut06ans CS2100_tut06ans_slides_for_tutors 9 Lect18_MSI_Components_full 18 MSI Components CS2100_tut07qns CS2100_tut07ans CS2100_tut07ans_slides_for_tutors 10 Lect19_Sequential_Logic_Part-1Lect19_Sequential_Logic_Part-2Lect19_Sequential_Logic_Part-3 19 Sequential Logic CS2100_tut08qns CS2100_tut08ans CS2100_tut08ans_slides_for_tutors 11 Lect20_Pipelining1_fullLect21_Pipelining2_full 20 Pipelining CS2100_tut09qns CS2100_tut09ans CS2100_tut09ans_slides_for_tutors 12 Lect22_Cache1_fullLect23_Cache2_full 22 Cache CS2100_tut10qnsCS2100_tut10ans CS2100_tut10ans_slides_for_tutors 13 - - CS2100_tut11qnsCS2100tut11_ansCS2100_tut11ans_slides_for_tutors <p>Key Notes</p>"},{"location":"Year%201%20Semester%202/CS2100/CS2100/#resources","title":"Resources","text":""},{"location":"Year%201%20Semester%202/CS2100/CS2100/#assessments","title":"Assessments","text":"CA component Weightage Lecture quizzes 5% Tutorial attendance 1% 2 Assignments 10% Labs 14% Mid-term test * 20% Final exam * 50%"},{"location":"Year%201%20Semester%202/CS2100/CS2100/#books","title":"Books","text":"<p>Digital Logic Design (DLD) 2nd edition \ud83d\udd3d Read Computer Organization and Design (COD), 4th edition \ud83d\udd3d</p>"},{"location":"Year%201%20Semester%202/CS2100/CS2100/#midterm-past-papers","title":"Midterm Past papers","text":"Paper Solution CS2100_midterm_21s1_qns CS2100_midterm_21s1_ans CS2100_midterm_20s2_qns CS2100_midterm_20s2_ans CS2100_midterm_19s2_qns CS2100_midterm_19s2_answer_sheetCS2100_midterm_19s2_ans CS2100_termtest1_18s2_qns CS2100_termtest1_18s2_form_ans CS2100_termtest1_17s2_qns CS2100_termtest1_17s2_form_ans_to_post <p>CS2100_MidTermAns-Release</p>"},{"location":"Year%201%20Semester%202/CS2100/CS2100/#finals","title":"Finals","text":"<ul> <li>AY2021/22 Semester 2:\u00a0Question paper\u00a0|\u00a0Answer sheets (blank)</li> <li>AY2021/22 Semester 1:\u00a0Question paper</li> <li>AY2020/21 Semester 2:\u00a0Question paper</li> <li>AY2019/20 Semester 2:\u00a0Question paper\u00a0|\u00a0Answer book (blank) | Answers</li> <li>AY2018/19 Semester 2:\u00a0Question paper\u00a0|\u00a0Answer book (blank) | Answers</li> <li>AY2017/18 Semester 2:\u00a0Question paper\u00a0|\u00a0Answer Book (blank)</li> <li>AY2016/17 Semester 2:\u00a0Question paper\u00a0|\u00a0Answer Book (blank)</li> <li>AY2015/16 Semester 1:\u00a0Question paper\u00a0|\u00a0Answer Book (blank)</li> </ul>"},{"location":"Year%201%20Semester%202/CS2100/CS2100/#assigment","title":"Assigment","text":"Assignment My Ans CS2100_assign1_qns assign1_ans CS2100_CS2100Assg2"},{"location":"Year%201%20Semester%202/CS2100/Notes/01%20Introduction/","title":"Introduction","text":""},{"location":"Year%201%20Semester%202/CS2100/Notes/01%20Introduction/#programming-languages","title":"Programming Languages","text":"<p>Programming language: a formal language that specifies a set of instructions for a computer to implement specific algorithms to solve problems.</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/01%20Introduction/#abstraction","title":"Abstraction","text":"<p>High-level program</p> <ul> <li> <p>Level of abstraction closer to problem domain</p> </li> <li> <p>Provides productivity and portability, Easy to read</p> </li> </ul> <p>Low-level program</p> <ul> <li>Textual and symbolic representation of instructions</li> </ul> <p>Machine Code</p> <ul> <li>Binary bits of instructions and data</li> </ul> <p></p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/01%20Introduction/#abstraction-layers","title":"Abstraction layers","text":""},{"location":"Year%201%20Semester%202/CS2100/Notes/01%20Introduction/#so-what-is-a-computer","title":"So, What is a Computer ?","text":"<p>A computer is a device capable of solving problems according to designed programs. It simply augments our power of storage and speed of calculation.</p> <p>From computer organisation perspective, we study the components and how they work together. Processor, memory, io devices, networks...</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/01%20Introduction/#components-of-a-computer","title":"Components of a computer","text":"<ul> <li>Power supply</li> <li>Motherboard</li> <li>Central Processing Unit (CPU)</li> <li>Random Access memory (RAM)</li> <li>Hard drive </li> <li>Cooling fan</li> <li>I/O Devices </li> </ul>"},{"location":"Year%201%20Semester%202/CS2100/Notes/01%20Introduction/#why-study-computer-organisation","title":"Why study Computer Organisation ?","text":"<ul> <li>Computer organisation is the study of internal working, structuring and implementation of a computer system.</li> <li>It\u00a0refers to the level of abstraction above the digital logic level, but below the operating system level.</li> </ul>"},{"location":"Year%201%20Semester%202/CS2100/Notes/01%20Introduction/#from-user-to-builder","title":"From User to Builder","text":"<ul> <li>You want to call yourself a computer scientist/specialist.</li> <li>You want to build software people use.</li> <li>You need to make purchasing decisions.</li> <li>You need to offer \u201cexpert\u201d advice.</li> <li>Hardware and software affect performance</li> <li>Algorithm determines number of source-level statements   (eg: CS1010, CS2030, CS2040, CS3230)</li> <li>Language, compiler, and architecture determine machine instructions    (COD chapters 2 and 3)</li> <li>Processor and memory determine how fast instructions are executed    (COD chapters 5, 6 and 7)</li> <li>Understanding performance (COD chapter 4)</li> </ul>"},{"location":"Year%201%20Semester%202/CS2100/Notes/02%20Overview%20of%20C%20programming/","title":"Overview of C Programming","text":""},{"location":"Year%201%20Semester%202/CS2100/Notes/02%20Overview%20of%20C%20programming/#edit-compile-execute","title":"Edit, Compile, Execute","text":""},{"location":"Year%201%20Semester%202/CS2100/Notes/02%20Overview%20of%20C%20programming/#a-simple-c-program","title":"A Simple C Program","text":""},{"location":"Year%201%20Semester%202/CS2100/Notes/02%20Overview%20of%20C%20programming/#general-form","title":"General Form","text":"<pre><code>preprocessor directives // Insturction to the compiler, eg librady headers\n\nmain function header \n{ \n    declaration of variables \n    executable statements\n    // Mainly consists of 3 parts\n    // - Input data\n    // - Computation\n    // - Output results\n}\n</code></pre> <p>By convention, <code>return 0</code> is for successful execution and <code>-1</code> for unsuccessful execution.</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/02%20Overview%20of%20C%20programming/#von-neumann-architecture","title":"von Neumann Architecture","text":"<ul> <li>Central Processing Unit (CPU)<ul> <li>Registers</li> <li>A control unit containing an instruction register and program counter</li> <li>An arithmetic/logic unit (ALU)</li> </ul> </li> <li>Memory<ul> <li>Stores both program and data in random-access memory (RAM)</li> </ul> </li> </ul>"},{"location":"Year%201%20Semester%202/CS2100/Notes/02%20Overview%20of%20C%20programming/#variables","title":"Variables","text":"<pre><code>float miles,kms;\n</code></pre> <p>Every variable is identified by a name (identifier), has a data type, and contains a value which could be modified. (Each variable actually has an address too)</p> <ul> <li>A variable is declared with a data type</li> <li>Variables may </li> <li>be initialized during declaration</li> <li>Without initialization, the variable contains an unknown value</li> </ul>"},{"location":"Year%201%20Semester%202/CS2100/Notes/02%20Overview%20of%20C%20programming/#data-types","title":"Data types","text":"<p>Every variable must be declared with a data type (strongly typed)</p> <ul> <li><code>int</code>: For integers</li> <li><code>float</code> or <code>double</code>: For real numbers<ul> <li>4 bytes for float and 8 bytes for double (in sunfire)</li> </ul> </li> <li><code>char</code>: For characters</li> </ul>"},{"location":"Year%201%20Semester%202/CS2100/Notes/02%20Overview%20of%20C%20programming/#macro-expansions","title":"Macro expansions","text":"<p>One of the uses is to define a macro for a constant value Eg: <code>#define PI 3.142 // use all CAP for macro</code></p> <p></p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/02%20Overview%20of%20C%20programming/#inputoutput","title":"Input/Output","text":"<ul> <li><code>scanf ( format string, input list );</code></li> <li><code>printf ( format string );</code></li> <li><code>printf ( format string, print list );</code></li> </ul>"},{"location":"Year%201%20Semester%202/CS2100/Notes/02%20Overview%20of%20C%20programming/#format-specifiers","title":"Format specifiers","text":"Placeholder Variable Type Function Use %c char printf/ scanf %d int printf / scanf %f float or double printf %f float scanf %if double scanf %e float or double printf (for scientific notation) <ul> <li>Examples of format specifiers used in printf():<ul> <li><code>%5d</code>: to display an integer in a width of 5, right justified</li> <li><code>%8.3f</code>: to display a real number (float or double) in a width of 8, with 3 decimal places, right justified</li> <li>Note: For <code>scanf()</code>, just use the format specifier without indicating width, decimal places, etc.</li> </ul> </li> </ul> <pre><code>int age;\ndouble cap; // cumulative average point\nprintf(\"What are your age and CAP? \");\nscanf(\"%d %lf\", &amp;age, &amp;cap);\nprintf(\"You are %d years old, and your CAP is %f\\n\", age, cap);\n</code></pre> <p>\u201cage\u201d\u00a0\u00a0 refers to value in the variable age. \u201c&amp;age\u201d\u00a0 refers to (address of) the memory cell where the value of age is stored.</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/02%20Overview%20of%20C%20programming/#escape-sequence","title":"Escape sequence","text":"Escape sequence Meaning Result \\n New line Subsequent output will appear on the next line \\t Horizontal tab Move to the next tab position on the current line \\\" Double quote Display a double quote \" \\%% Percent Display a percent character % <p>Escape sequences are used in <code>printf()</code> function for certain special effects or to display certain characters properly</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/02%20Overview%20of%20C%20programming/#compute","title":"Compute","text":""},{"location":"Year%201%20Semester%202/CS2100/Notes/02%20Overview%20of%20C%20programming/#function","title":"Function","text":"<p>A function body has two parts</p> <ul> <li>Declarations statements: tell compiler what type of memory cells needed</li> <li>Executable statements: describe the processing on the memory cells</li> </ul> <pre><code>int main(void) {\n/* declaration statements */\n/* executable statements */\nreturn 0;\n}\n</code></pre>"},{"location":"Year%201%20Semester%202/CS2100/Notes/02%20Overview%20of%20C%20programming/#declaration-statement","title":"Declaration statement","text":"<ul> <li>To declare use of variables</li> <li>eg <code>int count,value;</code></li> </ul>"},{"location":"Year%201%20Semester%202/CS2100/Notes/02%20Overview%20of%20C%20programming/#user-defined-identifier","title":"User-defined Identifier","text":"<ul> <li>Name of a variable or function</li> <li>May consist of letters (a-z, A-Z), digits (0-9) and underscores, but MUST NOT begin with a digit</li> <li>Case sensitive, i.e. count and Count are two distinct identifiers</li> <li>Guideline: Usually should begin with lowercase letter</li> <li>Must not be reserved words (next slide)</li> <li>Should avoid standard identifiers (next slide)</li> </ul>"},{"location":"Year%201%20Semester%202/CS2100/Notes/02%20Overview%20of%20C%20programming/#reserved-words","title":"Reserved Words","text":"<ul> <li>Have special meaning in C</li> <li>Eg: <code>int</code>, <code>void</code>, <code>return</code></li> </ul>"},{"location":"Year%201%20Semester%202/CS2100/Notes/02%20Overview%20of%20C%20programming/#standard-identifiers","title":"Standard identifiers","text":"<ul> <li>Names of common functions, such as <code>printf</code>, <code>scanf</code></li> <li>Avoid naming your variables/functions with the same name of built-in functions you intend to use</li> </ul>"},{"location":"Year%201%20Semester%202/CS2100/Notes/02%20Overview%20of%20C%20programming/#executable-statements","title":"Executable Statements","text":"<ul> <li>I/O statements (eg: printf, scanf)</li> <li>Computational and assignment statements</li> </ul>"},{"location":"Year%201%20Semester%202/CS2100/Notes/02%20Overview%20of%20C%20programming/#assignment-statements","title":"Assignment statements","text":"<ul> <li>Store a value or a computational result in a variable</li> <li>(Note: \u2018=\u2019 means \u2018assign value on its right to the variable on its left\u2019; it does NOT mean equality)</li> <li>Left side of \u2018=\u2019 is called lvalue</li> </ul>"},{"location":"Year%201%20Semester%202/CS2100/Notes/02%20Overview%20of%20C%20programming/#side-effect","title":"Side effect","text":"<p>An assignment statement has the side effect of returning the value of its right-hand side</p> <pre><code>z = a = 12; // or: z = (a = 12);\n</code></pre> <p>The above makes use of the side effect of the assignment statement a = 12; (which returns 12) and assigns it to z</p> <p>Side effects have their use, but avoid convoluted codes:</p> <pre><code>a = 5 + (b = 10); // assign 10 to b, and 15 to a\n</code></pre> <p>Side effects also apply to expressions involving other operators (eg: logical operators).</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/02%20Overview%20of%20C%20programming/#arithmetic-operations","title":"Arithmetic operations","text":"<ul> <li>Binary Operators: <code>+</code>, <code>\u2013</code>, <code>*</code>, <code>/</code>, <code>%</code> (remainder)<ul> <li>Left Associative (from left to right)</li> <li><code>46 / 15 / 2\u00a0\u2192 3 / 2 \u2192 1</code></li> </ul> </li> <li>Unary operators: <code>+</code>, <code>\u2013</code><ul> <li>Right Associative<ul> <li><code>p = +4 * 10</code></li> </ul> </li> </ul> </li> <li>Execution from left to right, respecting parentheses rule, and then precedence rule, and then associative rule<ul> <li>addition, subtraction are lower in precedence than multiplication, division, and remainder</li> <li>Truncate result if result can\u2019t be stored<ul> <li><code>int n; n = 9 * 0.5;</code> result in <code>4</code> being stored in <code>n</code></li> </ul> </li> </ul> </li> </ul>"},{"location":"Year%201%20Semester%202/CS2100/Notes/02%20Overview%20of%20C%20programming/#type-casting","title":"Type casting","text":"<p>Use a cast operator to change the type of an expression. Eg <code>float a = (float) 5/4</code></p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/02%20Overview%20of%20C%20programming/#selection-structures","title":"Selection Structures","text":"<p>C provides two control structures that allow you to select a group of statements to be executed or skipped when certain conditions are met.</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/02%20Overview%20of%20C%20programming/#ifelse","title":"If...else...","text":"<pre><code>if (condition) {\n/* Execute these statements if TRUE */\n}\n</code></pre> <pre><code>if (condition) {\n/* Execute these statements if TRUE\u00a0 */\n}\nelse {\n/* Execute these statements if FALSE */\u00a0}\n</code></pre>"},{"location":"Year%201%20Semester%202/CS2100/Notes/02%20Overview%20of%20C%20programming/#switch","title":"Switch","text":"<pre><code>/* variable or expression must be of discrete type */\nswitch ( &lt;variable or expression&gt; ) {\ncase value1:\nCode to execute if &lt;variable or expr&gt; == value1\nbreak; // If no break, it will continue down the case.\ncase value2:\nCode to execute if &lt;variable or expr&gt; == value2\nbreak;\n...\ndefault:\nCode to execute if &lt;variable or expr&gt; does not\nequal to the value of any of the cases above\nbreak;\n}\n</code></pre>"},{"location":"Year%201%20Semester%202/CS2100/Notes/02%20Overview%20of%20C%20programming/#condition-and-relational-operators","title":"Condition and Relational Operators","text":"Relational Operator Interpretation &lt; is less than &lt;= is less than or equal to &gt; is greater than &gt;= is greater than or equal to == is equal to != is not equal to"},{"location":"Year%201%20Semester%202/CS2100/Notes/02%20Overview%20of%20C%20programming/#truth-values","title":"Truth Values","text":"<p>There is no Boolean type in ANSI C. Instead, we use integers:</p> <ul> <li>0 to represent false</li> <li>Any other value to represent true (1 is used as the representative value for true in output)</li> </ul> <pre><code>int a = (2 &gt; 3);\nint b = (3 &gt; 2);\nprintf(\"a = %d; b = %d\\n\", a, b); //Gives a = 0; b = 1\n</code></pre>"},{"location":"Year%201%20Semester%202/CS2100/Notes/02%20Overview%20of%20C%20programming/#logical-operators","title":"Logical Operators","text":"A B A &amp;&amp; B A || B !A False False False False True False True False True True True False False True False True True True True False"},{"location":"Year%201%20Semester%202/CS2100/Notes/02%20Overview%20of%20C%20programming/#evaluation-of-boolean-expressions","title":"Evaluation of Boolean Expressions","text":"<pre><code>int x, y, z,\na = 4, b = -2, c = 0;\nx = (a &gt; b || b &gt; c &amp;&amp; a == b); // x is true (1) but\n//gcc issues warning due to ambiguity. Use parentheses instead\n</code></pre>"},{"location":"Year%201%20Semester%202/CS2100/Notes/02%20Overview%20of%20C%20programming/#short-circuit-evaluation","title":"Short-Circuit Evaluation","text":"<p>The code below will not cause an error because when the code evaluates <code>a != 0</code> to true, it will not evaluate the next expression. Also known as Lazy evaluation.</p> <pre><code>if ((a != 0) &amp;&amp; (b/a &gt; 3)) {\nprintf(. . .);\n}\n</code></pre> <ul> <li><code>expr1 || expr2</code>: If <code>expr1</code> is true, skip evaluating <code>expr2</code> and return true immediately, as the result will always be true.</li> <li><code>expr1 &amp;&amp; expr2</code>: If <code>expr1</code> is false, skip evaluating <code>expr2</code> and return false immediately, as the result will always be false.</li> </ul>"},{"location":"Year%201%20Semester%202/CS2100/Notes/02%20Overview%20of%20C%20programming/#repetition-structures","title":"Repetition Structures","text":"<p>C provides three control structures that allow you to select a group of statements to be executed repeatedly. white, do white, for</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/02%20Overview%20of%20C%20programming/#break-in-a-loop","title":"Break in a loop","text":"<p>In a nested loop, break only breaks out of the inner-most loop that contains the break statement.</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/02%20Overview%20of%20C%20programming/#continue-in-a-loop","title":"Continue in a loop","text":"<p>In a nested loop, continue only skips to the next iteration of the inner-most loop that contains the continue statement.</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/02%20Overview%20of%20C%20programming/#summary","title":"Summary","text":"<p> Short-Circuit Evaluation </p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/03%20Number%20Systems/","title":"Number Systems","text":""},{"location":"Year%201%20Semester%202/CS2100/Notes/03%20Number%20Systems/#data-representation","title":"Data Representation","text":""},{"location":"Year%201%20Semester%202/CS2100/Notes/03%20Number%20Systems/#basic-data-types-in-c","title":"Basic data types in C:","text":"<p>Data is represented depending on its type. This is why C requires to declare datatype. </p> <p></p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/03%20Number%20Systems/#unit","title":"Unit","text":"<ul> <li>Byte: 8 bits</li> <li>Nibble: 4 bits (rarely used now)</li> <li>Word: Eg in 7694, the digit 7 has the weight of 1000.</li> <li>\\(N\\) bits can represent up to _ \\(2^N\\)_ values</li> <li>To represent \\(M\\) values, \\(\\left\\lceil\\log _2 M\\right\\rceil\\) bits required</li> </ul>"},{"location":"Year%201%20Semester%202/CS2100/Notes/03%20Number%20Systems/#number-system","title":"Number System","text":"<ul> <li>Binary (base 2)<ul> <li>Weights in powers of 2</li> <li>Binary digits (bits): \\(\\mathbf{0 , 1}\\)</li> </ul> </li> <li>Octal (base 8)<ul> <li>Weights in powers of 8</li> <li>Octal digits: \\(\\mathbf{0 , 1}, \\mathbf{2 , 3}, \\mathbf{4 , 5 , 6 , 7 .}\\)</li> </ul> </li> <li>Hexadecimal (base 16)<ul> <li>Weights in powers of 16</li> </ul> </li> <li>Base/radix \\(R\\) :<ul> <li>Weights in powers of \\(R\\)</li> </ul> </li> </ul>"},{"location":"Year%201%20Semester%202/CS2100/Notes/03%20Number%20Systems/#number-representation-of-certain-bases-in-programming-languages","title":"Number representation of certain bases in Programming languages","text":"<p>In programming language C</p> <ul> <li>Prefix 0 for octal. Eg: 032 represents the octal number \\((32)_8\\)</li> <li>Prefix 0x for hexadecimal. Eg: 0x32 represents the hexadecimal number \\((32)_{16}\\)</li> </ul> <p>In QTSpim (a MIPS simulator you will use)</p> <ul> <li>Prefix 0x for hexadecimal. Eg: 0x100 represents the hexadecimal number \\((100)_{16}\\)</li> </ul> <p>In Verilog, the following values are the same</p> <ul> <li>8'b 11110000: an 8-bit binary value 11110000</li> <li>8'h F0: an 8-bit binary value represented in hexadecimal F0</li> <li>8'd 240: an 8-bit binary value represented in decimal 240</li> </ul>"},{"location":"Year%201%20Semester%202/CS2100/Notes/03%20Number%20Systems/#decimal-to-binary-conversion","title":"Decimal to Binary Conversion","text":""},{"location":"Year%201%20Semester%202/CS2100/Notes/03%20Number%20Systems/#repeated-division-by-2","title":"Repeated Division-by-2","text":"<p>To Convert a whole number to binary: \\((43)_{10}=(101011)_2\\)</p> <p></p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/03%20Number%20Systems/#repeated-multiplication-by-2","title":"Repeated Multiplication-by-2","text":"<p>To convert decimal fractions to binary: \\((0.3125)_{10}=(.0101)_2\\) </p> <p></p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/03%20Number%20Systems/#conversion-between-decimal-and-other-bases","title":"Conversion between decimal and other Bases","text":"<ul> <li>Base- \\(R\\) to decimal: multiply digits with their corresponding weights</li> <li>Decimal to binary (base 2)<ul> <li>Whole numbers: repeated division-by-2</li> <li>Fractions: repeated multiplication-by-2</li> </ul> </li> <li>Decimal to base- \\(R\\)<ul> <li>Whole numbers: repeated division-by- \\(R\\)</li> <li>Fractions: repeated multiplication-by- \\(R\\)</li> </ul> </li> </ul>"},{"location":"Year%201%20Semester%202/CS2100/Notes/03%20Number%20Systems/#conversion-between-bases","title":"Conversion Between Bases","text":""},{"location":"Year%201%20Semester%202/CS2100/Notes/03%20Number%20Systems/#ascii-code","title":"ASCII Code","text":"<ul> <li>American Standard Code for Information Interchange</li> <li>7 bits, plus 1 parity bit (odd or even parity</li> </ul> <p>Note: If you want to convert ASCII number to binary number, subtract ASCII 0 from ASCII number. Eg. ASCII 9 to binary 9 is: 0111001-0110000 = 1001</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/03%20Number%20Systems/#negative-numbers","title":"Negative Numbers","text":"<ul> <li>Unsigned numbers: Only non-negative values</li> <li>Signed numbers: include all values (positive and negative)</li> </ul> <p>There are 3 common representations for signed binary numbers</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/03%20Number%20Systems/#sign-and-magnitude","title":"Sign-and-Magnitude","text":"<ul> <li>The sign is represented by a \u2018sign bit\u2019 <ul> <li>0 for +</li> <li>1 for -</li> <li>eg \\(00100001_{sm}\\) (sm is used to indicate sign-and-magnitude)</li> </ul> </li> </ul> <ul> <li>Largest value: 01111111 = \\(+127_{10}\\)</li> <li>Smallest value: 11111111 = \\(-127_{10}\\)</li> <li>Zeros: 00000000 = \\(+0_{10}\\), 100000000 = \\(-0_{10}\\)</li> <li>Range (for 8-bit): \\(-127_{10}\\) to +\\(127_{10}\\)</li> </ul> <p>This is method is not good for arithmetic</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/03%20Number%20Systems/#1s-complement","title":"1s Complement","text":"<p>Given a binary \\(x\\). its negated value can be obtained in 1s-complement by inverting the bits.</p> <ul> <li>Largest value: \\(\\quad 01111111=+127_{10}\\)</li> <li>Smallest value: \\(\\quad 10000000=-127_{10}\\)</li> <li>Zeros: \\(\\quad 00000000=+0_{10}\\) \\(11111111=-0_{10}\\)</li> <li>Range (for 8 bits): \\(-127_{10}\\) to \\(+127_{10}\\)</li> <li>Range (for \\(n\\) bits): \\(-\\left(2^{n-1}-1\\right)\\) to \\(2^{n-1}-1\\)</li> <li>The most significant bit (MSB) still represents the sign: 0 for positive, 1 for negative.</li> </ul>"},{"location":"Year%201%20Semester%202/CS2100/Notes/03%20Number%20Systems/#2s-complement","title":"2s Complement","text":"<p>Given a binary \\(x\\), its negated value can be obtained in 2s-complement representation using:</p> <p>\\(\\(-x=2^n-x\\)\\) Or, invert the bits and add 1.</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/03%20Number%20Systems/#complement-on-fractions","title":"Complement on Fractions","text":"<p>We can extend the idea of complement on fractions.</p> <ul> <li>Negate \\(0101.01\\) in 1s-complement   Answer: \\(1010.10\\)</li> <li>Negate \\(0101.01\\) in 2s-complement   Answer: \\(1010.11\\)</li> </ul>"},{"location":"Year%201%20Semester%202/CS2100/Notes/03%20Number%20Systems/#2s-complement-on-additionsubtraction","title":"2s Complement on Addition/Subtraction","text":"<p>Algorithm for addition of integers, \\(A+B\\) :</p> <ol> <li>Perform binary addition on the two numbers.</li> <li>Ignore the carry out of the MSB.</li> <li>Check for overflow. Overflow occurs if the 'carry in' and 'carry out' of the MSB are different, or if result is opposite sign of \\(A\\) and \\(B\\).</li> </ol> <p>Algorithm for subtraction of integers, \\(A-B=A+(-B)\\)</p> <ol> <li>Take 2s-complement of  B.</li> <li>Add the 2 s-complement of \\(B\\) to \\(A\\).</li> </ol>"},{"location":"Year%201%20Semester%202/CS2100/Notes/03%20Number%20Systems/#overflow","title":"Overflow","text":"<p>Example: 4-bit 2s-complement system</p> <ul> <li>Range of value: \\(-8_{10}\\) to \\(7_{10}\\)</li> <li>\\(0101_{2 \\mathrm{~s}}+0110_{2 \\mathrm{~s}}=1011_{2 \\mathrm{~s}}\\) \\(5_{10}+6_{10}=-5_{10}\\) ?! (overflow!)</li> <li>\\(1001_{2 \\mathrm{~s}}+1101_{2 \\mathrm{~s}}=10110_{2 \\mathrm{~s}}\\) (discard end-carry) \\(=0110_{2 \\mathrm{~s}}\\) \\(-7_{10}+-3_{10}=6_{10}\\) ?! (overflow!)</li> </ul>"},{"location":"Year%201%20Semester%202/CS2100/Notes/03%20Number%20Systems/#1s-complement-on-additionsubtraction","title":"1s Complement on Addition/Subtraction","text":"<p>Algorithm for addition of integers, \\(A+B\\) :</p> <ol> <li>Perform binary addition on the two numbers.</li> <li>If there is a carry out of the MSB, add 1 to the result.</li> <li>Check for overflow. Overflow occurs if result is opposite sign of \\(A\\) and \\(B\\).</li> </ol> <p>Algorithm for subtraction of integers, \\(A-B=A+(-B)\\)</p> <ol> <li>Take 1s-complement of \\(B\\).</li> <li>Add the \\(1 \\mathrm{~s}\\)-complement of \\(\\mathrm{B}\\) to \\(\\mathrm{A}\\).</li> </ol>"},{"location":"Year%201%20Semester%202/CS2100/Notes/03%20Number%20Systems/#excess-representation","title":"Excess Representation","text":""},{"location":"Year%201%20Semester%202/CS2100/Notes/03%20Number%20Systems/#real-numbers","title":"Real Numbers","text":"<p>Due to the finite number of bits, real number are often represented in their approximate values.</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/03%20Number%20Systems/#fixed-point-representation","title":"Fixed Point Representation","text":"<p>Eg \\(011010.11_{2 \\mathrm{~s}}=26.75_{10}\\)</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/03%20Number%20Systems/#floating-point-representation","title":"Floating-Point Representation","text":"<p>Allow to represent very large or very small numbers</p> <p>Examples:</p> <ul> <li>\\(0.23 \\times 10^{23}\\) (very large positive number)</li> <li>\\(0.5 \\times 10^{-37}\\) (very small positive number)</li> <li>\\(-0.2397 \\times 10^{-18}\\) (very small negative number)</li> </ul>"},{"location":"Year%201%20Semester%202/CS2100/Notes/03%20Number%20Systems/#ieee-754-floating-point-rep","title":"IEEE 754 Floating-Point Rep","text":""},{"location":"Year%201%20Semester%202/CS2100/Notes/04%20Pointers%20and%20Functions/","title":"Pointers and Functions","text":""},{"location":"Year%201%20Semester%202/CS2100/Notes/04%20Pointers%20and%20Functions/#pointers","title":"Pointers","text":"<p>Note from: Lect4a_Pointers_and_Functions 1</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/04%20Pointers%20and%20Functions/#referring-to-the-address","title":"Referring to the address","text":"<pre><code>int a = 123;\nprintf(\"a= %d\\n\", a); //a = 123\nprintf(\"&amp;a = %p\\n\", &amp;a); //&amp;a = ffbff7dc\n</code></pre>"},{"location":"Year%201%20Semester%202/CS2100/Notes/04%20Pointers%20and%20Functions/#declaring-pointer-variable","title":"Declaring Pointer variable","text":"<p>Syntax: <code>type *pointer_name;</code></p> <pre><code>int *a_ptr;\n</code></pre>"},{"location":"Year%201%20Semester%202/CS2100/Notes/04%20Pointers%20and%20Functions/#assigning-value-to-a-pointer","title":"Assigning Value to a Pointer","text":"<p>Example: Assigning address <code>a</code> to <code>a_ptr</code></p> <pre><code>int a = 123;\nint *a_ptr; // declaring an int pointer\na_ptr = &amp;a;\n</code></pre>"},{"location":"Year%201%20Semester%202/CS2100/Notes/04%20Pointers%20and%20Functions/#accessing-variable-through-pointer","title":"Accessing Variable Through Pointer","text":"<pre><code>printf(\"a = %d\\n\", *a_ptr); // Is equiv to printf(\"a = %d\\n\", a);\n</code></pre>"},{"location":"Year%201%20Semester%202/CS2100/Notes/04%20Pointers%20and%20Functions/#incrementing-a-pointer","title":"Incrementing a Pointer","text":""},{"location":"Year%201%20Semester%202/CS2100/Notes/04%20Pointers%20and%20Functions/#functions","title":"Functions","text":""},{"location":"Year%201%20Semester%202/CS2100/Notes/04%20Pointers%20and%20Functions/#how-to-use-math-functions","title":"How to use math functions","text":"<p>To use math functions, you need to</p> <ul> <li>Include <code>&lt;math.h&gt;</code> AND</li> <li>Compile your program with <code>-lm</code> option (i.e. <code>gcc -lm ...</code>)</li> </ul> Function Arguments Result abs (x) int int ceil(x) double double cos(x) double (radians) double exp(x) double double fabs (x) double double floor(x) double double log(x) double double log 10(x) double double ceil(x) double double pow(x,y) double, double double sin(x) double (radians) double sqr(x) double double tan(x) double (radians) double"},{"location":"Year%201%20Semester%202/CS2100/Notes/04%20Pointers%20and%20Functions/#user-defined-functions","title":"User-Defined Functions","text":""},{"location":"Year%201%20Semester%202/CS2100/Notes/04%20Pointers%20and%20Functions/#passing-structure-to-function","title":"Passing Structure to Function","text":""},{"location":"Year%201%20Semester%202/CS2100/Notes/04%20Pointers%20and%20Functions/#strings","title":"Strings","text":"<ul> <li>We can turn an array of characters into a string by adding a null character <code>\\0</code> at the end of the array</li> <li>A string is an array of characters, terminated by a null character <code>\\0</code> (which has an ASCII value of zero)</li> <li>We can use string functions (include <code>&lt;string.h&gt;</code>) to manipulate strings.</li> </ul>"},{"location":"Year%201%20Semester%202/CS2100/Notes/04%20Pointers%20and%20Functions/#basic","title":"Basic","text":"<p>Declaration of an array of characters</p> <ul> <li><code>char str[6]</code>;</li> </ul> <p>Assigning character to an element of an array of characters</p> <ul> <li><code>str[0] = 'e';</code></li> <li><code>str[1] = 'g';</code></li> <li><code>str[2] = 'g';</code></li> <li><code>str[3] = '\\0';</code></li> </ul> <p>Initializer for string</p> <ul> <li><code>char fruit_name[] = \"apple\"; // double quote produces a string followed by a null terminator (ie \\0)</code></li> <li><code>char fruit_name[] = {'a','p','p','l','e','\\0'};</code></li> </ul>"},{"location":"Year%201%20Semester%202/CS2100/Notes/04%20Pointers%20and%20Functions/#read-strings-from-stdin","title":"Read Strings from stdin","text":""},{"location":"Year%201%20Semester%202/CS2100/Notes/04%20Pointers%20and%20Functions/#read","title":"Read","text":"<pre><code>fgets(str, size, stdin) // reads size \u2013 1 char,\n// or until newline\n// This stores \\n also in the array \n// Remove by changing len-1 to \\0\nscanf(\"%s\", str);\u00a0 // reads until white space\n</code></pre>"},{"location":"Year%201%20Semester%202/CS2100/Notes/04%20Pointers%20and%20Functions/#print","title":"Print","text":"<pre><code>puts(str);\u00a0 // terminates with newline\nprintf(\"%s\\n\", str);\n</code></pre>"},{"location":"Year%201%20Semester%202/CS2100/Notes/04%20Pointers%20and%20Functions/#string-functions","title":"String Functions","text":""},{"location":"Year%201%20Semester%202/CS2100/Notes/05%20Arrays%20String%20and%20Structures/","title":"Arrays String and Structures","text":""},{"location":"Year%201%20Semester%202/CS2100/Notes/05%20Arrays%20String%20and%20Structures/#arrays","title":"Arrays","text":"<pre><code>int a[3] = {54,9,10};\n</code></pre>"},{"location":"Year%201%20Semester%202/CS2100/Notes/05%20Arrays%20String%20and%20Structures/#scanning-and-printing-elements","title":"Scanning and printing elements","text":"<pre><code>#include &lt;stdio.h&gt;\n#define MAX 5\nint main(void) {\nint numbers[MAX];\nint i, sum = 0;\nprintf(\"Enter %d integers: \", MAX);\nfor (i = 0; i &lt; MAX; i++) {\nscanf(\"%d\", &amp;numbers[i]); // Use the address.\n}\nfor (i = 0; i &lt; MAX; i++) {\nsum += numbers[i];\n}\nprintf(\"Sum = %d\\n\", sum);\nreturn 0;\n}\n</code></pre>"},{"location":"Year%201%20Semester%202/CS2100/Notes/05%20Arrays%20String%20and%20Structures/#arrays-and-pointers","title":"Arrays and Pointers","text":""},{"location":"Year%201%20Semester%202/CS2100/Notes/05%20Arrays%20String%20and%20Structures/#copy-array-to-another","title":"Copy array to another","text":"<pre><code>#define N 10\nint source[N] = { 10, 20, 30, 40, 50 }; // dest = source will not work\nint dest[N];\nint i;\nfor (i = 0; i &lt; N; i++) {\ndest[i] = source[i];\n}\n</code></pre>"},{"location":"Year%201%20Semester%202/CS2100/Notes/05%20Arrays%20String%20and%20Structures/#array-parameters-in-functions","title":"Array parameters in Functions","text":"<p>Array passed into a method is a pointer. Changing the array in the method will change the array itself.</p> <p>Since an array name is a pointer, the following shows the alternative syntax for array parameter in function prototype and function header in the function definition.</p> <pre><code>int sumArray(int *, int); // fn prototype\n// function definition\nint sumArray(int *arr, int size) {\n...\n}\n</code></pre>"},{"location":"Year%201%20Semester%202/CS2100/Notes/05%20Arrays%20String%20and%20Structures/#structures","title":"Structures","text":"<p>Structures allow grouping of heterogeneous members (of different types)</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/05%20Arrays%20String%20and%20Structures/#declaring-structure-types","title":"Declaring Structure Types","text":""},{"location":"Year%201%20Semester%202/CS2100/Notes/05%20Arrays%20String%20and%20Structures/#initializing-structure-variables","title":"initializing Structure Variables","text":""},{"location":"Year%201%20Semester%202/CS2100/Notes/05%20Arrays%20String%20and%20Structures/#passing-structure-to-function","title":"Passing Structure to Function","text":"<p>The entire structure is copied, i.e., members of the actual parameter are copied into the corresponding members of the formal parameter. Pass-by-value.</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/05%20Arrays%20String%20and%20Structures/#passing-address-of-structure-to-function","title":"Passing Address of Structure to Function","text":""},{"location":"Year%201%20Semester%202/CS2100/Notes/05%20Arrays%20String%20and%20Structures/#the-arrow-operator","title":"The Arrow Operator","text":"<p>Expressions like <code>(*player_ptr).name</code> appear very often. Hence an alternative \u201cshortcut\u201d syntax is created for it.  The arrow operator (<code>-&gt;</code>)</p> <pre><code>// To change a player\u2019s name and age \nvoid change_name_and_age(player_t *player_ptr) { strcpy(player_ptr-&gt;name, \"Alexandra\"); player_ptr-&gt;age = 25; }\n</code></pre>"},{"location":"Year%201%20Semester%202/CS2100/Notes/07-9%20MIPS/","title":"MIPS","text":""},{"location":"Year%201%20Semester%202/CS2100/Notes/07-9%20MIPS/#contents","title":"Contents","text":"<p>Instruction set architecture Machine Code vs Assembly Language The code in action General purpose Registers MIPS Assembly Language Logical operations Shifting Logical Operations And OR How to Load Large Constant Memory Organisation Transfer Unit Word Alignment Memory Instruction Load &amp; Word Making Decisions </p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/07-9%20MIPS/#j-format-example","title":"J format - Example","text":"<p>To calculate the target address.  Ignore last 2 bits and first 4 bits. Add 4 bits of PC </p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/10%20ISA/","title":"ISA","text":""},{"location":"Year%201%20Semester%202/CS2100/Notes/10%20ISA/#fixed-length-instruction","title":"Fixed length instruction","text":"<p>Type A: 6 opcode 5 operand 5 operand Type B: 11 opcode 5 operand</p> <p>To maximise,eg reserve 111111 for Type A. Then the total combination of Type B is \\((2^6-1)\\times 2^5\\). \\(2^6-1\\) represent the total number of combination of the first  6 bits in Type B as one of the combination is used by Type A.</p> <p>To minimise eg reserve 111111 for Type B. The the total combination of Type B is \\(2^5\\)</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/11%20Datapath/","title":"The Processor: Datapath","text":""},{"location":"Year%201%20Semester%202/CS2100/Notes/11%20Datapath/#instruction-execution-cycle-overview","title":"Instruction Execution Cycle Overview","text":"<ol> <li>Fetch</li> <li>Decode</li> <li>Operand Fetch</li> <li>Execute</li> <li>Result Write (Store)</li> </ol> <p>Example in MIPS</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/11%20Datapath/#fetch-stage","title":"Fetch Stage","text":"<ol> <li>Use the PC to fetch the instruction from memory<ol> <li>PC is a special register in the processor</li> </ol> </li> <li>Increment the PC by 4 (size of instruction) to get the next instruction </li> </ol> <p>Details on the components used in the fetch stage</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/11%20Datapath/#decode-stage","title":"Decode Stage","text":"<ul> <li>Use the 32-bit instruction passed by the fetch stage</li> <li>Read the opcode</li> <li>Read the data from the registers</li> </ul> <p>Details</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/11%20Datapath/#reg-file","title":"Reg File","text":"<p>This is a control signal to indicate</p> <ul> <li>writing of register</li> <li>1 (True) = Write, 0 (False) = No Write</li> </ul> <p>Example</p> <ul> <li>Here, addresses of the register are passed into the Read register 1, 2. </li> <li>The contents of these register are passed from the Read data 1, 2 to the ALU</li> <li>Then, the output of ALU is passed to the Write data.</li> </ul> <p>Note that for immediate instruction eg. addi, Multiplexer is used to put the register address to the correct register in the register file.</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/11%20Datapath/#alu-stage","title":"ALU Stage","text":"<p>Also called the Execution stage</p> <p>Block Diagram</p> <p>Example of a Non Branch Instruction Example of a Branch Instruction</p> <p>The PCSource is determined with \\(beq \\cap iszero\\)</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/11%20Datapath/#memory-stage","title":"Memory Stage","text":"<p>Block Diagram</p> <p>Example</p> <p>REMEMBER that MemToReg is upside down. Input 1 is on top and input 0 is below. </p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/11%20Datapath/#register-write-stage","title":"Register Write Stage","text":"<p>Block Diagram</p> <p>Example</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/12%20Control/","title":"Control","text":"<p>Lecture PDF</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/12%20Control/#alu-control","title":"ALU Control","text":"<p>For <code>subtract</code>, the adder performs <code>A+B'+1</code>. The 1 is from <code>Cin</code>, hence turning \\(B\\) into two's complement.</p> <p>For <code>NOR</code>, the <code>AND</code> gate performs \\(A'\\cap b'\\) which is equivalent to \\((A+B)'\\) (De morgan's law)</p> <p><code>slt</code> will not be discussed. (may come out in assessment)</p> <p>PDF</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/12%20Control/#design-of-alu-control-unit-multilevel-decoding","title":"Design of ALU control unit: Multilevel Decoding","text":"<p>PDF</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/13%20Boolean%20Algebra/","title":"Boolean Algebra","text":""},{"location":"Year%201%20Semester%202/CS2100/Notes/13%20Boolean%20Algebra/#precedence-of-operators","title":"Precedence of Operators","text":"<ol> <li>Not</li> <li>And</li> <li>Or</li> </ol> <p>Use parenthesis to overwrite precedence</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/13%20Boolean%20Algebra/#proof-using-truth-table","title":"Proof using Truth Table","text":"<p>Use truth table to show the two results are the same. Visit PDF</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/13%20Boolean%20Algebra/#laws-of-boolean-algebra","title":"Laws of Boolean Algebra","text":""},{"location":"Year%201%20Semester%202/CS2100/Notes/13%20Boolean%20Algebra/#duality","title":"Duality","text":"<p>Switching <code>AND</code> and <code>OR</code> remains the equation valid</p> <p>The dual equation of </p> \\[a+(b \\cdot c)=(a+b) \\cdot(a+c)$$ is $$a \\cdot(b+c)=(a \\cdot b)+(a \\cdot c)\\]"},{"location":"Year%201%20Semester%202/CS2100/Notes/13%20Boolean%20Algebra/#theorems","title":"Theorems","text":""},{"location":"Year%201%20Semester%202/CS2100/Notes/13%20Boolean%20Algebra/#boolean-functions","title":"Boolean Functions","text":"<p>Visit PDF</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/13%20Boolean%20Algebra/#complement-functions","title":"Complement Functions","text":"<p>Visit PDF</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/13%20Boolean%20Algebra/#standard-forms","title":"Standard Forms","text":"<p>Certain types of Boolean expressions lead to circuits that are desirable from an implementation viewpoint.</p> <p>There are two standard forms: - Sum-of-Products (SOP) expression - Product-of-Sums (POS) expression</p> <p>Every boolean expression can be expressed in SOP or POS form.</p> <p>First lets start with the basic terms:</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/13%20Boolean%20Algebra/#literals","title":"Literals","text":"<ul> <li>A boolean variable on its own or in its complemented form</li> <li>Example: \\(x\\), \\(x'\\)</li> </ul>"},{"location":"Year%201%20Semester%202/CS2100/Notes/13%20Boolean%20Algebra/#product-term","title":"Product term","text":"<ul> <li>A single literal or a logical product (<code>AND</code>) of several literals</li> <li>Examples: \\(x,x \\cdot y \\cdot z',A' \\cdot B\\)</li> </ul>"},{"location":"Year%201%20Semester%202/CS2100/Notes/13%20Boolean%20Algebra/#sum-term","title":"Sum term","text":"<ul> <li>A single literal or a logical sum (<code>OR</code>) of several literals</li> <li>Examples: \\(x,x+y+z,A'+B\\)</li> </ul>"},{"location":"Year%201%20Semester%202/CS2100/Notes/13%20Boolean%20Algebra/#sum-of-products-sop-expression","title":"Sum-of-Products (SOP) expression","text":"<ul> <li>A product term or a logical sum (OR) of several product terms</li> <li>Examples \\(x,x+y \\cdot z'\\)</li> </ul>"},{"location":"Year%201%20Semester%202/CS2100/Notes/13%20Boolean%20Algebra/#product-of-sums-pos-expression","title":"Product-of-Sums (POS) expression","text":"<ul> <li>A sum term or a logical product (AND) of several sum terms</li> <li>Examples \\(x,x \\cdot(x+z'),(x+y) \\cdot (x'+y+z)\\)</li> </ul> <p>Quiz PDF</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/13%20Boolean%20Algebra/#minterms-and-maxterms","title":"Minterms and Maxterms","text":"<p>Visit </p> <p></p> <p>Each minterm is the complement of its corresponding maxterm.</p> <p>Example : PDF</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/13%20Boolean%20Algebra/#how-to-convert-boolean-expression-to-minterm-and-maxterm","title":"How to convert Boolean expression to Minterm and Maxterm.","text":"<p>Take (1) from Minterm. Represent the expression into binary by setting complement to 0 and the others to 1. This gives \\(A' \\cdot B' \\cdot C \\cdot D \\to 0011\\). Which in decimal is 3. Hence the minterm notation is m3. </p> <p>For Maxterm, do the opposit by setting the complement to 1.</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/13%20Boolean%20Algebra/#canonical-forms","title":"Canonical Forms","text":"<p>A unique form of representation</p> <ul> <li>Sum-of-minterms = Canonical sum-of-products</li> <li>Product-of-maxterms = Canonical product-ofsums</li> </ul>"},{"location":"Year%201%20Semester%202/CS2100/Notes/13%20Boolean%20Algebra/#sum-of-minterms","title":"Sum-of-Minterms","text":"<p>Visit PDF</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/13%20Boolean%20Algebra/#product-of-maxterms","title":"Product-of-Maxterms","text":"<p>Visit PDF</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/13%20Boolean%20Algebra/#conversion-of-standard-forms","title":"Conversion of Standard Forms","text":"\\[\\mathrm{F} 2=\\Sigma \\mathrm{m}(1,4,5,6,7)=\\Pi \\mathrm{M}(0,2,3)\\] <p>We see that the list of \\(\\Pi \\mathrm{M}(0,2,3)\\) is complementary to \\(\\Sigma \\mathrm{m}(1,4,5,6,7)\\).</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/14%20Logic%20Circuits/","title":"Logic Circuits","text":""},{"location":"Year%201%20Semester%202/CS2100/Notes/14%20Logic%20Circuits/#logic-gates","title":"Logic Gates","text":"<p>Symbols PDF</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/14%20Logic%20Circuits/#logic-circuits_1","title":"Logic Circuits","text":"<p>Fan-in : the number of inputs of a gate</p> <p>Visit PDF</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/14%20Logic%20Circuits/#universal-gates","title":"Universal Gates","text":"<p>Visit PDF</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/14%20Logic%20Circuits/#sop-and-nand-circuits","title":"SOP and NAND Circuits","text":"<p>Visit PDF. Note that the inverter is not considered a level as it is a literal.</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/14%20Logic%20Circuits/#pos-and-nor-circuits","title":"POS and NOR Circuits","text":"<p>Visit PDF</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/14%20Logic%20Circuits/#simplified-representation","title":"Simplified representation","text":"<p>Visit PDF</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/15%20Simplification/","title":"Simplification","text":""},{"location":"Year%201%20Semester%202/CS2100/Notes/15%20Simplification/#half-adder","title":"Half Adder","text":"<p>Half adder is a circuit that adds 2 single bits (X,Y) to produce a result of 2 bits (C,S)</p> <p>Visit PDF</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/15%20Simplification/#gray-code","title":"Gray Code","text":"<ul> <li>Only a single bit change from one value to the next</li> </ul>"},{"location":"Year%201%20Semester%202/CS2100/Notes/15%20Simplification/#generating-a-gray-code-sequence","title":"Generating a Gray code sequence:","text":"<p>Start with: $$\\begin{align} 0000 \\ 0001 \\ \\end{align} $$</p> <p>Make a mirror image:</p> \\[\\begin{align} 0000 \\\\ 0001 \\\\ 0001 \\\\ 0000 \\end{align} \\] <p>Change the second image to the right</p> \\[\\begin{align} 0000 \\\\ 0001 \\\\ 0011 \\\\ 0010 \\end{align} \\] <p>Make a mirror image again and change the third bit to the right. Repeat.</p> <p>Visit PDF</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/15%20Simplification/#karnaugh-map-k-map","title":"Karnaugh-map (K-map)","text":"<p>Karnaugh-map (K-map) is an abstract form of Venn diagram, organised as a matrix of squares, where</p> <ul> <li>Each square represents a minterm</li> <li>Two adjacent squares represent minterms that differ by exactly one literal</li> </ul> <p>Visit PDF</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/15%20Simplification/#how-to-use-k-maps","title":"How to use K-maps","text":"<p>Visit PDF</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/15%20Simplification/#pls-and-epis","title":"Pls and EPIs","text":"<p>Visit PDF</p> <p>max size = 4</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/15%20Simplification/#finding-simplified-sop-expression","title":"Finding simplified SOP Expression","text":"<p>Visit PDF</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/15%20Simplification/#finding-simplified-pos-expression","title":"Finding simplified POS Expression","text":"<p>Visit PDF</p> <p>Start with F' (complement) Apply the K-map technique Complement the boolean expression obtained</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/15%20Simplification/#dont-care-conditions","title":"Don't-Care Conditions","text":"<p>Visit PDF</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/17%20Combinational%20Circuits/","title":"Combinational Circuits","text":""},{"location":"Year%201%20Semester%202/CS2100/Notes/17%20Combinational%20Circuits/#introduction","title":"Introduction","text":""},{"location":"Year%201%20Semester%202/CS2100/Notes/17%20Combinational%20Circuits/#analysis-procedure","title":"Analysis Procedure","text":"<p>Given a combinational circuits, how do you analyze its function?</p> <ol> <li>Label the inputs and outputs</li> <li>Obtain the functions of intermediate points and the outputs</li> <li>Draw the truth table</li> <li>Deduce the functionality of the circuit</li> </ol> <p>Visit PDF</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/17%20Combinational%20Circuits/#design-methods","title":"Design Methods","text":"<p>Two different design methods for combinational circuit:</p> <ul> <li>Gate-level design method (with logic gates)</li> <li>Block-level design method (with functional blocks)</li> </ul> <p>Visit PDF</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/17%20Combinational%20Circuits/#gate-level-ssi-design","title":"Gate-level (SSI) Design","text":"<p>Half Adder Full Adder BCD to Excess-3</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/17%20Combinational%20Circuits/#block-level-design","title":"Block-Level Design","text":"<p>More complex circuits can also be built using block-level method</p> <p>4-bit parallel adder BCD to Excess-3</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/17%20Combinational%20Circuits/#summary","title":"Summary","text":"<p>Visit PDF</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/17%20Combinational%20Circuits/#magnitude-comparator","title":"Magnitude Comparator","text":"<p>Magnitude comparator: compares 2 unsigned values \\(A\\) and \\(B\\), to check if \\(A&gt;B, A=B\\), or \\(A&lt;B\\).</p> <p>Visit PDF</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/17%20Combinational%20Circuits/#circuit-delays","title":"Circuit Delays","text":"<p>Given a logic gate with delay \\(t\\). If inputs are stable at times \\(t_1, t_2, \\ldots, t_n\\), then the earliest time in which the output will be stable is: $$ \\max \\left(t_1, t_2, \\ldots, t_n\\right)+t $$</p> <p>Visit PDF</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/17%20Combinational%20Circuits/#propagation-delay","title":"Propagation delay","text":"<p>Visit PDF</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/18%20MSI%20Components/","title":"MSI Components","text":""},{"location":"Year%201%20Semester%202/CS2100/Notes/18%20MSI%20Components/#introduction","title":"Introduction","text":"<p>MIS: Medium scale integration</p> <p>Four Common and useful MSI circuits:</p> <ul> <li>Decode</li> <li>Demultiplexer</li> <li>Encoder</li> <li>Multiplexer</li> </ul> <p>Visit PDF</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/18%20MSI%20Components/#decoder","title":"Decoder","text":"<ul> <li>Codes are frequently used to represent entities, eg: your name is a code to denote yourself (an entity!)</li> <li>These codes can be identified (or decoded) using a decoder. Given a code, identify the entity.</li> <li>Convert binary information from \\(n\\) input lines to (a maximum of) \\(2^n\\) output lines.</li> <li>Known as \\(n\\)-to- \\(m\\)-line decoder, or simply \\(n: m\\) or \\(n \\times m\\) decoder \\(\\left(m \\leq 2^n\\right)\\).</li> <li>May be used to generate \\(2^n\\) minterms of \\(n\\) input variables.</li> </ul> <p>Visit PDF </p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/18%20MSI%20Components/#using-decoder-to-implement-full-adder","title":"Using Decoder to implement Full adder","text":"<p>Visit PDF </p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/18%20MSI%20Components/#decoder-with-enable","title":"Decoder with Enable","text":"<p>Decoders often come with an enable control signal, so that the device is only activated when the enable, \\(E=1\\).</p> <p>In most MSI decoders, enable signal is zero-enable, usually denoted by \\(\\mathrm{E}^{\\prime}\\) or \\(\\bar{E}\\). The decoder is enabled when the signal is zero (low).</p> <p>Visit PDF </p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/18%20MSI%20Components/#constructing-larger-decoders","title":"Constructing Larger Decoders","text":"<p>Visit PDF </p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/18%20MSI%20Components/#standard-msi-decoder","title":"Standard MSI Decoder","text":"<p>Has negated output!</p> <p>Visit PDF </p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/18%20MSI%20Components/#implementing-functions","title":"Implementing Functions","text":"<p>Visit PDF</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/18%20MSI%20Components/#encoders","title":"Encoders","text":"<p>Visit PDF</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/18%20MSI%20Components/#priority-encoder","title":"Priority Encoder","text":"<p>A priority encoder is one with priority</p> <ul> <li>If two or more inputs or equal to 1 , the input with the highest priority takes precedence.</li> <li>If all inputs are 0, this input combination is considered invalid.</li> </ul> <p>Visit PDF</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/18%20MSI%20Components/#multiplexers-and-demultiplexers","title":"Multiplexers and Demultiplexers","text":"<p>Visit PDF</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/18%20MSI%20Components/#demultiplexers","title":"Demultiplexers","text":"<ul> <li>It turns out that the demultiplexer circuit is actually identical to a decoder with enable.</li> </ul> <p>Visit PDF</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/18%20MSI%20Components/#multiplexers","title":"Multiplexers","text":"<p>Visit PDF</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/18%20MSI%20Components/#multiplexer-ic-package","title":"Multiplexer IC Package","text":"<p>Visit PDF</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/18%20MSI%20Components/#constructing-larger-multiplexers","title":"Constructing Larger Multiplexers","text":"<p>Visit PDF</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/18%20MSI%20Components/#standard-msi-multiplexer","title":"Standard MSI Multiplexer","text":"<p>w is just the complement of y</p> <p>Visit PDF</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/18%20MSI%20Components/#implementing-functions-using-multiplexers","title":"Implementing Functions using Multiplexers","text":"<p>Visit PDF</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/18%20MSI%20Components/#using-smaller-multiplexers","title":"Using Smaller Multiplexers","text":"<ul> <li>Earlier, we saw how a \\(2^n\\)-to-1 multiplexer can be used to implement a Boolean function of \\(n\\) (input) variables.</li> <li>However, we can use a single smaller \\(2^{(n-1)}\\)-to-1 multiplexer to implement a Boolean function of \\(n\\) (input) variables.</li> </ul> <p>Visit PDF</p> <p>Here, the grouping is done by A and B. eg A = 0, B = 0 is grouped together. A = 0, B = 1 is grouped together. See tut08 Q1 for example. </p> <p>Choose the Most significant bit for selectors because they are easily grouped together.</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/19%20Sequential%20Logic/","title":"Sequential Logic","text":""},{"location":"Year%201%20Semester%202/CS2100/Notes/19%20Sequential%20Logic/#introduction","title":"Introduction","text":"<p>Two types of sequential circuits:</p> <ul> <li>Synchronous: outputs change only at specific time</li> <li>Asynchronous: outputs change at any time</li> </ul> <p>Multivibrator: a class of sequential circuits</p> <ul> <li>Bistable (2 stable states)</li> <li>Monostable or one-shot ( 1 stable state)</li> <li>Astable (no stable state)</li> </ul> <p>Bistable logic devices</p> <ul> <li>Latches and flip-flops.</li> <li>They differ in the methods used for changing their state.</li> </ul> <p>We will only be looking at Bistable logic devices</p> <p>Visit PDF</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/19%20Sequential%20Logic/#memory-elements","title":"Memory Elements","text":"<p>Memory element: a device which can remember value indefinitely, or change value on command from its inputs.</p> <p>\\(Q(t)\\) is the current value that the memory element remembers. \\(Q(t+1)\\) is the next state of the memory element.</p> <p>Visit PDF</p> <p>Memory element with clock</p> <p>The command is only effective at a particular time. Usually it is at the rising edge (Positive edges) or the falling edge (Negative edge)</p> <p>Visit PDF</p> <p>Two types of triggering activation</p> <ul> <li>If the value is taken in the positive/negative edges, it is called Edge-triggered</li> <li>If the value is taken at a particular level such as the high level, it is called Pulse triggered</li> </ul> <p>High level is the upper horizontal sections on the pdf.</p> <p>The Edge-triggered memory elements are called Flip-flops.</p> <p>The Pulsed triggered memory elements are called Latches and it is active when the clock is in the <code>On</code> stage.</p> <p>Visit PDF</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/19%20Sequential%20Logic/#s-r-latch","title":"S-R Latch","text":"<p>Pulse triggered. It has two inputs S (set) and R (reset).</p> <p>There are two complementary outputs Q and Q'.</p> <ul> <li>When \\(Q\\) = High we say latch is in SET state. Achieved by \\(R = Low\\) and \\(S=High\\)</li> <li>When \\(Q\\) = Low, we say latch is in RESET state Achieved by \\(R = High\\) and \\(S=Low\\)</li> </ul> <p>When both \\(R\\) and \\(S\\) are LOW, there is no change in output \\(Q\\). When both \\(R\\) and \\(S\\) are HIGH, it is a invalid case and must be avoided (Drawback).</p> <p>Visit PDF Visit Diagram Visit Characteristic table</p> <p>Optional Active Low</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/19%20Sequential%20Logic/#gated-s-r-latach","title":"Gated S-R Latach","text":"<p>This is a standard S-R Latch with enable input (EN) and 2 NAND gates</p> <p></p> <p>Outputs change only when EN is high.</p> <p>Visit PDF</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/19%20Sequential%20Logic/#gated-d-latch","title":"Gated D Latch","text":"<p>Replace \\(R\\) with \\(S'\\). \\(D\\) latch eliminates the undesirable condition of invalid state  in S-R latch.</p> <p></p> <p>Visit Characteristic Table</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/19%20Sequential%20Logic/#flip-flops","title":"Flip-flops","text":"<p>Edge triggered.</p> <ul> <li>Flip-flops are synchronous bistable devices.</li> <li>Output changes state at a specified point on a triggering input called the clock.</li> <li>Change state either at the positive (rising) edge, or at the negative (falling) edge of the clock signal.</li> </ul> <p>Visit PDF</p> <p></p> <p>The \\(&gt;\\) notation implies a edge triggered device.</p> <p>Visit PDF</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/19%20Sequential%20Logic/#d-flip-flop","title":"D Flip-flop","text":"<p>Same as D-Latch Except that we follow the rising edge of the clock rather than the enable. </p> <p>Visit PDF</p> <p>Application: . In this example, when we want to copy over \\(x,y,z\\) to the flip flop, we pulse the clock. Then on the falling edge of the clock signal, \\(Q1=X\\)... As long as pulse is not sent to the circuit, this value in the flip flop remains the same. </p> <p>Flip flops themselves produce power, meaning they can extend the range of the power of the combinational circuit.</p> <p>Your registers are made of these flip flops. </p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/19%20Sequential%20Logic/#j-k-flip-flop","title":"J-K Flip-flop","text":"<p>Does not have a invalid state. Visit PDF</p> <ul> <li>\\(J=\\mathrm{HIGH}\\) and \\(K=\\mathrm{LOW} \\Rightarrow Q\\) becomes HIGH (SET state) // J is equiv to S, K is equiv to R</li> <li>\\(K=\\mathrm{HIGH}\\) and \\(J=\\) LOW \\(\\Rightarrow Q\\) becomes LOW (RESET state)</li> <li>Both \\(J\\) and \\(K\\) are LOW \\(\\Rightarrow\\) No change in output \\(Q\\)</li> <li>Both \\(J\\) and \\(K\\) are HIGH \\(\\Rightarrow\\) Toggle, meaning it will go to high when low, and low when high.</li> </ul> <p>Visit Circuit Table</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/19%20Sequential%20Logic/#t-flip-flop","title":"T Flip-flop","text":"<p>Single input version of the \\(J-K\\) flip-flop, formed by tying both inputs together.</p> <p>Visit Circuit Table</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/19%20Sequential%20Logic/#asynchronous-inputs","title":"Asynchronous Inputs","text":"<p>Flips flop can have a asynchronous input:  PDF</p> <p>Asynchronous inputs affect the state of the flip-flop independent of the clock. See  flip-flot with active low PRESET and CLEAR asynchronous inputs. This allows to changing state regardless of the clock cycle.</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/19%20Sequential%20Logic/#sequential-circuits-analysis","title":"Sequential Circuits: Analysis","text":"<p>Given a sequential circuit diagram, we can analyze its behaviour by deriving its state table and hence its state diagram. We use \\(\\boldsymbol{A}(t)\\) and \\(\\boldsymbol{A}(\\boldsymbol{t + 1})\\) (or simply \\(A\\) and \\(A^{+}\\)) to represent the present state and next state, respectively, of a flip-flop represented by \\(A\\). PDF</p> <p>Example: </p> <ol> <li>Derive the State equation<ol> <li>E.g. Calculate the equation for D (one in the A side, can be marked DA)</li> <li>Since \\(A^+\\) (next state) = DA, the equation for \\(A^{+}=A \\cdot x+B \\cdot x\\)</li> </ol> </li> <li>Create a State table<ol> <li>Tip : find the condition for \\(A^+\\) is 1 and fill in the next state.</li> </ol> </li> <li>Draw the State diagram<ol> <li>note input/output format</li> </ol> </li> </ol> <p>See characteristic table</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/19%20Sequential%20Logic/#flip-flop-input-functions","title":"Flip-flop input functions","text":"<p>Visit PDF</p> <p>Example two J-K flip-flops with no output. In the state table note that next state is derived after filling in flip flop inputs. Eg. JA KA are 0 and 0 which is a no change. Hence \\(A^+\\) is 0</p> <p>Example two J-K flip-flops with output.</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/19%20Sequential%20Logic/#flip-flop-excitation-table","title":"Flip flop Excitation Table","text":"<p>Visit PDF</p> <p>Execution tables: given the required transition from present state to next state, determine the flip-flop input(s).</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/19%20Sequential%20Logic/#designing-a-sequential-circuits","title":"Designing a Sequential Circuits","text":"<p>Goal: Build a state machine. Our computer is a state machine.</p> <p>Design procedure:</p> <ul> <li>Start with circuit specifications - description of circuit behaviour, usually a state diagram or state table.</li> <li>Derive the state table.</li> <li>Perform state reduction if necessary.</li> <li>Perform state assignment.</li> <li>Determine number of flip-flops and label them.</li> <li>Choose the type of flip-flop to be used.</li> <li>Derive circuit excitation and output tables from the state table.</li> <li>Derive circuit output functions and flip-flop input functions.</li> <li>Draw the logic diagram.</li> </ul> <p>Example Please remember the clocking input</p> <p>Example</p> <p>Example with unused states. Be careful as it can be trapped in a loop of invalid state. This can be avoided by checking if the state is self correcting. Visit Recitation 10. Method: draw the state table of the unused states. Check if they go to a used (valid) or unused state (invalid) eventually.</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/19%20Sequential%20Logic/#memory","title":"Memory","text":"<p>Visit PDF</p> <p>Different from memory element. This is the memory chips that are used to store programs and data.</p> <p>Memory should have these properties: Fast access, large capacity, economical cost, non-volatile. However, most memory devices can not possess all these properties. Hence we organize these memories into Memory hierarchy.</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/19%20Sequential%20Logic/#data-transfer-between-memory-and-cpu","title":"Data transfer between memory and CPU","text":"<p>Visit PDF, Block Diagram</p> <p>Recall that the memory is divided into pigeon holes and each pigeon holes has a index number called a address. If there are \\(k\\) addressing bits, there will be \\(2^k\\) addressable locations.</p> <p>The addresses are travelled over wires called address bus. For \\(k\\) addressable locations, the address bus must have \\(k\\) wires to carry \\(k\\) bits of address.</p> <p>In the processor, there is a register called Memory Address Register that generates the addresses to be sent to memory to write or load data. </p> <p>The data to be stored on the pigeon hole is stored in the Memory Data Register. The data is transferred through the data bus which has width equal to 1 word in most cases. Hence in 32 machine the data bus is usually 32 bits wide.</p> <p>The control lines Read and Write specifies the direction of the transfer of the data.</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/19%20Sequential%20Logic/#readwrite-operations","title":"Read/Write Operations","text":"<p>Visit PDF</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/19%20Sequential%20Logic/#memory-cell","title":"Memory Cell","text":"<p>There are two types of RAM</p> <ul> <li>Static RAMs use flip-flops as the memory cells</li> <li>Dynamic RAM use capacitor charges to represent data. The simpler in circuitry, the have to be constantly refreshed.</li> </ul> <p>We will look at Static RAM for this course. Visit PDF</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/19%20Sequential%20Logic/#memory-arrays","title":"Memory Arrays","text":"<p>Logic construction of a \\(4 \\times 3\\) RAM (with decoder and OR gates): Visit PDF</p> <p>An array of RAM chips can be combined to form larger memory: Visit PDF</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/20%20Pipelining/","title":"Pipelining","text":""},{"location":"Year%201%20Semester%202/CS2100/Notes/20%20Pipelining/#introduction","title":"Introduction","text":"<p>PDF</p> <p>In the previous MIPS, the data propagates through each component. However, to achieve concurrency, we must have buffers so that when the new instruction is loaded, the next stage is not effected.</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/20%20Pipelining/#mips-pipeline-stages","title":"MIPS Pipeline Stages","text":"<p>PDF</p> <p>Recall that Mips instruction has five Execution Stages:</p> <p>IF: Instruction Fetch ID: Instruction Decode and Register Read Ex: Execute an operation or calculate an address MEM: Access an operand in data memory WB: Write back the result into a register</p> <p>Also recall the the datapath:  PDF. Each of the stage will take 1 clock cycle as shown PDF (each box takes 1). Note that if there is two instruction, then eg, IF of the next instruction can only be executed after the first IF. Same with the rest.  </p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/20%20Pipelining/#pipeline-datapath","title":"Pipeline Datapath","text":"<p>PDF</p> <p>In order to achieve the pipelining there are changes that need to be made on the datapath. </p> <p>When there is no pipeline (Single-cycle implementation):</p> <ul> <li>Update to the PC, register file, data memory are all done at the end of a clock cycle</li> </ul> <p>In contrast, during the Pipeline implementation:</p> <ul> <li>Each of the five stages are executed in one clock cycle</li> <li>Data required for each stage needs to be stored separately using registers</li> </ul>"},{"location":"Year%201%20Semester%202/CS2100/Notes/20%20Pipelining/#pipeline-registers","title":"Pipeline registers","text":"<p>PDF:</p> <ul> <li>Example: The IF/ID registers stores the instruction, and the PC+4 value</li> </ul> <p>Refer to PDF of how each stages work. Note that in the WB Stage, the address which the value need to be stored is incorrect. This is because the write register will hold the address from the other instruction. PDF. To solve this, the \u201cWrite register\u201d number from ID/EX will be carried forward through EX/MEM to MEM/WB pipeline register for use in WB stage. Hence the corrected datapath should look like:  PDF</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/20%20Pipelining/#pipeline-control","title":"Pipeline Control","text":"<p>PDF</p> <p>The control signal also have to be carried forward from one stage to another to implement the pipeline. PDF. See that the branch signal is in the MEM stage. This is because it has to be used during the next stage.</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/20%20Pipelining/#pipeline-performance","title":"Pipeline Performance","text":"<p>PDF</p> <p>This is the performance (number of clock cycle) in a ideal pipeline where there are no Hazards.</p> <p>PDF</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/20%20Pipelining/#hazards","title":"Hazards","text":"<p>PDF</p> <p>Hazards are problems that prevent next instruction from immediately following previous instruction.</p> <p>There are three types of Hazards. Structural, Data and Control. The last two are instruction dependencies.</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/20%20Pipelining/#structural-hazards","title":"Structural Hazards","text":"<p>PDF</p> <p>Example is where two instruction is attempting to access the memory at the same time. One solution is with stall (Delay the instruction). However, this could lead to a another structural hazard.</p> <p>Other solution is by splitting the memory into Data and Instruction memory. PDF</p> <p>In this structural hazard example, Reg is being accessed by two instructions. Since Registers are very fast memory, it is possible to split the cycle into half. PDF</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/20%20Pipelining/#instruction-dependencies","title":"Instruction Dependencies","text":"<p>PDF</p> <p>Data Dependency: When different instructions accesses (read/write) the same register. Only Raw Data dependency cause pipeline hazards. This will be discussed in the next section. To determine the dependency of two instruction, see the overlapping address. then see what is done to the address. Eg, <code>$1</code> is both in the two instructions. i1 writes to <code>$1</code> and i2 reads from <code>$1</code>. Hence RAW.</p> <p>Control Dependency: When the execution of an instruction depends on another instruction</p> <p>Failure to handle dependencies can affect program correctness!</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/20%20Pipelining/#raw-data-hazards","title":"RAW Data Hazards","text":"<p>PDF</p> <p>In the example: </p> <ul> <li>The <code>sub $2, $ 1, $3</code> instruction only writes the value in <code>$s2</code> at clock cycle 5. However, the <code>and $12, $2, $ 5</code>  instruction needs to read the <code>$s2</code> register at clock cycle 3.</li> <li>To solve this. the value calculated by the ALU can be forwarded to the ALU in the next instruction. See PDF.</li> </ul> <p>However, this solution does not work for LOAD Instruction Solution : Example. To solve this, we have to put a stall.</p> <p>In summary, RAW Data Hazards can be solved by forwarding. If there is a load instruction, Stall is also used. The detailed processed will not be discussed in this module. Visit Exercise.</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/20%20Pipelining/#control-hazards","title":"Control Hazards","text":"<p>PDF</p> <p>Recall <code>j</code> or <code>beq</code> instruction. During pipelining the instruction after jump can always be allowed to be executed. Hence we have to solve this problem. Example.</p> <p>One simple solution is adding delays. Example. This wastes 3 clock cycle. This is too heavy. Other solutions include:</p> <ul> <li>Early Branch Resolution</li> <li>Branch Prediction</li> <li>Delayed Branching</li> </ul> <p>Usually Early Branch Resolution is always used, and then combined with one of the two remaining methods.</p> <p>PDF</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/20%20Pipelining/#early-branch","title":"Early Branch","text":"<p>PDF</p> <p>Make decision in ID stage instead of MEM. PDF Achieve reduction from 3 to 1 clock cycle delay. PDF</p> <ul> <li>However if the register involved in the comparison is produced by preceding instruction, There is a additional delay (stall). PDF</li> <li>The problem is worse with load followed by branch. PDF</li> </ul> <p>Important</p> <p>For branch instruction, when there is a dependency between the previous instruction, there is delay as the data has to be forwarded to the ID stage unlike other instructions.PDF.</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/20%20Pipelining/#branch-prediction","title":"Branch Prediction","text":"<p>PDF</p> <p>There are many branch prediction schemes. Assume branch is taken, assume branch is not taken.</p> <p>In this section, all branches are assumed to be not taken. Then when the actual branch outcome is known:</p> <ul> <li>Not taken: Guessed correctly -&gt; No pipeline stall </li> <li>Taken:  Guessed wrongly -&gt; Wrong instructions in the pipeline -&gt; Flush successor instruction from the pipeline. </li> </ul> <p>Note that early branch is done, hence the decision is made at the ID stage.</p> <p>Example</p> <p>Example from Quiz 20-21: How many cycles are needed to execute the  program with forwarding,\u00a0assume branch-NOT-taken prediction strategy, branch decision made at MEM, whereas the actual branch in the code is taken.</p> <pre><code>        lw  $s2, 0($s1)\n        bne $s2, $s3, L1\n        sub $s0, $s4, $s5\nL1: add $s0, $s0, $s3\n</code></pre> 1 2 3 4 5 6 7 8 9 10 11 <code>lw</code> F D E M W <code>bne</code> F D E M W <code>sub</code> F D E X X <code>add</code> F D X X X <code>add</code> F D E M W <p>There are two key things to know here:</p> <ul> <li>In the \\(4^{\\text{th}}\\) row (add), the decode is not after Fetch because the previous instruction Decode cycle has not finished. In other words it can only be executed when the previous instruction is in Execute stage. The same goes for the 3rd row.</li> <li>Note that there are two add instruction. This is because before the branch decision is made in cycle 6 (MEM), the processor continues with the instructions. Then when the clock cycle reaches 7, it stopes and move on to the L1 instruction (because it is actual branch is taken) which is again, the add instruction.</li> </ul>"},{"location":"Year%201%20Semester%202/CS2100/Notes/20%20Pipelining/#delayed-branch","title":"Delayed Branch","text":"<p>PDF</p> <p>Move non-control dependent instructions into the X slots following a branch. Example</p> <p>Best and Worst case</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/22%20Cache/","title":"Cache","text":""},{"location":"Year%201%20Semester%202/CS2100/Notes/22%20Cache/#introduction","title":"Introduction","text":"<p>Recall that in a computer, the processor access the memory to perform a load or store operation. </p> <p></p> <p>However, the speed at which these data are travelled are slow. For instance, </p> <ul> <li>A 1GHz Processor implies that it takes 1ns per clock cycle.</li> <li>50ns for DRAM access implies that it takes 50 processor clock cycles per memory access.</li> <li>This speed difference is cased by a faster development of the CPU speed compared to the DRAM access speed. See this Graph. </li> </ul> <p>Such performance difference is unfavorable. Therefore, we must find faster memory technology ie cache.  </p> <p>There are two kinds of memory technology: DRAM and SRAM</p> <p></p> SRAM DRAM 6 transistors per memory cell 1 transistor per memory cell Low density Hight density Fast access latency of 0.5-5ns Slow access latency of 50-70ns More costly Less costly Uses flip flops Used in main memory <p>SRAM is normally used for cache. Besides these memory there are secondary memory such as Magnetic Disk. </p> <p>In summary: </p> Capacity Latency Cost/GB Register 100 s Bytes 20ps $$$$ SRAM 100sKB 0.5-5ns $$$ DRAM 100 s MB 50-70ns $ Hard Disk 100sGB 5-20ms Cents Ideal 1GB 1ns Cheap"},{"location":"Year%201%20Semester%202/CS2100/Notes/22%20Cache/#cache-the-basic-idea","title":"Cache: The Basic Idea","text":"<p>Imagine that bookshelf are the memory. You want the read the book, but every time you want to read a another book, you are forced to put back the current book to its bookshelf.</p> <p>One solution is to take books that are likely to be needed soon and place them nearby on a desk. This way, you can save time moving back and forth. This is the basic principle of how cache work:</p> <ul> <li>Keep the frequently and recently used data in smaller but faster memory</li> <li>Refer to bigger and slower memory only when you cannot find data/instruction in the faster memory</li> </ul> <p>Why does this work? </p> <p>Principle of Locality: Program accesses only a small portion of the memory address space within a small time interval.</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/22%20Cache/#types-of-locality","title":"Types of Locality","text":"<p>Temporal locality: If an item is referenced, it will tend to be referenced again soon. E.g., variable in a loop</p> <p>Spatial locality: If an item is referenced, nearby items will tend to be referenced soon. E.g., you access the 1st, 2nd... element in a array.</p> <p>Diagram. Our aim is to capture the working set and keep it in the memory closet to CPU</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/22%20Cache/#cache-location","title":"Cache location","text":"<p>To improve the access time of the data, cache (SRAM) memory is placed in between the processor and the memory (DRAM). </p> <p></p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/22%20Cache/#memory-access-time","title":"Memory Access Time","text":"<p>Cache works by bringing extra \"books\" that may be needed soon. Hence there is a probability involved. Diagram. Lets say the processor tries to access a data. It can either be in the cache (hit) or in the memory (miss).</p> <p>Hit: Data is in cache (e.g., X)</p> <ul> <li>Hit rate: Fraction of memory accesses that hit</li> <li>Hit time: Time to access cache</li> </ul> <p>Miss: Data is not in cache (e.g., Y)</p> <ul> <li>Miss rate \\(=1-\\) Hit rate</li> <li>Miss penalty: Time to replace cache block + hit time</li> </ul> <p>Hit time \\(&lt;\\) Miss penalty</p> <p>\\(\\(\\text{Average access time} = \\text{hit rate} \\times\\text{hit time}+(1-\\text{Hit rate})\\times\\text{Miss penalty}\\)\\)</p> <p>Example calculation: Suppose our on-chip SRAM (cache) has 0.8 ns access time, but the fastest DRAM (main memory) we can get has an access time of \\(10 n s\\). How high a hit rate do we need to sustain an average access time of \\(1 \\mathrm{~ns} ?\\)</p> <p>Let \\(h\\) be the desired hit rate. $$ \\begin{aligned} &amp; 1=0.8 h+(1-h) \\times(10+0.8) \\ &amp; =0.8 h+10.8-10.8 h \\ &amp; 10 h=9.8 \\rightarrow h=0.98 \\end{aligned} $$ Hence we need a hit rate of \\(98 \\%\\).</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/22%20Cache/#memory-to-cache-mapping","title":"Memory to Cache Mapping","text":"<p>Recall that a word of data is transferred from the memory to the processor. But when we have a cache, we will transfer more than one word of data because we want to bring in more \"books\" from the \"library\" to put it on the \"desk\". This amount of data is called the cache block/Line</p> <ul> <li>Cache Block/Line: Unit of transfer between memory and cache</li> <li>Block size is typically one or more word<ul> <li>e.g.: 16-byte block \\(\\cong 4\\)-word block (MIPS)</li> <li>32-byte block \\(\\cong 8\\)-word block </li> </ul> </li> </ul> <p></p> <p>Block number is the left 2 bits for the example above. Block offset is the remaining bits.</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/22%20Cache/#direct-mapped-cache","title":"Direct Mapped Cache","text":"<p>In the previous section, we have divided the memory address into two portions: Block number and offset. Now lets takes the block number and map them to the cache index. This can be achieved by dividing the block number again into two portions: tag number and  cache index</p> <p></p> <p>If number of Cache Blocks = \\(2^M \\to\\) the last M bits of the block number is the cache index. E.g. Cache has \\(2^2=4\\) blocks \\(\\to\\) last 2 bits of the block number is the cache index.</p> <p>Multiple memory blocks can map to the same cache block \\(\\to\\) Same cache index. However, they have unique tag number: Tag = Block number / Number of Cache Blocks. (Integer division). This is used to determine where the data in the cache is from. </p> <p>In summary the memory address is divided into the following sections.</p> <p></p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/22%20Cache/#cache-structure","title":"Cache Structure","text":"<p>In the cache, along with the data block, it also contains the following administrative information (overheads):</p> <ul> <li>Tag of the memory block.</li> <li>Valid bit indicating whether the cache line contains valid data.</li> </ul> <p>When the computers starts, cache is normally filled with random data. Hence it is possible for the tag to coincidently match with the searching tag. This is why valid bit is used to ensure the real data is in the cache.</p> <p>With this information, cache hit can be determined with</p> <pre><code>(Valid[index] = True) AND (Tag[index] = Tag[memory address])\n</code></pre> <p>For example: </p> <p></p> <p>With this, lets say we want to determine the cache hit for a particular memory address of the data you are looking for. </p> <p></p> <ol> <li>Use the index to go to the correct row in the cache. E.g. 2</li> <li>Determine if the data is in the cache by checking <ol> <li>valid.</li> <li>Tag in the row is equal to the given Tag.</li> </ol> </li> <li>If it is a hit<ol> <li>Use the offset to determine the word you need. E.g the left 2 bits from the offset.</li> </ol> </li> </ol>"},{"location":"Year%201%20Semester%202/CS2100/Notes/22%20Cache/#reading-data-example","title":"Reading Data Example","text":"<p>To explore further how the directed mapped cache works, see this :</p> <p>Given a Direct Mapped 16KB cache: 16-byte blocks \\(\\times\\) 1024 cache blocks. Trace the following memory accesses:</p> <p></p> <p>Lets begin with the first address.</p> <p></p> <p>Step 1: Check Cache Block at index 1 Step 2: Data i block 1 is invalid (Cold/Compulsory Miss)</p> <p></p> <p>Step 3: Load 16 bytes from memory; Set Tag and Valid bit</p> <p></p> <p>Step 4: Return Word 1 (byte offset = 4) to Register</p> <p>See here for the remaining addresses.</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/22%20Cache/#summary","title":"Summary","text":"<p>See here for another example.</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/22%20Cache/#types-of-cache-misses","title":"Types of Cache Misses","text":"<p>Compulsory misses</p> <ul> <li>On the first access to a block; the block must be brought into the cache</li> <li>Also called cold start misses or first reference misses</li> </ul> <p>Conflict misses</p> <ul> <li>Occur in the case of direct mapped cache or set associative cache, when several blocks are mapped to the same block/set</li> <li>Also called collision misses or interference misses</li> </ul> <p>Capacity misses</p> <ul> <li>Occur when blocks are discarded from cache as cache cannot contain all blocks needed</li> </ul>"},{"location":"Year%201%20Semester%202/CS2100/Notes/22%20Cache/#writing-data","title":"Writing Data","text":"<p>When we want to write data to the memory, we must consider the fact that the data is in both the memory and the cache. In this example when we write a data to a cache, it does not reflect the data in the memory. Cache and main memory are inconsistent!</p> <p>Solution 1: Write-through cache (easy but slow)</p> <ul> <li>Write data both to cache and to main memory</li> </ul> <p>Solution 2: Write-back cache (more popular)</p> <ul> <li>Only write to cache</li> <li>Write to main memory only when cache block is replaced (evicted) </li> </ul>"},{"location":"Year%201%20Semester%202/CS2100/Notes/22%20Cache/#write-through-cache","title":"Write - Through Cache","text":"<p>Problem: Write will operate at the speed of main memory</p> <p></p> <p>Solution: Put a write buffer between cache and main memory</p> <ul> <li>Processor: writes data to cache + write buffer</li> <li>Memory controller: write contents of the buffer to memory</li> <li>This allows the processor to continue on, instead of waiting for the write operation on the DRAM completes.</li> </ul>"},{"location":"Year%201%20Semester%202/CS2100/Notes/22%20Cache/#write-back-cache","title":"Write - Back Cache","text":"<p>Problem: We need a way to indicated whether the data has been changed in the cache. Otherwise the only option is to write back for every evicted cache blocks which is wasteful. </p> <p>Solution: Add an additional bit (Dirty bit) to each cache block. Write operation will change dirty bit to 1. Then, when a cache block is replaced, only write back to memory if dirty bit is 1</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/22%20Cache/#handling-cache-misses","title":"Handling Cache Misses","text":"<p>On a Read Miss</p> <ul> <li>Data loaded into cache and then load from there to register </li> </ul> <p>Write Miss option 1: Write allocate</p> <ul> <li>Load the complete block into cache</li> <li>Change only the required word in cache</li> <li>Write to main memory depends on write policy (either write back or write through)</li> </ul> <p>Write Miss option 2: Write around</p> <ul> <li>Do not load the block to cache</li> <li>Write directly to main memory only</li> </ul> <p>In summary: </p> <p></p> <p>Reading: Large and Fast: Exploiting Memory Hierarchy.</p> <ul> <li>Chapter 7 sections 7.1 \u2013 7.2 (3rd edition)</li> <li>Chapter 5 sections 5.1 \u2013 5.2 (4th edition)</li> </ul>"},{"location":"Year%201%20Semester%202/CS2100/Notes/22%20Cache/#block-size-trade-off","title":"Block Size Trade - off","text":"<p>Recall that:</p> \\[\\text{Average access time} = \\text{hit rate} \\times\\text{hit time}+(1-\\text{Hit rate})\\times\\text{Miss penalty}\\] <p>Using larger block size has trade offs:</p> <ul> <li>Takes advantage of spatial locality</li> <li>Larger miss penalty: Takes longer time to fill up the block</li> <li>If block size is too big relative to cache size \\(\\to\\) too few cache blocks \\(\\to\\) miss rate will go up</li> </ul> <p></p> <p>diagram</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/22%20Cache/#set-associative-sa-cache","title":"Set Associative (SA) Cache","text":"<p>SA Cache is a another type of cache used to solve conflict misses. See Types of Cache Misses for recap. </p> <p>SA cache can have N-way. N refers to number of blocks in each set. Within the set, a memory block can be placed in any of the N cache blocks in the set. PDF. For instance a 2-way Set Associative Cache looks as follows:</p> <p></p> <p>There is a need to search both blocks to look for the memory block.</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/22%20Cache/#mapping","title":"Mapping","text":"<p>Just like the Direct Mapped Cache we have to map the addresses to the cache.</p> <p></p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/22%20Cache/#example","title":"Example","text":""},{"location":"Year%201%20Semester%202/CS2100/Notes/22%20Cache/#advantage","title":"Advantage","text":"<p>Lets compare SA Cache with Direct Mapped Cache to see how it avoids conflict Miss. In the Direct Mapped Cache:</p> <p></p> <p>However in the SA Cache:</p> <p></p> <p></p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/22%20Cache/#example-2","title":"Example 2","text":"<p>Visit PDF For detailed example</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/22%20Cache/#fully-associative-fa-cache","title":"Fully Associative (FA) Cache","text":"<p>A memory block can be placed in any location in the cache</p> <p>Key idea: Memory block placement is no longer restricted by cache index or cache set index</p> <ul> <li>Can be placed in any BUT</li> <li>Need to search all cache blocks for memory access</li> </ul>"},{"location":"Year%201%20Semester%202/CS2100/Notes/22%20Cache/#mapping_1","title":"Mapping","text":"<p>In FA Cache there is only two portions. The tag and the Offset</p> <p></p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/22%20Cache/#example_1","title":"Example","text":"<ul> <li>4KB cache size and 16-Byte block size</li> <li>Compare every tags (256) and valid bits in parallel</li> </ul>"},{"location":"Year%201%20Semester%202/CS2100/Notes/22%20Cache/#performance","title":"Performance","text":"<ol> <li>Cold/compulsory miss remains the same irrespective of cache size/associativity.</li> <li>For the same cache size, conflict miss goes down with increasing associativity.</li> <li>Conflict miss is 0 for FA caches.</li> <li>For the same cache size, capacity miss remains the same irrespective of associativity.</li> <li>Capacity miss decreases with increasing cache size .</li> </ol>"},{"location":"Year%201%20Semester%202/CS2100/Notes/22%20Cache/#block-replacement-policy","title":"Block Replacement Policy","text":"<p>This only applies to the Set Associative (SA) Cache and Fully Associative (FA) Cache because</p> <ul> <li>Can choose where to place a memory block</li> <li>Potentially replacing another cache block if full</li> <li>Need block replacement policy</li> </ul> <p>Least Recently Used (LRU) is one type of block replacement policy </p> <ul> <li>How: For cache hit, record the cache block that was accessed<ul> <li>When replacing a block, choose one which has not been accessed for the longest time</li> </ul> </li> <li>Why: Temporal locality</li> </ul> <p>Example: Lets say that the following memory accesses are done: <code>0 4 8 12 4 16 12 0 4</code> in a 4-way SA cache. Figure below shows the data structure (not the cache) to keep track which one is most recently used. By the time <code>0 4 8 12</code> is accessed, we see that in the first line, 12 is the most recently used and 0 is the least recently used.</p> <p></p> <p>Then when the next access <code>4</code> is performed, it should move up the data structure shown by the second line. Next when <code>16</code> is accessed, it is a miss, hence the LRU (<code>0</code>) is chosen to evicted illustrated by the 3rd line.</p> <p>Draw back for LRU</p> <ul> <li>Hard to keep track if there are many choices.</li> </ul> <p>Other replacement policies:</p> <ul> <li>First in first out (FIFO)</li> <li>Random replacement (RR)</li> <li>Least frequently used (LFU)</li> </ul> <p>Visit PDF for comparison using example.</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/22%20Cache/#summary_1","title":"Summary","text":"<p>Visit PDF</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/22%20Cache/#exploration-multilevel-cache","title":"Exploration: Multilevel Cache","text":"<p>It is possible to separate the cache into</p> <ul> <li>Data caches</li> <li>Instruction cach</li> </ul> <p>It is also possible to have different level of caches.</p> <p>Visit PDF</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/Key%20Notes/","title":"Number Systems","text":""},{"location":"Year%201%20Semester%202/CS2100/Notes/Key%20Notes/#repeated-division-repeated-multiply-to-convert-decimal-into-binary","title":"Repeated division &amp; Repeated Multiply to convert decimal into binary","text":"<p>Repeated Multiply is for binary. Multiply the decimal points by 2.</p> <p>If the binary fraction have to be only n bits, do the multiply by only n+1 for rounding. eg 2.1 in binary: \\(0.1 \\times 2=0.2\\) \\(0.2 \\times 2=0.4\\) \\(0.4 \\times 2=0.8\\) \\(0.8 \\times 2=1.6\\) Therefore: 0010.001</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/Key%20Notes/#overflow-in-1s-complement","title":"Overflow in 1s Complement","text":"<p>Add the Overflow to then LSB</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/Key%20Notes/#converting-binary-with-fraction-into-2s-complement","title":"Converting binary with fraction into 2s Complement","text":"<p>Add 1 to the end eg: 0010.100 into 2s complement is 1101.100</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/Key%20Notes/#mips","title":"MIPS","text":""},{"location":"Year%201%20Semester%202/CS2100/Notes/Key%20Notes/#register-in-mips","title":"Register in MIPS","text":""},{"location":"Year%201%20Semester%202/CS2100/Notes/Key%20Notes/#beq-jump","title":"BEQ &amp; Jump","text":"<p>BEQ is PC relative: Count from PC+4. given in number of instructions</p> <p>Jump: Absolute. Get the target address. Throw away last 2 bits and left 4 bits. Which give 26 remaining bits.</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/Key%20Notes/#isa","title":"ISA","text":""},{"location":"Year%201%20Semester%202/CS2100/Notes/Key%20Notes/#fixed-length-instruction","title":"Fixed length instruction","text":"<p>Type A: 6 opcode 5 operand 5 operand Type B: 11 opcode 5 operand</p> <p>To maximise,eg reserve 111111 for Type A. Then the total combination of Type B is \\((2^6-1)\\times 2^5\\). \\(2^6-1\\) represent the total number of combination of the first  6 bits in Type B as one of the combination is used by Type A.</p> <p>To minimise eg reserve 111111 for Type B. The the total combination of Type B is \\(2^5\\)</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/Key%20Notes/#size-of-the-register-and-address","title":"Size of the register and address","text":"<p>Eg if a machine have 6 registers, the size of each register is 3 bits because 2^3 is the minimum to represent all registers.</p> <p>If a machine have 64 addresses, the size of address have to be log2(62)=6 to represent all addresses.</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/Key%20Notes/#consensus-theorem","title":"Consensus Theorem","text":"\\[X . Y+X^{\\prime} Z+Y . Z=X \\cdot Y+X^{\\prime} Z\\]"},{"location":"Year%201%20Semester%202/CS2100/Notes/Key%20Notes/#circuit-implementation-calculating-minterms","title":"Circuit implementation calculating minterms","text":"<p>Don't try out everything. Here B must be 1 for F to be 1. Start there</p>"},{"location":"Year%201%20Semester%202/CS2100/Notes/Key%20Notes/#pipelining","title":"Pipelining","text":"<p>Be careful of <code>beq</code> instruction eg</p> <pre><code>slt $t0, $t2, $s0 \nbeq $t0, $0, E2\n</code></pre> <p>Don't forget that <code>$t0</code> is being read, so there is a RAW relationship</p> <p>For Forwarding see Lect21_Pipelining2_full. The Decode stage for or instruction is executed only when the previous instruction's ID stage is finished. So there is a delay here also. i</p>"},{"location":"Year%201%20Semester%202/DTK1234/DTK1234/","title":"DTK1234","text":"<p>NUS MODS Canvas</p> <p>In this module, students use design principles to develop their creative potential and practise design thinking using a people-centered approach to solve problems and create new possibilities. Through practical activities, students will discover tools and mindsets that guide them in navigating ambiguity in a creative process, observing and learning from others in unfamiliar contexts, and generating and experimenting with ideas quickly. While students draw on design thinking as a personal creative skillset, they will also value the impact of design that affords people the opportunity and privilege to shape the world that they, and others, inhabit.</p> <p>Module Guide Timetable</p> <p></p>"},{"location":"Year%201%20Semester%202/DTK1234/DTK1234/#intro-segment-design-doing-not-thinking","title":"Intro Segment - Design Doing, not Thinking","text":"<p>Intro Segment - Design Doing, not Thinking</p> Supplementary Readings <p>The Design of Everyday Things (2013) </p> Original Mine DTK1234 Intro Segment ILA Moon Ji Hoon TO23 Intro Segment ILA"},{"location":"Year%201%20Semester%202/DTK1234/DTK1234/#segment-1-systematic-creativity","title":"Segment 1 - Systematic Creativity","text":"Original Mine DTK1234 Segment 1 ILA Moon Ji Hoon TO23 Segment 1 ILA"},{"location":"Year%201%20Semester%202/DTK1234/DTK1234/#segment-2-empathize","title":"Segment 2 -Empathize","text":"Supplementary Readings <p>Segment 2 Supplementary Materials </p> <p>IDEO (2015) The Little Book of Design Research Ethics</p> <p>Battarbee et al (2014) Empathy on the Edge</p> <p>Pernice (2018) \"User Interviews: How, When, and Why to Conduct Them\", Nielsen Norman GroupLinks to an external site.</p> Original Mine DTK1234 Segment 2 ILA Moon Ji Hoon TO23 Segment 2 ILA"},{"location":"Year%201%20Semester%202/DTK1234/DTK1234/#segment-3-do-undo-redo","title":"Segment 3 - Do, Undo, Redo","text":"Supplementary Readings <p>Houde &amp; Hill (1997) What do prototypes prototype </p> <p>Buchenau &amp; Suri (2000) Experience prototyping</p> Original Mine DTK1234 Segment 3 ILA Moon Ji Hoon TO23 Segment 3 ILA"},{"location":"Year%201%20Semester%202/DTK1234/DTK1234/#segment-4-evaluate-with-people","title":"Segment 4 - Evaluate with people","text":"Supplementary Readings <p>IDEO (2015) The Little Book of Design Research Ethics (1)</p> Original Mine DTK1234 Segment 4 ILA Moon Ji Hoon TO23 Segment 4 ILA"},{"location":"Year%201%20Semester%202/DTK1234/DTK1234/#journal","title":"Journal","text":"<p>To curate your entire DTK journey, you will be using the\u00a0Design\u00a0Thinking\u00a0Journal\u00a0(DTJ) to document your body of work. </p> Original Mine Original DTK1234 Wrap Up Segment Design Thinking Journal DTK1234 Wrap Up Segment Design Thinking Journal"},{"location":"Year%201%20Semester%202/DTK1234/DTK1234/#additional","title":"Additional","text":"<p>TBW_Summary(Sem2)</p>"},{"location":"Year%201%20Semester%202/DTK1234/Notes/Intro%20Segment%20-%20Design%20Doing%2C%20not%20Thinking/","title":"Intro Segment - Design Doing, not Thinking","text":"<p>The term design thinking is much more about doing than thinking. If your idea of creativity or design is a image of us sitting around the table and thinking, waiting for great ideas to drop into your minds, you are utterly mistaken because design thinking is action bias. Instead of thinking about what to build, you build in order to think. It is a hands on iterative process which favors ongoing experimentation until the right solution is found. </p> <p>This module has been designed with the same approach. You will move away from long lecture and inanimate tutorials. Instead, you will receive small doses of lectures, like appetizers and healthy servings of activity-based learning.</p> <p>Through practical activities that activate embodied learnings, we hope that you will Discover tools and mindsets that guide you in navigating ambiguity in a creative process. Observe and learn from others in an unfamiliar context; and generate and experiment with ideas quickly. </p> <p>This module is divided into 6 segments shown above. Each segment has a individual learning activity (ILA) and a team based workshop. The ILA is asynchronous. You will be given a two week period to complete it in you own pace. This will be followed by segment's team based learning. In the workshop you will come together with your tutorial group for a hands on workshop session. With this sequencing, the ILA and TBW of different segments will overlap.</p> <p>Design thinking has been around for some time now. It is a useful and valuable set of methods and mindsets especially with the 4th industrial revolution where creativity and abilities to connect with people are often ranked as top skills required in this age. Now, here are three definition from experts</p> IDEO <p>Design thinking is a human-centered approach to innovation-anchored in understanding customer's needs, rapid prototyping, and generating creative ideas-that will transform the way you develop products, services, processes, and organizations. By using design thinking, you make decisions based on what customers really want instead of relying only on historical data or making risky bets based on instinct instead of evidence.</p> Rikke Friis Dam and Teo Yu Siang, Interaction Design Foundation <p>Design Thinking is a design methodology that provides a solution-based approach to solving problems. It's extremely useful in tackling complex problems that are ill-defined or unknown, by understanding the human needs involved, by re-framing the problem in human-centric ways, by creating many ideas in brainstorming sessions, and by adopting a hands-on approach in prototyping and testing.</p> Tim Brown, Executive Char of IDEO <p>Design Thinking is a human-centered approach to innovation that draws from the designer's toolkit to integrate the needs of people, the possibilities of technology, and the requirements for business success.</p>"},{"location":"Year%201%20Semester%202/DTK1234/Notes/Intro%20Segment%20-%20Design%20Doing%2C%20not%20Thinking/#what-exactly-is-design-thinking","title":"What exactly is Design Thinking?","text":"<p>You will learn to build your own creative confidence. At the same time, we hope that you can foster an amount of empathy because that's something really important in DTK process. Contrary to popular belief, design is not a self-centered activity. It is about learning about, from and with others. Here are things that will be covered in different segments.</p>"},{"location":"Year%201%20Semester%202/DTK1234/Notes/Intro%20Segment%20-%20Design%20Doing%2C%20not%20Thinking/#segment-1-systematic-creativity","title":"Segment 1 - Systematic Creativity","text":"<p>Creativity is about creating a solution that deviates from the norm, but one that works exceptionally well. This segment will cover how you can get to that deviation that causes it to be out of the box.</p> <p>Most people feel creativity is a bit of a stroke of luck. Maybe thats because most education do not provide a step by step process almost like a science. \"Luck\" may be true, but to a good extent, a lot of creative deviation can be systematically arrived at if we just know the techniques.</p>"},{"location":"Year%201%20Semester%202/DTK1234/Notes/Intro%20Segment%20-%20Design%20Doing%2C%20not%20Thinking/#segment-2-empathize","title":"Segment 2 - Empathize","text":"<p>After segment, students will now will make their ideas relevant to those people who are going to actually use the product or services that they are creating. This empathize segment will teach students how to build a genuine understanding of other people who the students creates solution for. This is relevant to any major as understanding other people's needs is critical to make their creation relevant to other people, be it technology,, service, article or literature.</p> <p>Students will also go on a field study to learn to translate the data collected into new solution opportunities;  through mini exercises and the workshop.</p>"},{"location":"Year%201%20Semester%202/DTK1234/Notes/Intro%20Segment%20-%20Design%20Doing%2C%20not%20Thinking/#segment-3-do-undo-redo","title":"Segment 3 - Do, Undo, Redo","text":"<p>As the name suggests, this segment is all about building prototype and what different types of prototypes you might encounter, or you might build, as you are trying to design something. So, building prototypes is all about helping to develop and flesh out your ideas. Essentially we can see prototypes as these external objects that enable us to reflect on them and study them. And use the insights that are surfaced from one prototype, to inform the next prototype that we might build. Therefore, after a iterative way, all of the prototype that we build will help use bone in on a more informed and comprehensive solutions to address the opportunity at hand.</p> <p>This segment forms a bridge that connects the previous two segments. <code>Systematic creativity</code> , <code>Emphathize</code>. We essentially take the ideas out of our head and into the real world and realize them there, hopefully to get a better understanding if they stick. By building prototype, you can test and improve our understanding and assumptions about the situation that we are designing for.</p>"},{"location":"Year%201%20Semester%202/DTK1234/Notes/Intro%20Segment%20-%20Design%20Doing%2C%20not%20Thinking/#segment-4-evaluate-with-people","title":"Segment 4 - Evaluate with people","text":"<p>In this segment we will going to take the prototype and put it on the hands of actual users to help use understand its usefulness and its usability characteristics. You have to keep in mind that people are very complex. So when you design something in a studio, that's one thing. But once you get it out into the field, there's lots of other things that you can learn about your prototype, whether it be usability, attitude, maybe even how it interfaces or interacts with another product or dependency. </p> <p>You will take the data from the users to see things that are insightful. Those insights will either going to lead you to moving forward and implementing your prototype or perhaps circling back and looking back at one of other previous processes to further refine your ideas.</p>"},{"location":"Year%201%20Semester%202/DTK1234/Notes/Intro%20Segment%20-%20Design%20Doing%2C%20not%20Thinking/#final-note","title":"Final Note","text":"<p>These methods and principles are applicable to you, whatever discipline that you come from. For instance, fast food restaurants have to be models for efficiency. There are so many different components parts in terms of the physical makeup of the establishment, self-service kiosks, fulfillment centers, interfacing with third parties like Grab and FoodPanda. </p>"},{"location":"Year%201%20Semester%202/DTK1234/Notes/Intro%20Segment%20-%20Design%20Doing%2C%20not%20Thinking/#convergent-divergent-thinking","title":"Convergent &amp; Divergent Thinking","text":"<p>In the book <code>Out of Our Minds</code>, Sir Ken Robinson first describes imagination as being made up of two parts: the imaginal and the imaginative. </p> <ul> <li>When we bring some mental image to mind which is drawn from our personal experiences or real experiences, they are imaginal. </li> <li>But if you bring to mind something that you have no direct experience with, creating a mental image that is composed in your mind rather than recalled, they are imaginative.</li> </ul> <p>In this book, Ken Robinson goes on to propose that </p> <p>The creative process is rooted in imaginative thought, in envisaging new possibilities. But creativity goes further. Imagination can be an entirely private process of internal consciousness....and may have no impact in the public world at all. But creativity does. In a sense, it is applied imagination.</p> <p>And he goes on to elaborate</p> <p>To call somebody creative suggests they are actively producing something in a deliberate way. A first definition of creativity then is imaginative processes with outcomes in the public world.</p> <p>Unlike popular belief, creativity is not an exclusive ability restricted to a special set of people. For a long time experts in cognitive science has shown that creativity is an inherent human capability required to recognize incoming information and compose metal structures in our minds. In other words, if you are able to think, you have creative potential.</p> <p>Secondly creativity does not happen in a vacuum, of inactivity. Your ideas, however brilliant, if it stays in your mind, you will be considered imaginative at most. To be creative, you have to apply your imaginativeness to produce outcomes in the real world. </p> <p>The design thinking approach adapts methods commonly applied by designers. These methods are organized into processes with clear identifiable steps that guide people who use them. With this formalized framework, a human-centric, designedly way of creating new solutions could be adopted by individuals like yourself. In real practice  design thinking is often regarded as a toolkit, where a variety of methods could be selected and put together as a framework that guides teams or organizations in innovating meaningful solutions. In fact, this is particularly useful when large multidisciplinary teams and stakeholders come together to solve complex problem. Design thinking becomes a common process platform where all parties work from. To unravel this a little further, the overall Design thinking process is rooted in a interplay of Convergent and Divergent Thinking</p> <p>So what are these convergent and Divergent Thinking? Convergent thinking is a type of thinking that focuses on coming up with a single, well established answer to a problem. For example what is the solution of 21+4? While trying to solve this question, you went through a logical arithmetic steps in your mind and the though process in solving this question is Convergent thinking in principle. You have some facts that you depended upon to find an answer. In some ways convergent thinking is like solving the puzzle, trying to find the optimum solution based on the data given.</p> <p>On the other hand, Divergent thinking is the opposite of convergent thinking. This is the though process that generates may ideas or possible solutions based on a single stimulus or problem. Imagine you are tasked with the same question: 21+4. In the perspective of divergent thinking, what might be the possible solutions?</p> <ul> <li>21+4 = 25</li> <li>21+4 = 10+15</li> <li>21 +4 = 77 - 45 -7</li> </ul> <p>It goes on and on. It has infinite number of solutions. This is a simple example of divergent thinking which involves the process of coming up with many alternative solutions to a task. </p> <p>Both types of thinking are equally important especially in a creative process. Design thinking as a process moves between Divergent and Convergent Thinking and guides practitioners to use the most appropriate dominant thought at the right time. For instance we diverge when we observe people from a variety of perspectives, or when exploring as many ideas as we can. On the other hand, convergent thinking is critical when we analyze findings and define problems, or converging on solution through an iterative decision marking process.</p>"},{"location":"Year%201%20Semester%202/DTK1234/Notes/Intro%20Segment%20-%20Design%20Doing%2C%20not%20Thinking/#norman-doors-the-theory-of-affordance","title":"Norman Doors &amp; The Theory of Affordance","text":"<p>In a previous section, we discussed creativity as an interplay of Divergent Thinking and Convergent Thinking. Going further, Design Thinking places the human experience at the core of the design objective. It also involves people in a co-design process, while we aim to come up with new solutions to improve the experiences of products and services for people who use them. Tools in design thinking help find out who are the true stakeholders of an issue are, and guides us in deeply understanding the issues these people face. To do that, working with empathy is an important mindset. Empathy also helps us acknowledge that people are very complex and unique. Our needs, preferences and behaviour are all different, depending on many conditions such as age, culture, beliefs, personality and social setting. Design Thinking helps us make viable solutions despite all these differences. We will dive deeper into Empathy in Segment 2.</p> <p>On the other hand, in spite of the differences, humans have shared values, collective memories and common behaviour. One area of studies that is important to design is Usability. Usability refers to the ease of use and learnability of a product or service where a product is designed with a generalise user psychology and physiology in mind. We can study human behaviour to understand the way people perceive and interact with products, and use these insights to generate creative solutions. In 1977, the psychologist James J. Gibson, in his article \u201cThe Theory of Affordance\u201d introduced the term \u201cAffordance\u201d. Affordance refers to all action possibilities between the environment and an agent, which could be people or animals. This relationship is independent of an individual's ability to recognise them, but always in relation to agents and therefore dependent on their capabilities.</p> <p>For example, a flight of steps to an adult affords many, probably countless action possibilities, such as walking up, sitting on, lying down, balancing on an edge, etc. On the other hand, the same flight of steps will afford less action possibilities to a crawling baby, which will not be able to perform most of these actions. Don Norman, in his book \"The Design of Everyday Things\", built on this premise and proposed the notion of \u201cPerceived Affordance\u201d. \"Perceive Affordance\", in Design, refers to the action possibilities that are readily perceivable by a user. Here, the visibility of affordances is important. By making affordances explicit, we can provide strong clues to the operation of things. In Don Norman\u2019s words, \u201cPerceived affordances help people figure out what actions are possible without the need for labels and instructions.\u201d</p> <p>So, when we commend a well-designed product as intuitive, what we really mean is that it has good perceived affordance that makes it easy to use and understand. For instance, the physical attribute of a button can signify how it can be used. Its shape, details and texture can suggest that it should be pressed, pulled, pushed or turned. Have you ever used a water faucet with poor perceived affordance where you had to figure out how to turn on the tap, and then received a shock of hot water? On the other hand, a water faucet with good perceived affordance will be able to indicate to you how to activate it, without you having to think.</p> <p>Perceived affordance can even be critical in some context - imagine an emergency situation where you need to stop an industrial machine immediately but you had to find the button, and then got confused about how to trigger it. This could have led to a dreadful outcome. IKEA instruction manuals are a good example of perceived affordance in the domain of communication design, where the instructions for assembling a piece of furniture are represented with such graphic clarity that words are not required to explain procedures. The original multi-touch gestures on the Apple Mac trackpad or iPhone is another good example in the area of Human-Computer Interface Design. The finger gestures designed for the operating system are based on common understanding of natural finger movements. We slide our fingers to scroll, or pinch with two fingers and spread to zoom in, which feels as if one is clearing out a spot to see better. When the gestures were first launched, it required very little learning to use. Even young children knew how to use it without any instruction!</p> <p>In his book, Don Norman used doors to describe perceived affordances that failed. Have you pushed a door meant to be pulled? Pulled a door meant to be pushed? Or got stuck when push or pull failed, only to realize that the door slides? And when you approach the same sliding door again, you can't tell which direction it slides. Last one - have you reached out to a door, only to have it open on its own? The failure of door and door handle designs to visibly indicate use, in this case, how to open the door, is a common situation of poorly designed perceived affordance. Have a walk around, I believe you can find many examples.</p>"},{"location":"Year%201%20Semester%202/GEC1036/GEC1036/","title":"GEC1036 Radiation-Scientific Understanding and Public Perception","text":"<p>NUS MODS Canvas</p> <p>This module aims to equip students with the essential knowledge to make intelligent assessments on the potential risks and uses of radiation in our modern society. After introducing the physics behind various forms of radiation, we will look at how these radiations are used in medical diagnosis and treatment and other applications. Some controversial issues in these applications will be raised and debated. The health effects of high and low levels of radiation will be presented based on scientific evidence thus dispelling some of the negative misconceptions of radiation and irrational fear of it.</p>"},{"location":"Year%201%20Semester%202/GEC1036/GEC1036/#notes","title":"Notes","text":"Week Notes Tutorial 1 GEC1036 01 Introduction to Module - 1 GEC1036 02 Atoms &amp; EM Radiation - 2 GEC1036 03 Atomic Nucleus &amp; Radioactivity - 2 GEC1036 04 Units and Dosage - 3 GEC1036_05 Detection, Measurement and Identification - 4 GEC1036 06 Radiation in Natural Environment Radiation-2023-Tutorial-1Radiation-Tutorial-1 Solutions 4 GEC1036 07 Radiation in Everyday Life - 5 GEC1036 08 Biological Effects of Ionising Radiation - 5 GEC1036 09 Biological Effects of Ionising Radiation (Part 2) - 6 GEC1036 10  Nuclear Power Plants Radiation-2023-Tutorial-2 7 GEC1036 11 - Safety of NPPs - 7 GEC1036 12  Future NPPs - 8 GEC1036 13  Nuclear Fuel Cycle and Nuclear Wastes Radiation-2023-Tutorial-3RSDSCo60 9 GEC1036 14 Radiation from Nuclear Bombs and Past Tests - 9 GEC1036 17 - Applications in Agriculture and Food Production - 10 GEC1036 18 - Applications of Radiation in Industries and Engineering Radiation-2023-Tutorial-4 10 GEC1036 15 - Applications of Radiation - Medical Imaging - 11 GEC1036 19 - Applications in Science &amp; Arts &amp; Research - 11 Radiation in Medical Application Therapeutic (James C L Lee) - 12 GEC1036 20 - Public Perception on Radiation I - 13 Radiation-2023-Lect21 - Public Perception on Radiation II Radiation-2023-Tutorial-5"},{"location":"Year%201%20Semester%202/GEC1036/GEC1036/#midterm","title":"Midterm","text":"Paper Answer GEC1036 (2022) Term Test 1 GEC1036 (2022) Term Test 1 (Ans) GET1024 (2019) Term Test 1 GET1024 (2019) Term Test 1 (Ans) GET1024 (2018) Term Test 1 GET1024 (2018) Term Test 1 (Ans)"},{"location":"Year%201%20Semester%202/GEC1036/GEC1036/#resources","title":"Resources","text":"<ul> <li>Chart</li> </ul>"},{"location":"Year%201%20Semester%202/MA2001/MA2001%20Final%20Note/","title":"MA2001 Final Note","text":""},{"location":"Year%201%20Semester%202/MA2001/MA2001%20Final%20Note/#linear-systems","title":"Linear Systems","text":"<p>General solution: If \\(u\\) is a solution to \\(Ax=0\\), the general solution to \\(Ax=b\\) is \\(u+b\\).</p>"},{"location":"Year%201%20Semester%202/MA2001/MA2001%20Final%20Note/#matrix","title":"Matrix","text":"<p>Transpose:</p> <ul> <li>\\(\\left(A^{\\mathrm{T}}\\right)^{\\mathrm{T}}=A\\).</li> <li>\\(A\\) is symmetric \\(\\Leftrightarrow A=A^{\\mathrm{T}}\\).</li> <li>Let \\(c\\) be a scalar. Then \\((c \\boldsymbol{A})^{\\mathrm{T}}=c \\boldsymbol{A}^{\\mathrm{T}}\\).</li> <li>Let \\(\\boldsymbol{B}\\) be \\(m \\times n\\). Then \\((\\boldsymbol{A}+\\boldsymbol{B})^{\\mathrm{T}}=\\boldsymbol{A}^{\\mathrm{T}}+\\boldsymbol{B}^{\\mathrm{T}}\\).</li> <li>Let \\(\\boldsymbol{B}\\) be \\(n \\times p\\). Then \\((\\boldsymbol{A} \\boldsymbol{B})^{\\mathrm{T}}=\\boldsymbol{B}^{\\mathrm{T}} \\boldsymbol{A}^{\\mathrm{T}}\\).</li> </ul> <p>Determinant:</p> <p>\\(\\begin{aligned} &amp; \\operatorname{det}(\\boldsymbol{A})=\\operatorname{det}\\left(\\boldsymbol{A}^{\\mathrm{T}}\\right) \\\\ &amp; \\operatorname{det}(\\boldsymbol{A} \\boldsymbol{B})=\\operatorname{det}(\\boldsymbol{A}) \\operatorname{det}(\\boldsymbol{B}) \\\\ &amp; \\operatorname{det}(c \\boldsymbol{A})=c^n \\operatorname{det}(\\boldsymbol{A}), \\text { where } \\boldsymbol{A} \\text { is } n \\times n \\\\ &amp; \\operatorname{det}\\left(\\boldsymbol{A}^{-1}\\right)=\\operatorname{det}(\\boldsymbol{A})^{-1} \\text { if } \\boldsymbol{A} \\text { is invertible. }\\end{aligned}\\) Suppose a square matrix \\(\\boldsymbol{A}\\) has a zero row. Then \\(\\operatorname{det}(\\boldsymbol{A})=0\\).</p> <p>Adjoint matrix: Let \\(\\boldsymbol{A}=\\left(\\begin{array}{ccc}1 &amp; -1 &amp; 1 \\\\ 0 &amp; -1 &amp; 0 \\\\ 1 &amp; 0 &amp; 3\\end{array}\\right) \\cdot \\operatorname{det}(\\boldsymbol{A})=(-1)\\left|\\begin{array}{ll}1 &amp; 1 \\\\ 1 &amp; 3\\end{array}\\right|=-2\\)</p> \\[\\operatorname{adj}(\\boldsymbol{A})=\\left(\\begin{array}{lll}A_{11} &amp; A_{21} &amp; A_{31} \\\\ A_{12} &amp; A_{22} &amp; A_{32} \\\\ A_{13} &amp; A_{23} &amp; A_{33}\\end{array}\\right)\\] <p>Cramer's Rule:</p> <p>\\(\\left(\\begin{array}{ccc}1 &amp; 1 &amp; 3 \\\\ 2 &amp; -2 &amp; 2 \\\\ 3 &amp; 9 &amp; 0\\end{array}\\right)\\left(\\begin{array}{l}x \\\\ y \\\\ z\\end{array}\\right)=\\left(\\begin{array}{l}0 \\\\ 4 \\\\ 3\\end{array}\\right)\\text{. Det =}\\left|\\begin{array}{ccc}1 &amp; 1 &amp; 3 \\\\ 2 &amp; -2 &amp; 2 \\\\ 3 &amp; 9 &amp; 0\\end{array}\\right|=60\\) \\(\\begin{aligned} &amp; \\circ \\quad x=\\frac{\\left|\\begin{array}{ccc}0 &amp; 1 &amp; 3 \\\\ 4 &amp; -2 &amp; 2 \\\\ 3 &amp; 9 &amp; 0\\end{array}\\right|}{60}=\\frac{132}{60}=2.2 \\\\ &amp; \\circ \\quad y=\\frac{\\left|\\begin{array}{lll}1 &amp; 0 &amp; 3 \\\\ 2 &amp; 4 &amp; 2 \\\\ 3 &amp; 3 &amp; 0\\end{array}\\right|}{60}=\\frac{-24}{60}=-0.4 \\\\ &amp; \\circ \\quad z=\\frac{\\left|\\begin{array}{ccc}1 &amp; 1 &amp; 0 \\\\ 2 &amp; -2 &amp; 4 \\\\ 3 &amp; 9 &amp; 3\\end{array}\\right|}{60}=\\frac{-36}{60}=-0.6 \\\\ &amp; \\end{aligned}\\)</p> <p>Inverse: Let \\(\\boldsymbol{A}, \\boldsymbol{B}\\) be invertible matrices of same size.</p> <ul> <li>Let \\(c \\neq 0 . c \\boldsymbol{A}\\) is invertible, and \\((c \\boldsymbol{A})^{-1}=\\frac{1}{c} \\boldsymbol{A}^{-1}\\).</li> <li>\\(\\boldsymbol{A}^{\\mathrm{T}}\\) is invertible, and \\(\\left(\\boldsymbol{A}^{\\mathrm{T}}\\right)^{-1}=\\left(\\boldsymbol{A}^{-1}\\right)^{\\mathrm{T}}\\).</li> <li>\\(\\boldsymbol{A}^{-1}\\) is invertible, and \\(\\left(\\boldsymbol{A}^{-1}\\right)^{-1}=\\boldsymbol{A}\\).</li> <li>\\(A B\\) is invertible, and \\((A B)^{-1}=B^{-1} A^{-1}\\).</li> </ul>"},{"location":"Year%201%20Semester%202/MA2001/MA2001%20Final%20Note/#vector-spaces","title":"Vector Spaces","text":"<p>To show Linearly Independent: \\(c_1 \\boldsymbol{v}_1+c_2 \\boldsymbol{v}_2+\\cdots+c_k \\boldsymbol{v}_k=\\mathbf{0} \\Rightarrow c_1=\\cdots=c_k=0\\). Also can be shown by seeing the vectors as column vectors and checking if all columns are pivot.</p> <p>Dimension Theorem: Let \\(A\\) be a \\(m \\times n\\) matrix. Then \\(\\operatorname{rank}(A)+\\operatorname{nullity}(A)=n\\)</p>"},{"location":"Year%201%20Semester%202/MA2001/MA2001%20Final%20Note/#orthogonality","title":"Orthogonality","text":"<p>Gram-Schmidt Process: Let \\(\\left\\{\\boldsymbol{u}_1, \\boldsymbol{u}_2, \\ldots, \\boldsymbol{u}_k\\right\\}\\) be a basis for a vector space \\(V\\). </p> \\[\\begin{aligned} &amp; \\boldsymbol{v}_1=\\boldsymbol{u}_1 \\\\ &amp; \\boldsymbol{v}_2=\\boldsymbol{u}_2-\\frac{\\boldsymbol{u}_2 \\cdot \\boldsymbol{v}_1}{\\boldsymbol{v}_1 \\cdot \\boldsymbol{v}_1} \\boldsymbol{v}_1 \\\\ &amp; \\boldsymbol{v}_3=\\boldsymbol{u}_3-\\frac{\\boldsymbol{u}_3 \\cdot \\boldsymbol{v}_1}{\\boldsymbol{v}_1 \\cdot \\boldsymbol{v}_1} \\boldsymbol{v}_1-\\frac{\\boldsymbol{u}_3 \\cdot \\boldsymbol{v}_2}{\\boldsymbol{v}_2 \\cdot \\boldsymbol{v}_2} \\boldsymbol{v}_2 \\\\ &amp; \\vdots \\quad \\quad \\quad \\vdots \\\\ &amp; \\boldsymbol{v}_k=\\boldsymbol{u}_k-\\frac{\\boldsymbol{u}_k \\cdot \\boldsymbol{v}_1}{\\boldsymbol{v}_1 \\cdot \\boldsymbol{v}_1} \\boldsymbol{v}_1-\\frac{\\boldsymbol{u}_k \\cdot \\boldsymbol{v}_2}{\\boldsymbol{v}_2 \\cdot \\boldsymbol{v}_2} \\boldsymbol{v}_2-\\cdots-\\frac{\\boldsymbol{u}_k \\cdot \\boldsymbol{v}_{k-1}}{\\boldsymbol{v}_{k-1} \\cdot \\boldsymbol{v}_{k-1}} \\boldsymbol{v}_{k-1}\\end{aligned}\\] <p>Make sure to normalize if you want to find a orthonormal  basis.a</p> <p>Projection: Let \\(\\left\\{\\boldsymbol{u}_1, \\boldsymbol{u}_2, \\ldots, \\boldsymbol{u}_k\\right\\}\\) be an orthogonal basis for a vector space \\(V\\). The projection of \\(w\\) onto \\(V\\) is</p> \\[\\left(\\frac{\\boldsymbol{w} \\cdot \\boldsymbol{u}_1}{\\boldsymbol{u}_1 \\cdot \\boldsymbol{u}_1}\\right) \\boldsymbol{u}_1+\\left(\\frac{\\boldsymbol{w} \\cdot \\boldsymbol{u}_2}{\\boldsymbol{u}_2 \\cdot \\boldsymbol{u}_2}\\right) \\boldsymbol{u}_2+\\cdots+\\left(\\frac{\\boldsymbol{w} \\cdot \\boldsymbol{u}_k}{\\boldsymbol{u}_k \\cdot \\boldsymbol{u}_k}\\right) \\boldsymbol{u}_k\\] <p>Projection (other method): Suppose \\(V=\\operatorname{span}\\left\\{\\boldsymbol{a}_1, \\ldots, \\boldsymbol{a}_n\\right\\}\\).</p> <ul> <li>Write \\(\\boldsymbol{A}=\\left(\\begin{array}{lll}\\boldsymbol{a}_1 &amp; \\cdots &amp; \\boldsymbol{a}_n\\end{array}\\right)\\), each \\(\\boldsymbol{a}_j\\) is a column vector.</li> <li>Find a least squares solution \\(\\boldsymbol{u}\\) to \\(\\boldsymbol{A x}=\\boldsymbol{b}\\). i.e., a solution \\(\\boldsymbol{u}\\) to \\(\\boldsymbol{A}^{\\mathrm{T}} \\boldsymbol{A} \\boldsymbol{x}=\\boldsymbol{A}^{\\mathrm{T}} \\boldsymbol{b}\\).</li> <li>The projection of \\(\\boldsymbol{b}\\) onto \\(V\\) is \\(\\boldsymbol{p}=\\boldsymbol{A} \\boldsymbol{u}\\).</li> </ul> <p>To find the shortest distance from \\(u\\) point to \\(V\\): </p> <ol> <li>Find the orthogonal basis</li> <li>Find the projection of \\(u\\) onto \\(V\\)</li> <li>Find the distance \\(\\mid \\mid Av-u\\mid \\mid\\) where \\(v\\) is the LSS</li> </ol> <p>Least Square Solution of \\(Ax=b\\):</p> <ul> <li>Find the column space of \\(A\\)</li> <li>Find the projection of \\(b\\) onto the column space</li> <li>Solve \\(Ax=p\\)</li> <li>Or just solve \\(A^TAx=A^Tb\\)</li> </ul> <p>Orthogonal matrix: Square matrix \\(A\\) is called an orthogonal matrix if \\(A^TA=I\\). Equivalently \\(A^{-1}=A^T\\).</p> <p>\\(\\Leftrightarrow\\) columns of \\(\\boldsymbol{A}\\) form an orthonormal basis for \\(\\mathbb{R}^n\\). \\(\\Leftrightarrow\\) rows of \\(\\boldsymbol{A}\\) form an orthonormal basis for \\(\\mathbb{R}^n\\).</p>"},{"location":"Year%201%20Semester%202/MA2001/MA2001%20Final%20Note/#diagonalization","title":"Diagonalization","text":"<p>Eigenvalue and Eigenvector: \\(Av=\\lambda v\\) </p> <p>Algebraic Multiplicities: The algebraic multiplicity always adds up to n.</p> <p>Diagonalization: Let \\(\\boldsymbol{A}\\) be a square matrix of order \\(n\\). 1. Solve \\(\\operatorname{det}(\\lambda \\boldsymbol{I}-\\boldsymbol{A})=0\\) to find eigenvalues of \\(\\boldsymbol{A}\\). 2. For each eigenvalue \\(\\lambda_i\\) of \\(\\boldsymbol{A}\\),    - find a basis \\(S_i\\) for the eigenspace \\(E_{\\lambda_i}\\). $$ \\begin{aligned} &amp; \\boldsymbol{A} \\text { is diagonalizable } \\Leftrightarrow\\left|S_1\\right|+\\cdots+\\left|S_k\\right|=n, \\ &amp; \\boldsymbol{A} \\text { is not diagonalizable } \\Leftrightarrow\\left|S_1\\right|+\\cdots+\\left|S_k\\right|&lt;n . \\end{aligned} $$</p> <p>Suppose \\(\\boldsymbol{A}\\) is diagonalizable. Then - \\(S_1 \\cup \\cdots \\cup S_k=\\left\\{\\boldsymbol{v}_1, \\ldots, \\boldsymbol{v}_n\\right\\}\\) is a basis for \\(\\mathbb{R}^n\\). - \\(\\boldsymbol{A}\\) is diagonalized by \\(\\boldsymbol{P}=\\left(\\begin{array}{lll}\\boldsymbol{v}_1 &amp; \\cdots &amp; \\boldsymbol{v}_n\\end{array}\\right)\\).</p> <p>Key things to know:  For \\(\\boldsymbol{P}^{-1} \\boldsymbol{A} \\boldsymbol{P}=\\boldsymbol{D}\\), if we want to calculate for \\(\\boldsymbol{A^n}\\), \\(\\boldsymbol{P}\\) stays the same but \\(\\boldsymbol{D^n}\\).</p> <p>Orthogonally diagonalize symmetric matrix: Find eigenvalues \\(\\to\\) find orthonormal basis for each eigenspace by Gram-Schmidt Process.</p>"},{"location":"Year%201%20Semester%202/MA2001/MA2001%20Final%20Note/#linear-transformation","title":"Linear Transformation","text":"<p>Standard Matrix: \\(T(\\boldsymbol{x})=\\boldsymbol{A x}\\)</p> <p>Property: \\(T \\circ S: \\mathbb{R}^n \\rightarrow \\mathbb{R}^k\\) is a linear transformation and its standard matrix is \\(\\boldsymbol{B} \\boldsymbol{A}\\).</p> <p>Range: \\(T\\left(\\left(\\begin{array}{l}x \\\\ y\\end{array}\\right)\\right)=\\left(\\begin{array}{c}x+y \\\\ y \\\\ x\\end{array}\\right)\\) </p> <ul> <li>Use the standard basis:   \\(T\\left(\\left(\\begin{array}{l}1 \\\\ 0\\end{array}\\right)\\right)=\\left(\\begin{array}{l}1 \\\\ 0 \\\\ 1\\end{array}\\right), \\quad T\\left(\\left(\\begin{array}{l}0 \\\\ 1\\end{array}\\right)\\right)=\\left(\\begin{array}{l}1 \\\\ 1 \\\\ 0\\end{array}\\right)\\).   \\(R(T)=\\operatorname{span}\\left\\{\\left(\\begin{array}{l}1 \\\\ 0 \\\\ 1\\end{array}\\right),\\left(\\begin{array}{l}1 \\\\ 1 \\\\ 0\\end{array}\\right)\\right\\}\\)</li> </ul> <p>\\(\\mathrm{R}(T)=\\) column space of \\(\\boldsymbol{A}\\).  \\(\\operatorname{rank}(T)=\\operatorname{dim} \\mathrm{R}(T)=\\operatorname{dim}\\) (coln space of \\(\\boldsymbol{A})=\\operatorname{rank}(\\boldsymbol{A})\\)</p> <p>Kernel: \\(\\operatorname{Ker}(T)=\\left\\{\\boldsymbol{v} \\in \\mathbb{R}^n \\mid T(\\boldsymbol{v})=\\boldsymbol{0}\\right\\} \\subseteq \\mathbb{R}^n\\)</p> <p>Properties:</p> <ul> <li>\\(\\mathrm{R}(T)=\\) column space of \\(\\boldsymbol{A}\\).<ul> <li>\\(\\operatorname{rank}(T)=\\operatorname{rank}(\\boldsymbol{A})\\).</li> </ul> </li> <li>\\(\\operatorname{Ker}(T)=\\) nullspace of \\(\\boldsymbol{A}\\).<ul> <li>\\(\\operatorname{nullity}(T)=\\operatorname{nullity}(\\boldsymbol{A})\\).</li> </ul> </li> <li>Recall Dimension Theorem for Matrices:<ul> <li>\\(\\operatorname{rank}(\\boldsymbol{A})+\\operatorname{nullity}(\\boldsymbol{A})=\\) number of colns of \\(\\boldsymbol{A}=n\\).</li> <li>\\(\\therefore \\operatorname{rank}(T)+\\operatorname{nullity}(T)=n=\\) dimension of domain.</li> </ul> </li> </ul>"},{"location":"Year%201%20Semester%202/MA2001/MA2001%20Final%20Note/#main-theorem-for-invertible-matrices","title":"Main theorem for invertible matrices","text":"<p>Theorem. Let \\(\\boldsymbol{A}\\) be a square matrix of order \\(n\\). Then the following are equivalent:</p> <ol> <li>\\(A\\) is invertible.</li> <li>The reduced row-echelon form of \\(\\boldsymbol{A}\\) is \\(\\boldsymbol{I}_n\\).</li> <li>The homogeneous linear system \\(\\boldsymbol{A x}=\\mathbf{0}\\) has only the trivial solution.</li> <li>The linear system \\(\\boldsymbol{A} \\boldsymbol{x}=\\boldsymbol{b}\\) has exactly one solution.</li> <li>\\(A\\) is the product of elementary matrices.</li> <li>\\(\\operatorname{det}(\\boldsymbol{A}) \\neq 0\\).</li> <li>The rows of \\(A\\) form a basis for \\(\\mathbb{R}^n\\).</li> <li>The columns of \\(\\boldsymbol{A}\\) form a basis for \\(\\mathbb{R}^n\\).</li> <li>\\(\\operatorname{rank}(\\boldsymbol{A})=n\\).</li> <li>0 is not an eigenvalue of \\(\\boldsymbol{A}\\).</li> <li>For standard matrix \\(\\boldsymbol{A}\\) of \\(T\\): \\(\\boldsymbol{A} = \\operatorname{Ker}(T)={0}\\)</li> </ol>"},{"location":"Year%201%20Semester%202/MA2001/MA2001%20Final%20Note/#examples","title":"Examples","text":"<p>Consider the vector equation $$ c_1 \\boldsymbol{w}1+c_2 \\boldsymbol{w}_2+c_3 \\boldsymbol{w}_3=\\mathbf{0} $$ Substituting \\(w_1=v_1+2 v_2, w_2=v_2+2 v_3\\) and \\(w_3=v_3\\) into \\((\\dagger)\\), we have $$ \\begin{aligned} &amp; c_1\\left(\\boldsymbol{v}}+2 \\boldsymbol{v}{\\mathbf{2}}\\right)+c_2\\left(\\boldsymbol{v}}+2 \\boldsymbol{v}{\\mathbf{3}}\\right)+c_3 \\boldsymbol{v}}=\\mathbf{0} \\ \\Rightarrow \\quad &amp; c_1 \\boldsymbol{v}{\\mathbf{1}}+\\left(2 c_1+c_2\\right) \\boldsymbol{v}}+\\left(2 c_2+c_3\\right) \\boldsymbol{v}_{\\mathbf{1}}=\\mathbf{0} . \\end{aligned} $$ Since \\(S\\) is linearly independent, the coefficients in the equation ( \\(\\ddagger\\) ) must be all zero, i.e. $$ \\left{\\begin{aligned} c_1 &amp; =0 \\ 2 c_1+c_2 &amp; =0 \\ 2 c_2+c_3 &amp; =0 \\end{aligned}\\right. $$ which implies \\(c_1=0, c_2=0, c_3=0\\). Since the equation \\((\\dagger)\\) has only the trivial solution, \\(T\\) is linearly independent. On the other hand, \\(|T|=|S|=\\operatorname{dim}(W)\\). We conclude that \\(T\\) is a basis for \\(W\\).</p>"},{"location":"Year%201%20Semester%202/MA2001/MA2001/","title":"MA2001 Linear Algebra I","text":"<p>NUS MODS Canvas</p> <p>This module is a first course in linear algebra. Fundamental concepts of linear algebra will be introduced and investigated in the context of the Euclidean spaces R^n. Proofs of results will be presented in the concrete setting. Students are expected to acquire computational facilities and geometric intuition with regard to vectors and matrices. Some applications will be presented. Major topics Systems of linear equations, matrices, determinants, Euclidean spaces, linear combinations and linear span, subspaces, linear independence, bases and dimension, rank of a matrix, inner products, eigenvalues and eigenvectors, diagonalization, linear transformations between Euclidean spaces, applications.</p> <p>MathLab</p>"},{"location":"Year%201%20Semester%202/MA2001/MA2001/#notes","title":"Notes","text":"Week Notes Summary Tutorial 1 MA2001-Chapter1 01 Linear Systems &amp; Gaussian Elimination - 2 MA2001-Chapter2 02 Matrices - 3 MA2001_HW1 - Tut 1 4 MATLAB Lesson1 - Tut 2 5 MA2001-Chapter3 03 Vector Spaces Tut 3 6 MATLAB Lesson2 - tut 4 Recess MA2001_HW2 - - 7 MA2001-Chapter4 - tut 5 8 MA2001-Chapter5 04 Orthogonality tut 6 9 MA2001_HW3 - tut 7 10 MA2001-Chapter6 05 Diagonalization tut 8 11 MA2001-Chapter7 06 Linear Transformations tut 9 12 MA2001_HW4 - tut 10 13 - - tut 11"},{"location":"Year%201%20Semester%202/MA2001/MA2001/#textbook","title":"TextBook","text":"<p>linear-algebra-concepts-and-techniques-on-euclidean-spaces Solution and tutorial exercises</p>"},{"location":"Year%201%20Semester%202/MA2001/MA2001/#mid-term","title":"Mid term","text":"<ol> <li>The test covers all materials up to and including Chapter 3.3: Subspaces, Tutorial 1-4, and Homework 1-2.\u00a0 MATALB is not tested.</li> <li>This an open book test.\u00a0 All hardcopy of materials can be used.\u00a0 No electronic device can be used except non-graphing calculators.</li> <li>You may use blue or black colour pen or pencil in the test.</li> </ol> <p>MA2001 Midterm note MA2001(2021Sem2)Test MA2001(2021Sem2)Test-Q4Ans</p>"},{"location":"Year%201%20Semester%202/MA2001/MA2001/#finals","title":"Finals","text":"Past paper Solution PastPapers PastPapersSol ma2001_2021s1_final ma2001_2021s1_final_solution ma2001_1920s1_final ma2001_1920s1_final_solution ma2001_1415s2_final ma2001_1415s2_final_solution ma2001_1415s1_final ma2001_1415s1_final_solution <p>MA2001 Final Note</p>"},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW1/","title":"HW1 Written","text":"<p>Moon Ji HoonA0255555X</p>"},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW1/#question-1","title":"Question 1","text":"\\[ \\begin{aligned} a x+y+z &amp; =a^3 \\\\ x+a y+z &amp; =1 \\\\ x+y+a z &amp; =a \\end{aligned} \\] <p>Into Augmented matrix: $$ \\left(\\begin{array}{lll|l} a &amp; 1 &amp; 1 &amp; a^3 \\ 1 &amp; a &amp; 1 &amp; 1 \\ 1 &amp; 1 &amp; a &amp; a \\end{array}\\right) $$ Into row-echelon form: When \\(a \\neq 0\\) and \\(a \\neq-1\\)  $$ \\begin{aligned} &amp; \\stackrel{R_3-R_2}{\\longrightarrow}\\left(\\begin{array}{ccc|c} a &amp; 1 &amp; 1 &amp; a^3 \\ 1 &amp; a &amp; 1 &amp; 1 \\ 0 &amp; 1-a &amp; a-1 &amp; a-1 \\end{array}\\right) \\ &amp; R_2 \\longleftrightarrow R_1\\left(\\begin{array}{ccc|c} 1 &amp; a &amp; 1 &amp; 1 \\ a &amp; 1 &amp; 1 &amp; a^3 \\ 0 &amp; 1-a &amp; a-1 &amp; a-1 \\end{array}\\right) \\ &amp; \\stackrel{R_2-a R_1}{\\longrightarrow}\\left(\\begin{array}{ccc|c} 1 &amp; a &amp; 1 &amp; 1 \\ 0 &amp; 1-a^2 &amp; 1-a &amp; a^3-a \\ 0 &amp; 1-a &amp; a-1 &amp; a-1 \\end{array}\\right) \\ &amp; \\stackrel{(1+a) R_3}{\\longrightarrow}\\left(\\begin{array}{ccc|c} 1 &amp; a &amp; 1 &amp; 1 \\ 0 &amp; 1-a^2 &amp; 1-a &amp; a^3-a \\ 0 &amp; 1-a^2 &amp; a^2-1 &amp; a^2-1 \\end{array}\\right) \\ &amp; \\stackrel{R_3-R_2}{\\longrightarrow}\\left(\\begin{array}{ccc|c} 1 &amp; a &amp; 1 &amp; 1 \\ 0 &amp; 1-a^2 &amp; 1-a &amp; a^3-a \\ 0 &amp; 0 &amp; a^2+a-2 &amp; -a3+a2+a-1 \\end{array}\\right) \\end{aligned} $$</p> <p>When \\(a=0\\), there is a unique solution. $$ \\left(\\begin{array}{lll|l} a &amp; 1 &amp; 1 &amp; a^3 \\ 1 &amp; a &amp; 1 &amp; 1 \\ 1 &amp; 1 &amp; a &amp; a \\end{array}\\right)=\\left(\\begin{array}{lll|l} 0 &amp; 1 &amp; 1 &amp; 0 \\ 1 &amp; 0 &amp; 1 &amp; 1 \\ 1 &amp; 1 &amp; 0 &amp; 0 \\end{array}\\right)=\\left(\\begin{array}{lll|l} 1 &amp; 0 &amp; 1 &amp; 1 \\ 0 &amp; 1 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 1 &amp; \\frac{1}{2} \\end{array}\\right) $$</p> <p>When \\(a=-1\\), there is a unique solution.</p> \\[ \\left(\\begin{array}{ccc|c} a &amp; 1 &amp; 1 &amp; a^3 \\\\ 1 &amp; a &amp; 1 &amp; 1 \\\\ 1 &amp; 1 &amp; a &amp; a \\end{array}\\right)=\\left(\\begin{array}{ccc|c} -1 &amp; 1 &amp; 1 &amp; -1 \\\\ 1 &amp; -1 &amp; 1 &amp; 1 \\\\ 1 &amp; 1 &amp; -1 &amp; -1 \\end{array}\\right)=\\left(\\begin{array}{ccc|c} 1 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 &amp; \\frac{1}{2} \\end{array}\\right) \\] <p>Taking consideration when \\(a=0\\) and \\(a\\neq-1\\),  the condition for no solution, unique solution and infinitely many solutions can be obtained:</p>"},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW1/#1-no-solution","title":"1 No solution","text":"<p>The last column is a pivot column.</p> <p>\\(a^2+a-2=0 ,\\quad -a^3+a^2+a-1 \\neq 0\\) \\((a+2)(a-1)=0 ,\\quad  a \\neq-1 ,1\\)</p> <p>There is no solution when \\(a=-2\\) </p>"},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW1/#2-a-unique-solution","title":"2 A unique solution","text":"<p>The last column is a non-pivot column. All other columns are pivot columns.</p> <p>\\(a^2+a-2 \\neq 0 \\quad\\) \\(1-a^2 \\neq 0 \\quad\\) </p> <p>There is a unique solution when \\(a \\neq 1,-2\\)</p>"},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW1/#3-infinitely-many-solutions","title":"3 Infinitely many solutions","text":"<p>The last column is a non pivot column. Some columns are non pivot columns.</p> <p>\\(a^2+a-2 \\neq 0\\) or \\(a = 1\\) \\(1-a^2 =  0\\)</p> <p>The system has infinitely many solutions when  \\(a=1\\) </p>"},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW1/#question-2","title":"Question 2","text":"<p>$$ A=\\left(\\begin{array}{ccc} b &amp; b &amp; 1 \\ a &amp; -a &amp; 0 \\ a - 2 &amp; a+1 &amp; 0 \\end{array}\\right) $$ $$ \\begin{aligned} \\operatorname{det}(A) &amp; =b\\left|\\begin{array}{cc} -a &amp; 0 \\ a+1 &amp; 0 \\end{array}\\right|-b\\left|\\begin{array}{cc} a &amp; 0 \\ a-2 &amp; 0 \\end{array}\\right|+\\left|\\begin{array}{cc} a &amp; -a \\ a-2 &amp; a+1 \\end{array}\\right| \\ &amp; =b(0-0)-b(0-0)+\\left(a2+a-(-a2+2 a)\\right) \\ &amp; =2a^2-a \\ &amp; =a(2a-1) \\end{aligned} $$ \\(A\\) is invertible iff  \\(\\det(\\mathrm{A}) \\neq 0\\). Hence \\(a \\neq 0,a \\neq \\frac{1}{2} \\quad b \\in \\mathbb{R}\\).</p>"},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW1/#question-3","title":"Question 3","text":"\\[ \\begin{aligned} B &amp; =\\left(\\begin{array}{ccc} 1 &amp; -1 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\end{array}\\right)^{-1}\\left(\\begin{array}{lll} 0 &amp; 0 &amp; 1 \\\\ 0 &amp; 1 &amp; 0 \\\\ 1 &amp; 0 &amp; 0 \\end{array}\\right)^{-1}\\left(\\begin{array}{lll} 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 2 \\end{array}\\right)^{-1} A \\\\ &amp; =\\left(\\begin{array}{lll} 1 &amp; 1 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\end{array}\\right)\\left(\\begin{array}{lll} 0 &amp; 0 &amp; 1 \\\\ 0 &amp; 1 &amp; 0 \\\\ 1 &amp; 0 &amp; 0 \\end{array}\\right)\\left(\\begin{array}{lll} 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; \\frac{1}{2} \\end{array}\\right) A \\end{aligned} \\] <p>Hence, \\(B\\) can be obtained with the following elementary row operations on \\(A\\):</p> <ol> <li>\\(\\frac{1}{2}R_{3}\\)</li> <li>\\(R_{1}\\leftrightarrow R_{3}\\)</li> <li>\\(R_{1}+R_{2}\\)</li> </ol>"},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW1/#question-4","title":"Question 4","text":"<p>Suppose \\(A=\\left(a_{i j}\\right)_{m \\times n}\\) and \\(B=\\left(b_{i j}\\right)_{n \\times p}\\).</p> <p>Then, the \\((i, j)\\)-entry of \\(A B: \\sum_{k=1}^n a_{i k} b_{k j}\\).</p> <ol> <li>Suppose \\(A\\) has a zero row.<ol> <li>Then there exists \\(i_0\\) such that \\(a_{i_0 j}=0\\) for all \\(j\\). </li> <li>Thus the \\(\\left(i_0, j\\right)\\)-entry of \\(A B: \\sum_{k=1}^n a_{i_0 k} b_{k j}=0\\) for all \\(j\\). </li> </ol> </li> <li>Therefore \\(AB\\) has a zero row as well.</li> </ol>"},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW1/#question-5","title":"Question 5","text":"<p>Since \\(A\\) is a square matrix, for every square matrix \\(B\\) of order \\(n\\):  \\(\\(\\operatorname{det}(A B)=\\operatorname{det}(A) \\operatorname{det}(B)=0 \\times \\operatorname{det}(B)=0\\)\\) Hence \\(A B\\) is singular.</p>"},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW1/#question-6","title":"Question 6","text":"\\[A=\\left(\\begin{array}{lll}0 &amp; 0 &amp; 1 \\\\ 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0\\end{array}\\right)\\]"},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW1/#question-7","title":"Question 7","text":"<p>$$ A=\\left(\\begin{array}{ll} 1 &amp; 0 \\ 0 &amp; 0 \\end{array}\\right) $$ \\(\\operatorname{det}(A)=0\\), hence \\(A\\) is not invertible. Therefore \\(A\\) is not a product of elementary matrices.</p>"},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW1/#question-8","title":"Question 8","text":"<p>If \\(A\\) and \\(B\\) are symmetric, \\(A=A^{T}\\) and \\(B=B^{T}\\). Therefore:  $$ (A+B){T}=A+B^{T}=A+B $$</p>"},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW1/#question-9","title":"Question 9","text":""},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW1/#1-a-is-a-square-matrix","title":"1. \\(A\\) is a square matrix","text":"<p>Suppose \\(A=\\left(a_{i j}\\right)_{n \\times m}\\) such that \\(A^T=kA\\).</p> <ol> <li>\\(A^T\\) has size \\(m \\times n\\). </li> <li>Hence the size of \\(kA\\) (\\(n\\times m\\)) has to be equal to \\(m\\times n\\)</li> <li>Therefore \\(n=m\\).</li> <li>\\(A\\) is a square matrix.</li> </ol>"},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW1/#2-k-1-or-k-1","title":"2.  \\(k = 1\\) or \\(k = -1\\)","text":"\\[\\begin{aligned} &amp; A^T=k A \\\\ &amp; \\left(A^T\\right)^T=(k A)^T \\\\ &amp; A=k A^T \\\\ &amp; A=k^2 A \\\\ &amp; k=\\pm 1\\end{aligned}\\]"},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW2/","title":"HW2 Written","text":"<p>Moon Ji HoonA0255555X</p>"},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW2/#question-1","title":"Question 1","text":"<p>Let \\(V\\) be a subset of \\(\\mathbb{R}^n\\). A subspace \\(V\\) is of the form \\(\\operatorname{span}(S)\\):</p> <ul> <li>\\(0 \\in V\\),</li> <li>\\(c \\in \\mathbb{R}\\) &amp; \\(v \\in V\\) \\(\\Rightarrow c v \\in V\\),</li> <li>\\(u \\in V\\) &amp; \\(v \\in V \\Rightarrow u + v \\in V\\)</li> </ul> <p>Since there exists vectors \\(v_1, v_2 \\in V\\) such that \\(v_1-2 v_2 \\notin V\\), it fails the third criteria. Hence, \\(V\\) is not a subspace of \\(\\mathbb{R}^n\\).</p>"},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW2/#questions-2","title":"Questions 2","text":""},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW2/#1-operatornamespanleftboldsymbolu_mathbf1-boldsymbolu_mathbf2-boldsymbolu_boldsymbol3-boldsymbolu_mathbf4rightmathbbr3","title":"1.  \\(\\operatorname{span}\\left\\{\\boldsymbol{u}_{\\mathbf{1}}, \\boldsymbol{u}_{\\mathbf{2}}, \\boldsymbol{u}_{\\boldsymbol{3}}, \\boldsymbol{u}_{\\mathbf{4}}\\right\\}=\\mathbb{R}^3\\)","text":"\\[\\left(\\begin{array}{cccc}-3 &amp; 1 &amp; 1 &amp; 0 \\\\ 0 &amp; 4 &amp; 2 &amp; 3 \\\\ 2 &amp; 0 &amp; -1 &amp; -2\\end{array}\\right) \\underset{\\text { Elimination }}{\\stackrel{\\text { Gaussian }}{\\longrightarrow}}\\left(\\begin{array}{cccc}-3 &amp; 1 &amp; 1 &amp; 0 \\\\ 0 &amp; 4 &amp; 2 &amp; 3 \\\\ 0 &amp; 0 &amp; -\\frac{2}{3} &amp; -\\frac{2}{5}\\end{array}\\right)\\] <p>It has no zero row, hence \\(\\operatorname{span}\\left\\{\\boldsymbol{u}_{\\mathbf{1}}, \\boldsymbol{u}_{\\mathbf{2}}, \\boldsymbol{u}_{\\boldsymbol{3}}, \\boldsymbol{u}_{\\mathbf{4}}\\right\\}=\\mathbb{R}^3\\)</p>"},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW2/#2-operatornamespanleftboldsymbolu_boldsymbol1-boldsymbolu_boldsymbol2-boldsymbolu_boldsymbol3rightmathbbr3","title":"2. \\(\\operatorname{span}\\left\\{\\boldsymbol{u}_{\\boldsymbol{1}}, \\boldsymbol{u}_{\\boldsymbol{2}}, \\boldsymbol{u}_{\\boldsymbol{3}}\\right\\}=\\mathbb{R}^3\\)","text":"\\[\\left(\\begin{array}{cccc}-3 &amp; 1 &amp; 1 \\\\ 0 &amp; 4 &amp; 2 \\\\ 2 &amp; 0 &amp; -1 \\end{array}\\right) \\underset{\\text { Elimination }}{\\stackrel{\\text { Gaussian }}{\\longrightarrow}}\\left(\\begin{array}{cccc}-3 &amp; 1 &amp; 1  \\\\ 0 &amp; 4 &amp; 2 \\\\ 0 &amp; 0 &amp; -\\frac{2}{3}\\end{array}\\right)\\] <p>It has no zero row, hence \\(\\operatorname{span}\\left\\{\\boldsymbol{u}_{\\boldsymbol{1}}, \\boldsymbol{u}_{\\boldsymbol{2}}, \\boldsymbol{u}_{\\boldsymbol{3}}\\right\\}=\\mathbb{R}^3 ?\\)</p>"},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW2/#3-operatornamespanleftboldsymbolu_1-boldsymbolu_2rightneqmathbbr3","title":"3.  \\(\\operatorname{span}\\left\\{\\boldsymbol{u}_1, \\boldsymbol{u}_2\\right\\}\\neq\\mathbb{R}^3\\)","text":"<p>Two vectors cannot span \\(\\mathbb{R}^3\\):</p> \\[\\left(\\begin{array}{cccc}-3 &amp; 1 \\\\ 0 &amp; 4  \\\\ 2 &amp; 0 \\end{array}\\right) \\underset{\\text { Elimination }}{\\stackrel{\\text { Gaussian }}{\\longrightarrow}}\\left(\\begin{array}{cccc}-3 &amp; 1  \\\\ 0 &amp; 4 \\\\ 0 &amp; 0 \\end{array}\\right)\\] <p>It has a zero row, hence \\(\\operatorname{span}\\left\\{\\boldsymbol{u}_1, \\boldsymbol{u}_2\\right\\}\\neq\\mathbb{R}^3\\). </p>"},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW2/#question-3","title":"Question 3","text":"<p>Suppose  \\(A=\\left(a_{i j}\\right)_{m \\times n}\\) such that \\(Ax = 0\\) for all \\(x \\in \\mathbb{R}^n\\). Let \\(E=\\left\\{\\boldsymbol{e}_1, \\boldsymbol{e}_2, \\ldots, \\boldsymbol{e}_n\\right\\}\\) be a standard basis for \\(\\mathbb{R}^n\\). </p> <p>Then for all \\(e_{i}\\), \\(Ae_{i}\\) is equal to the \\(i^{th}\\) column of \\(A\\). Therefore every column of \\(A\\) is zero, i.e \\(A=0\\)</p>"},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW2/#question-4","title":"Question 4","text":""},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW2/#1-implicit-form-of-v","title":"1. Implicit form of \\(V\\)","text":"<p>\\(V=\\{(t, 2 t, 3 t-1) \\mid t \\in \\mathbb{R}\\}\\)</p> <p>Let \\(x = t\\), \\(y=2t\\), \\(z=3t-1\\).</p> \\[\\left(\\begin{array}{c|c}1 &amp; x \\\\ 1 &amp; \\frac{y}{2} \\\\ 1 &amp; \\frac{{z+1}}{3} \\end{array}\\right) \\underset{\\text { elimination }}{\\stackrel{\\text { Gaussian }}{\\longrightarrow}}\\left(\\begin{array}{c|c}1 &amp; x \\\\ 0 &amp; \\frac{y}{2}-x \\\\ 0 &amp; \\frac{{z+1}}{3}-x \\end{array}\\right)\\] <p>The system is consistent. Therefore \\(\\frac{y}{2}-x=0\\), \\(\\frac{{z+1}}{3}-x=0\\)</p> <p>Implicit form: \\(\\{(x, y, z) \\mid y-2x=0\\text{ } \\&amp;\\text{ } z-3x=-1\\}\\)</p>"},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW2/#2-is-there-a-homogeneous-linear-system-whose-solution-set-is-v","title":"2. Is there a homogeneous linear system whose solution set is \\(V\\) ?","text":"<p>No. A linear system is homogenous if every linear equation of the system is homogenous. However, there is a non-zero constant term  in \\(z-3x=-1\\).</p>"},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW2/#question-5","title":"Question 5","text":""},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW2/#1-solution-set-of-the-given-homogeneous-linear-system-is-a-subspace-of-mathbbr5","title":"1. Solution set of the given homogeneous linear system is a subspace of \\(\\mathbb{R}^5\\).","text":"<p>Theorem: The solution set of a homogenous linear system of \\(n\\) variables is a subspace of \\(\\mathbb{R}^n\\).</p> <p>\\(A\\) into reduced row echelon form: </p> \\[\\left(\\begin{array}{ccccc}2 &amp; 3 &amp; 1 &amp; -1 &amp; 2 \\\\ -2 &amp; 0 &amp; -2 &amp; 1 &amp; -1 \\\\ 2 &amp; 2 &amp; -2 &amp; 2 &amp; 0\\end{array}\\right) \\underset{\\text { elimination }}{\\stackrel{\\text { Gaussian }}{\\longrightarrow}}\\left(\\begin{array}{ccccc}1 &amp; 0 &amp; 0 &amp; \\frac{2}{5} &amp; 0 \\\\ 0 &amp; 1 &amp; 0 &amp; -\\frac{3}{10} &amp; \\frac{1}{2} \\\\ 0 &amp; 0 &amp; 1 &amp; -\\frac{9}{10} &amp; \\frac{1}{2}\\end{array}\\right)\\] <p>The system has infinitely many solutions:</p> <p>\\((x_{1},x_{2},x_{3},x_{4},x_{5})=\\left( -\\frac{2}{5}s, \\frac{3}{10}s-\\frac{1}{2}t, \\frac{9}{10}s-\\frac{1}{2}t, s, t \\right)\\)</p> <p>\\(=s\\left( -\\frac{2}{5}, \\frac{3}{10}, \\frac{9}{10}, 1, 0 \\right)+t\\left( 0, -\\frac{1}{2},-\\frac{1}{2},0,1 \\right)\\)</p> <p>The solution space is \\(\\operatorname{span}\\left( -\\frac{2}{5}, \\frac{3}{10}, \\frac{9}{10}, 1, 0 \\right)+\\left( 0, -\\frac{1}{2},-\\frac{1}{2},0,1 \\right)\\). So the solution set is a subspace of \\(\\mathbb{R}^5\\)</p>"},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW2/#2-boldsymbola-boldsymbolxboldsymbolb-where-boldsymbolbleftbeginarrayc1-2-2endarrayright","title":"2. \\(\\boldsymbol{A} \\boldsymbol{x}=\\boldsymbol{b}\\), where \\(\\boldsymbol{b}=\\left(\\begin{array}{c}1 \\\\ -2 \\\\ -2\\end{array}\\right)\\)","text":"<p>Column 3 in matrix \\(A\\) is equal to \\(b\\). Hence the row echelon form of the augmented matrix can be obtained by copying over the result of Gaussian elimination in column 3:</p> \\[ \\left(\\begin{array}{ccccc|c} 1 &amp; 0 &amp; 0 &amp; \\frac{2}{5} &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 &amp; -\\frac{3}{10} &amp; -\\frac{1}{2} &amp; 0\\\\ 0 &amp; 0 &amp; 1 &amp; -\\frac{9}{10} &amp; \\frac{1}{2} &amp; 1\\\\ \\end{array}\\right) \\] <p>The general solution to the linear system is the addition of the homogeneous solution (\\(Ax=0\\)) and the particular solution (\\(Ax=b\\)):</p> \\[(x_{1},x_{2},x_{3},x_{4},x_{5})=\\left( -\\frac{2}{5}s,\\frac{3}{10}s-\\frac{1}{2}t, 1+\\frac{9}{10}s-\\frac{1}{2}t, s, t \\right)\\]"},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW3/","title":"HW3 Written","text":"<p>Moon Ji HoonA0255555X</p>"},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW3/#1-compute-a-basis-for-the-nullspace-of","title":"1. Compute a basis for the nullspace of","text":"\\[\\boldsymbol{A}=\\left(\\begin{array}{ccccc}2 &amp; 2 &amp; 0 &amp; -2 &amp; 3 \\\\ -2 &amp; 3 &amp; -3 &amp; 3 &amp; -2 \\\\ 0 &amp; 4 &amp; -3 &amp; -2 &amp; 3 \\end{array}\\right)$$ $$(\\boldsymbol{A} \\mid \\mathbf{0}) \\stackrel{\\text { G.J. }}{\\longrightarrow}\\left(\\begin{array}{lllll|l}1 &amp; 0 &amp; 0 &amp; -4 &amp; \\frac{7}{2} &amp; 0 \\\\ 0 &amp; 1 &amp; 0 &amp; 3 &amp; -2 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 &amp; \\frac{14}{3} &amp; -\\frac{11}{3} &amp; 0 \\end{array}\\right)$$ $$\\boldsymbol{A} \\boldsymbol{x}=\\mathbf{0} \\Leftrightarrow \\boldsymbol{x}=\\left(\\begin{array}{c}4s-\\frac{7}{2}t \\\\ -3s+2t \\\\ -\\frac{14}{3}s+\\frac{11}{3}t \\\\ s \\\\ t\\end{array}\\right)=s\\left(\\begin{array}{c}4 \\\\ -3 \\\\ -\\frac{14}{3} \\\\ 1 \\\\ 0\\end{array}\\right)+t\\left(\\begin{array}{c}-\\frac{7}{2} \\\\ 2 \\\\ \\frac{11}{3} \\\\ 0 \\\\ 1\\end{array}\\right)\\] <p>Hence, a basis for the nullspace of \\(A\\) is given by \\(\\left\\{\\left( 4,-3,-\\frac{14}{3},1,0 \\right)^{\\mathrm{T}},\\left( -\\frac{7}{2},2,\\frac{11}{3},0,1 \\right)^{\\mathrm{T}}\\right\\}\\).</p>"},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW3/#2-computer-a-basis-for-the-vector-space","title":"2. Computer a basis for the vector space","text":"<p>\\(\\text{let } V=\\left\\{(s-2 t,-s-2 u, 3 s+t+5 u, 3 s-2 t+4 u) \\in \\mathbb{R}^4 \\mid s, t, u \\in \\mathbb{R}\\right\\}\\)</p> <p>Every vector in \\(V\\) is of the form</p> \\[s\\left(\\begin{array}{c}1 \\\\ -1 \\\\ 3 \\\\ 3 \\end{array}\\right)+t\\left(\\begin{array}{c}-2 \\\\ 0 \\\\ 1 \\\\ -2 \\end{array}\\right)+u\\left(\\begin{array}{c}0 \\\\ -2 \\\\ 5 \\\\ 4 \\end{array}\\right)\\] <p>Hence \\(V =\\text{span}\\{(1,-1,3-3),(-2,0,1,-2),(0,-2,5,4)\\}\\). </p> <p>To find the basis for the vector space \\(V\\), view each vector as a row vector and form a matrix:</p> \\[\\left(\\begin{array}{cccc}1 &amp; -1 &amp; 3 &amp; -3 \\\\ -2 &amp; 0 &amp; 1 &amp; -2 \\\\ 0 &amp; -2 &amp; 5 &amp; 4\\end{array}\\right) \\stackrel{R_2+2 R_1}{\\longrightarrow}\\left(\\begin{array}{cccc}1 &amp; -1 &amp; 3 &amp; -3 \\\\ 0 &amp; -2 &amp; 7 &amp; -8 \\\\ 0 &amp; -2 &amp; 5 &amp; 4\\end{array}\\right) \\stackrel{R_3-R_2}{\\longrightarrow}\\left(\\begin{array}{cccc}1 &amp; -1 &amp; 3 &amp; -3 \\\\ 0 &amp; -2 &amp; 7 &amp; -8 \\\\ 0 &amp; 0 &amp; -2 &amp; 12\\end{array}\\right)\\] <p>The above matrix have the same row space as \\(V\\) and the nonzero rows are linearly independent. Therefore, \\(V\\) has a basis \\(\\{(1,-1,3,-3),(0,-2,7,-8),(0,0,-2,12)\\}\\).</p>"},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW3/#3-prove-that-leftboldsymbolx-boldsymbola-boldsymbolx-boldsymbola2-boldsymbolxright-is-linearly-independent","title":"3. Prove that \\(\\left\\{\\boldsymbol{x}, \\boldsymbol{A} \\boldsymbol{x}, \\boldsymbol{A}^2 \\boldsymbol{x}\\right\\}\\) is linearly independent.","text":"<p>Suppose \\(\\boldsymbol{A}\\) is an \\(n \\times n\\) matrix and \\(\\boldsymbol{x}\\) is a vector in \\(\\mathbb{R}^n\\) such that \\(\\boldsymbol{A}^3 \\boldsymbol{x}=\\mathbf{0}\\) but \\(\\boldsymbol{A}^2 \\boldsymbol{x} \\neq \\mathbf{0}\\).</p> <p>Let \\(c_{1},c_{2},c_{3} \\in \\mathbb{R}\\) such that </p> \\[c_{1}x+c_{2}Ax+c_{3}A^2x=0\\] <p>Multiplying the equation by \\(A\\) gives:</p> \\[ \\begin{aligned} c_{1}Ax+c_{2}A^2x+c_{3}A^3x&amp;=0 \\\\ c_{1}Ax+c_{2}A^2x&amp;=0 \\end{aligned} \\] <p>Multiplying the equation again by \\(A\\) gives:</p> \\[ \\begin{aligned} c_{1}A^2x+c_{2}A^3x&amp;=0 \\\\ c_{1}A^2x&amp;=0 \\end{aligned} \\] <p>Since \\(A^2x\\neq 0\\), \\(c_{1}\\) must be 0. </p> <p>Substituting back to equation \\(c_{1}Ax+c_{2}A^2x=0\\) gives: </p> \\[ \\begin{aligned} c_{2}A^2x&amp;=0 \\end{aligned} \\] <p>Hence \\(c_{2}\\) must be 0 as \\(A^2x\\neq 0\\)</p> <p>Lastly, substituting \\(c_{1},c_{2}\\) to \\(c_{1}x+c_{2}Ax+c_{3}A^2x=0\\) gives:</p> <p>\\(\\(c_{3}A^2x=0\\)\\) \\(c_{3}\\) must be 0 as \\(A^2x\\neq 0\\).</p> <p>Since \\(c_{1}=c_{2}=c_{3}=0\\), the equation has only a trivial solution.  \\(\\{x,Ax,A^2x\\}\\) is linearly independent.</p>"},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW3/#4-suppose-m-is-the-matrix-leftbeginarrayllboldsymbola-boldsymbolb-hline-boldsymbolc-boldsymboldendarrayright-with-blocks-boldsymbola-boldsymbolb-boldsymbolc-boldsymbold","title":"4. Suppose \\(M\\) is the matrix \\(\\left(\\begin{array}{l|l}\\boldsymbol{A} &amp; \\boldsymbol{B} \\\\ \\hline \\boldsymbol{C} &amp; \\boldsymbol{D}\\end{array}\\right)\\) with blocks \\(\\boldsymbol{A}, \\boldsymbol{B}, \\boldsymbol{C}, \\boldsymbol{D}\\).","text":""},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW3/#1-for-each-of-the-following-3-cases-write-down-1-times-1-matrices-boldsymbola-boldsymbolb-boldsymbolc-boldsymbold-and-nullity-boldsymbola-nullity-boldsymbolm-such-that","title":"1. For each of the following 3 cases, write down \\(1 \\times 1\\) matrices \\(\\boldsymbol{A}, \\boldsymbol{B}, \\boldsymbol{C}, \\boldsymbol{D}\\) and nullity \\((\\boldsymbol{A})\\), nullity \\((\\boldsymbol{M})\\) such that:","text":"<ol> <li> <p>Let \\(\\boldsymbol{A}=\\begin{pmatrix}1\\end{pmatrix}\\) and \\(\\boldsymbol{M}=\\left(\\begin{array}{ll}\\boldsymbol{A} &amp; \\boldsymbol{B} \\\\ \\boldsymbol{C} &amp; \\boldsymbol{D}\\end{array}\\right)=\\left(\\begin{array}{ll}1 &amp; 0 \\\\ 0 &amp; 0\\end{array}\\right)\\). Then nullity \\((\\boldsymbol{A})=0\\) and nullity \\((\\boldsymbol{M})=1\\), so nullity \\((\\boldsymbol{M})&gt;\\operatorname{nullity}(\\boldsymbol{A})\\).</p> </li> <li> <p>Let \\(\\boldsymbol{A}=\\begin{pmatrix}1\\end{pmatrix}\\) and \\(\\boldsymbol{M}=\\left(\\begin{array}{ll}\\boldsymbol{A} &amp; \\boldsymbol{B} \\\\ \\boldsymbol{C} &amp; \\boldsymbol{D}\\end{array}\\right)=\\left(\\begin{array}{ll}1 &amp; 0 \\\\ 0 &amp; 1\\end{array}\\right)\\). Then nullity \\((\\boldsymbol{A})=0\\) and nullity \\((\\boldsymbol{M})=0\\), so nullity \\((\\boldsymbol{M})=\\operatorname{nullity}(\\boldsymbol{A})\\).</p> </li> <li> <p>Let \\(\\boldsymbol{A}=\\begin{pmatrix}0\\end{pmatrix}\\) and \\(\\boldsymbol{M}=\\left(\\begin{array}{ll}\\boldsymbol{A} &amp; \\boldsymbol{B} \\\\ \\boldsymbol{C} &amp; \\boldsymbol{D}\\end{array}\\right)=\\left(\\begin{array}{ll}0 &amp; 1 \\\\ 1 &amp; 0\\end{array}\\right)\\). Then nullity \\((\\boldsymbol{A})=1\\) and nullity \\((\\boldsymbol{M})=0\\), so nullity \\((\\boldsymbol{M})&lt;\\operatorname{nullity}(\\boldsymbol{A})\\).</p> </li> </ol>"},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW3/#2-prove-that-in-general-operatornamerankm-geq-operatornamerankboldsymbola","title":"2. Prove that in general, \\(\\operatorname{rank}(M) \\geq \\operatorname{rank}(\\boldsymbol{A})\\).","text":"<p>\\(\\boldsymbol{A}\\) is a \\(1 \\times 1\\) matrix, hence rank(\\(A\\)) \\(\\leq 1\\). \\(\\boldsymbol{M}\\) is a \\(2 \\times 2\\) matrix, hence rank(\\(A\\)) \\(\\leq 2\\).</p> <p>If \\(\\boldsymbol{A}\\) is a non zero matrix, the row-echelon form of \\(\\boldsymbol{M}\\) is: </p> <p>\\(\\(\\left(\\begin{array}{ll}A &amp; B \\\\ C &amp; D\\end{array}\\right) \\stackrel{R_2-\\frac{C}{A} R_1}{\\longrightarrow}\\left(\\begin{array}{ll}A &amp; B \\\\ 0 &amp; D-\\frac{C B}{A}\\end{array}\\right)\\)\\)</p> <p>Hence rank(\\(M\\)) \\(\\geq 1\\).</p> <p>If \\(\\boldsymbol{A}=0\\) , </p> \\[\\boldsymbol{M}=\\left(\\begin{array}{ll}\\boldsymbol{0} &amp; \\boldsymbol{B} \\\\ \\boldsymbol{C} &amp; \\boldsymbol{D}\\end{array}\\right)\\] <p>Hence, rank(\\(M\\)) \\(\\geq 0\\).</p> <p>In both cases, \\(\\operatorname{rank}(M) \\geq \\operatorname{rank}(A)\\).</p>"},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW3/#5-suppose-boldsymbola-is-an-m-times-n-matrix-prove-that-if-boldsymbola-boldsymbolxmathbf0-has-a-unique-solution-then-for-every-boldsymbolb-in-mathbbrn-the-system-boldsymbolamathrmt-boldsymboluboldsymbolb-is-consistent","title":"5. Suppose \\(\\boldsymbol{A}\\) is an \\(m \\times n\\) matrix. Prove that if \\(\\boldsymbol{A} \\boldsymbol{x}=\\mathbf{0}\\) has a unique solution, then for every \\(\\boldsymbol{b}\\) in \\(\\mathbb{R}^n\\), the system \\(\\boldsymbol{A}^{\\mathrm{T}} \\boldsymbol{u}=\\boldsymbol{b}\\) is consistent.","text":"<p>Suppose \\(Ax=0\\) has a unique solution. Then:</p> <ul> <li>nullity of \\(A\\) is 0 </li> <li>rank(\\(A)=n\\) (Dimension Theorem)</li> </ul> <p>Since rank(\\(A)=n\\), all columns of \\(A\\) are pivot columns. </p> <p>Also, \\(\\operatorname{rank}(A^{\\text{T}})=\\operatorname{rank}(A)=n\\) which implies that all rows of \\(A^{\\mathrm{T}}\\) contains a pivot.</p> <p>Therefore, \\(\\operatorname{rank}(A^{\\mathrm{T}} \\mid b) = \\operatorname{rank}(A^{\\mathrm{T}})\\) as there will not be additional pivot column for \\((A^{\\mathrm{T}} \\mid b)\\) Hence \\(A^{\\mathrm{T}} u=b\\) is consistent every \\(b\\) in \\(\\mathbb{R}^n\\)</p>"},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW4/","title":"HW4 Written","text":"<p>Moon Ji HoonA0255555X</p>"},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW4/#question-1","title":"Question 1","text":""},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW4/#11-prove-that-leftboldsymbolv_1-boldsymbolv_2-boldsymbolv_3right-is-an-orthonormal-set-of-vectors","title":"1.1 Prove that \\(\\left\\{\\boldsymbol{v}_1, \\boldsymbol{v}_2, \\boldsymbol{v}_3\\right\\}\\) is an orthonormal set of vectors.","text":"<p>Every vectors in \\(\\left\\{\\boldsymbol{v}_1, \\boldsymbol{v}_2, \\boldsymbol{v}_3\\right\\}\\) is is a unit vector:  $$ \\begin{aligned} v_1 \\cdot v_1= &amp; \\left(\\frac{2}{3} u_1+\\frac{2}{3} u_2+\\frac{1}{3} u_3\\right) \\cdot\\left(\\frac{2}{3} u_1+\\frac{2}{3} u_2+\\frac{1}{3} u_3\\right) \\ = &amp; \\frac{4}{9} u_1 \\cdot u_1+\\frac{4}{9} u_1 \\cdot u_2+\\frac{2}{9} u_1 \\cdot u_3 \\ &amp; +\\frac{4}{9} u_2 \\cdot u_1+\\frac{4}{9} u_2 \\cdot u_2+\\frac{2}{9} u_2 \\cdot u_3 \\ &amp; +\\frac{2}{9} u_3\\cdot u_1+\\frac{2}{9} u_3 \\cdot u_2+\\frac{1}{9} u_3 \\cdot u_3 \\ = &amp; \\frac{4}{9}+\\frac{4}{9}+\\frac{1}{9}=1 \\end{aligned} $$ Similarly,</p> \\[ \\begin{aligned} &amp;\\begin{aligned} v_2 \\cdot v_2 &amp; =\\frac{1}{2} u_1 \\cdot u_1+\\frac{1}{2} u_2 \\cdot u_2 \\\\ &amp; =\\frac{1}{2}+\\frac{1}{2}=1 \\end{aligned}\\\\ &amp;\\begin{aligned} v_3 \\cdot v_3 &amp; =\\frac{2}{36} u_1 \\cdot u_1+\\frac{2}{36} u_2 \\cdot u_2+\\frac{8}{9} u_3 \\cdot u_3 \\\\ &amp; =\\frac{2}{36}+\\frac{2}{36}+\\frac{8}{9}=1 \\end{aligned} \\end{aligned} \\] <p>\\(\\left\\{\\boldsymbol{v}_1, \\boldsymbol{v}_2, \\boldsymbol{v}_3\\right\\}\\) is orthogonal: </p> \\[ \\begin{aligned} v_1 \\cdot v_2 &amp; =\\left(\\frac{2}{3} u_1+\\frac{2}{3} u_2+\\frac{1}{3} u_3\\right) \\cdot\\left(-\\frac{1}{\\sqrt{2}} u_1+\\frac{1}{\\sqrt{2}} u_2\\right) \\\\ &amp; =-\\frac{2}{3 \\sqrt{2}} u_1 \\cdot u_1+\\frac{2}{3 \\sqrt{2}} u_2 \\cdot u_2 \\\\ &amp; =0 \\\\ v_1 \\cdot v_3 &amp; =\\left(\\frac{2}{3} u_1+\\frac{2}{3} u_2+\\frac{1}{3} u_3\\right) \\cdot\\left(-\\frac{\\sqrt{2}}{6} u_1-\\frac{\\sqrt{2}}{6} u_2+\\frac{2 \\sqrt{2}}{3} u_3\\right) \\\\ &amp; =-\\frac{2 \\sqrt{2}}{18} u_1 \\cdot u_1-\\frac{2 \\sqrt{2}}{18} u_2 \\cdot u_2+\\frac{2 \\sqrt{2}}{9} u_3 \\cdot u_3 \\\\ &amp; =0 \\\\ v_2 \\cdot v_3 &amp; =\\left(-\\frac{1}{\\sqrt{2}} u_1+\\frac{1}{\\sqrt{2}} u_2\\right) \\cdot\\left(-\\frac{\\sqrt{2}}{6} u_1-\\frac{\\sqrt{2}}{6} u_2+\\frac{2 \\sqrt{2}}{3} u_3\\right) \\\\ &amp; =\\frac{\\sqrt{2}}{6 \\sqrt{2}} u_1 \\cdot u_1-\\frac{\\sqrt{2}}{6 \\sqrt{2}} u_2 \\cdot u_2 \\\\ &amp; =0 \\end{aligned} \\] <p>Hence \\(\\left\\{\\boldsymbol{v}_1, \\boldsymbol{v}_2, \\boldsymbol{v}_3\\right\\}\\) is an orthonormal set of vectors.</p>"},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW4/#12-prove-that-operatornamespanleftboldsymbolu_1-boldsymbolu_2-boldsymbolu_3rightoperatornamespanleftboldsymbolv_1-boldsymbolv_2-boldsymbolv_3right","title":"1.2 Prove that \\(\\operatorname{span}\\left\\{\\boldsymbol{u}_1, \\boldsymbol{u}_2, \\boldsymbol{u}_3\\right\\}=\\operatorname{span}\\left\\{\\boldsymbol{v}_1, \\boldsymbol{v}_2, \\boldsymbol{v}_3\\right\\}\\).","text":"<p>\\(v_{1},v_{2},v_{3}\\) are a linear combination of \\(u_{1},u_{2},u_{3}.\\) Also since both set of vectors are orthonormal, they are linearly independent. Therefore, they must span the same vector space.</p>"},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW4/#question-2","title":"Question 2","text":""},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW4/#21","title":"2.1","text":"<p>Suppose \\(V\\) is a subspace of \\(\\mathbb{R}^n\\) with \\(\\dim(V) = k\\). Then, there exists a basis \\(\\{v_1, v_2, \\dots, v_k\\}\\) for \\(V\\). Since these vectors are linearly independent, there exists a \\(n \\times k\\) matrix whose columns form an orthonormal set. </p> <p>Let \\(\\mathbf{A}=\\left[\\begin{array}{c}\\boldsymbol{a}_{1} \\\\ \\vdots \\\\ \\boldsymbol{a}_{k}\\end{array}\\right]\\) , a  \\(k \\times n\\) matrix where the rows are the transpose of the orthonormal basis. Then, since the columns of \\(A^T\\) form an orthonormal set, \\(AA^T=I_{k}\\).</p> <p>Next, let \\(w \\in\\mathbb{R}^n\\). If \\(u\\) is a least square solution to \\(A^Tx=w\\), then \\(A^Tu\\) is the projection of \\(w\\) onto \\(V\\).   \\(u\\) can be calculated by </p> \\[\\begin{align} AA^Tx=Aw \\\\ u=AA^T Aw \\end{align}\\] <p>Therefore, the projection \\(p=A^TAA^T Aw=A^TAw\\).</p>"},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW4/#22-prove-that-leftboldsymbolamathrmt-boldsymbolaright2boldsymbolamathrmt-boldsymbola","title":"2.2 Prove that \\(\\left(\\boldsymbol{A}^{\\mathrm{T}} \\boldsymbol{A}\\right)^2=\\boldsymbol{A}^{\\mathrm{T}} \\boldsymbol{A}\\).","text":"<p>$$ \\begin{align}</p> <p>(ATA)2 &amp;= ATAATA \\ \\ &amp;= A^TI_{k}A\\ &amp;=A^TA \\end{align} $$</p>"},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW4/#question-3","title":"Question 3","text":""},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW4/#31-computer-the-characteristic-polynomial-of-a","title":"3.1 Computer the characteristic polynomial of \\(A\\)","text":"\\[\\begin{aligned} \\operatorname{det}(\\lambda I-A) &amp; =\\left|\\begin{array}{ccc}\\lambda-1 &amp; 2 &amp; 0 \\\\ -1 &amp; \\lambda+1 &amp; 0 \\\\ 2 &amp; 1 &amp; \\lambda+2\\end{array}\\right| \\\\ &amp; =(\\lambda+2)\\left|\\begin{array}{cc}\\lambda-1 &amp; 2 \\\\ -1 &amp; \\lambda+1\\end{array}\\right| \\\\ &amp; =(\\lambda+2)\\left(\\lambda^2-1+2\\right) \\\\ &amp; =(\\lambda+2)\\left(\\lambda^2+1\\right) \\\\ &amp; =\\lambda^3+2 \\lambda^2+\\lambda+2 \\\\ &amp; =\\left(\\lambda^2+1\\right)(\\lambda+2)\\end{aligned}\\]"},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW4/#32-prove-that-a-is-not-diagonalizable","title":"3.2 Prove that \\(A\\) is not diagonalizable.","text":"<p>The eigenvalues values are \\(i,-i\\) and \\(-2\\). Since some of the eigenvalues are not real, \\(A\\) is not diagonalizable.</p>"},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW4/#question-4","title":"Question 4","text":""},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW4/#41-compute-all-eigenvalues-of-boldsymbola","title":"4.1 Compute all eigenvalues of \\(\\boldsymbol{A}\\).","text":"\\[\\boldsymbol{A}=\\left(\\begin{array}{ccc}-3 &amp; 2 &amp; -2 \\\\ 2 &amp; -3 &amp; 4 \\\\ 4 &amp; -5 &amp; 6\\end{array}\\right)\\] \\[\\operatorname{det}(A-\\lambda I)=\\left|\\begin{array}{ccc}-3-\\lambda &amp; 2 &amp; -2 \\\\ 2 &amp; -3-\\lambda &amp; 4 \\\\ 4 &amp; -5 &amp; 6-\\lambda\\end{array}\\right|=-\\lambda^3+3 \\lambda-2\\] <p>\\(-\\lambda^3+3 \\lambda-2=-(\\lambda-1) \\cdot(\\lambda+2) \\cdot(\\lambda-1)=0\\)</p> <p>\\(\\therefore\\lambda=1,-2\\)</p>"},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW4/#42-for-each-eigenvalue-lambda-of-boldsymbola-compute-a-basis-for-the-eigenspace-e_lambda","title":"4.2 For each eigenvalue \\(\\lambda\\) of \\(\\boldsymbol{A}\\), compute a basis for the eigenspace \\(E_\\lambda\\).","text":"\\[\\begin{aligned} &amp; \\left(\\begin{array}{ccc}-4 &amp; 2 &amp; -2 \\\\ 2 &amp; -4 &amp; 4 \\\\ 4 &amp; -5 &amp; 5\\end{array}\\right) \\stackrel{G \\cdot E}{\\longrightarrow}\\left(\\begin{array}{lll}1 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; -1 \\\\ 0 &amp; 0 &amp; 0\\end{array}\\right) \\\\ &amp; E_{1}=\\operatorname{Span}\\left\\{\\left(\\begin{array}{c}0 \\\\ 1 \\\\ 1\\end{array}\\right)\\right\\}\\end{aligned}\\] \\[\\begin{aligned} &amp; \\left(\\begin{array}{ccc}-1 &amp; 2 &amp; -2 \\\\ 2 &amp; -1 &amp; 4 \\\\ 4 &amp; -5 &amp; 8\\end{array}\\right) \\stackrel{G \\cdot E}{\\longrightarrow}\\left(\\begin{array}{lll}1 &amp; 0 &amp; 2 \\\\ 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 0\\end{array}\\right) \\\\ &amp; E_{-2}=\\operatorname{Span}\\left\\{\\left(\\begin{array}{c}-2 \\\\ 0 \\\\ 1\\end{array}\\right)\\right\\}\\end{aligned}\\]"},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW4/#43-prove-that-boldsymbola-is-not-diagonalizable","title":"4.3 Prove that \\(\\boldsymbol{A}\\) is not diagonalizable.","text":"<p>\\(\\boldsymbol{A}\\) has two linearly independent eigenvectors. However \\(A\\) is a square matrix of order \\(3\\). Therefore, \\(\\boldsymbol{A}\\) is not diagonalizable.</p>"},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW4/#question-5","title":"Question 5","text":""},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW4/#51-write-down-a-3-times-3-matrix-boldsymbola","title":"5.1 Write down a \\(3 \\times 3\\) matrix \\(\\boldsymbol{A}\\)","text":"\\[A=\\left(\\begin{array}{ccc}0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\\\ 4 &amp; 4 &amp; -1\\end{array}\\right)\\]"},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW4/#52-without-computing-any-eigenvectors-explain-why-boldsymbola-is-diagonalizable","title":"5.2 Without computing any eigenvectors, explain why \\(\\boldsymbol{A}\\) is diagonalizable.","text":"<p>\\(\\(\\begin{aligned} \\operatorname{det}(\\lambda I-A) &amp; =\\left|\\begin{array}{ccc}\\lambda &amp; -1 &amp; 0 \\\\ 0 &amp; \\lambda &amp; -1 \\\\ -4 &amp; -4 &amp; \\lambda+1\\end{array}\\right| \\\\  &amp; =\\lambda\\left|\\begin{array}{cc}\\lambda &amp; -1 \\\\ 0 &amp; \\lambda\\end{array}\\right| + \\left|\\begin{array}{cc}0 &amp; -1 \\\\ -4&amp; \\lambda+1\\end{array}\\right|\\\\  &amp; = \\lambda^3+\\lambda^2-4 \\lambda-4\\end{aligned}\\)\\) The eigenvalues values are \\(\\lambda=-2,2,-1\\). There are 3 distinct eigenvalues and since \\(A\\) is a \\(3\\times 3\\) matrix, \\(A\\) is diagonalizable.</p>"},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW4/#53-diagonalize-boldsymbola","title":"5.3 Diagonalize \\(\\boldsymbol{A}\\)","text":"<p>For each eigenvalues, find the bases for eigenspace:</p> \\[\\begin{aligned} &amp; \\left(\\begin{array}{ccc}-2 &amp; -1 &amp; 0 \\\\ 0 &amp; -2 &amp; -1 \\\\ -4 &amp; -4 &amp; -1\\end{array}\\right) \\stackrel{G \\cdot E}{\\longrightarrow}\\left(\\begin{array}{lll}1 &amp; 0 &amp; -\\frac{1}{4} \\\\ 0 &amp; 1 &amp; \\frac{1}{2} \\\\ 0 &amp; 0 &amp; 0\\end{array}\\right) \\\\ &amp; E_{-2}=\\operatorname{Span}\\left\\{\\left(\\begin{array}{l} \\frac{1}{4} \\\\ -\\frac{1}{2} \\\\ 1\\end{array}\\right)\\right\\}\\end{aligned}\\] \\[\\begin{aligned} &amp; \\left(\\begin{array}{ccc}2 &amp; -1 &amp; 0 \\\\ 0 &amp; 2 &amp; -1 \\\\ -4 &amp; -4 &amp; 3\\end{array}\\right) \\stackrel{G \\cdot E}{\\longrightarrow}\\left(\\begin{array}{lll}1 &amp; 0 &amp; -\\frac{1}{4} \\\\ 0 &amp; 1 &amp; -\\frac{1}{2} \\\\ 0 &amp; 0 &amp; 0\\end{array}\\right) \\\\ &amp; E_{2}=\\operatorname{Span}\\left\\{\\left(\\begin{array}{l} \\frac{1}{4} \\\\ \\frac{1}{2} \\\\ 1\\end{array}\\right)\\right\\}\\end{aligned}\\] <p>\\(\\(\\begin{aligned} &amp; \\left(\\begin{array}{ccc}-1 &amp; -1 &amp; 0 \\\\ 0 &amp; -1 &amp; -1 \\\\ -4 &amp; -4 &amp; 0\\end{array}\\right) \\stackrel{G \\cdot E}{\\longrightarrow}\\left(\\begin{array}{lll}1 &amp; 0 &amp; -1 \\\\ 0 &amp; 1 &amp; 1 \\\\ 0 &amp; 0 &amp; 0\\end{array}\\right) \\\\ &amp; E_{-1}=\\operatorname{Span}\\left\\{\\left(\\begin{array}{l} 1 \\\\ -1 \\\\ 1\\end{array}\\right)\\right\\}\\end{aligned}\\)\\) Next, \\(\\boldsymbol{P}=\\left(\\begin{array}{ccc} \\frac{1}{4} &amp; \\frac{1}{4} &amp; 1 \\\\ -\\frac{1}{2} &amp; \\frac{1}{2} &amp; -1 \\\\ 1 &amp; 1 &amp; 1\\end{array}\\right)\\). Then \\(\\boldsymbol{P}^{-1} \\boldsymbol{A P}=\\left(\\begin{array}{lll}-2 &amp; 0 &amp; 0 \\\\ 0 &amp; 2 &amp; 0 \\\\ 0 &amp; 0 &amp; -1\\end{array}\\right)\\).</p>"},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW4/#54-use-the-previous-parts-to-derive-a-non-recursive-formula-for-a_n-in-terms-of-n","title":"5.4 Use the previous parts to derive a (non-recursive) formula for \\(a_n\\) in terms of \\(n\\).","text":"\\[ \\left(\\begin{array}{l} a_{n+1} \\\\ a_{n+2} \\\\ a_{n+3} \\end{array}\\right)=A\\left(\\begin{array}{l} a_n \\\\ a_{n+1} \\\\ a_{n+2} \\end{array}\\right)=A^{n+1}\\left(\\begin{array}{l} a_0 \\\\ a_1 \\\\ a_2 \\end{array}\\right)=PD^{n+1}P^{-1}\\left(\\begin{array}{l} 0 \\\\ 0 \\\\ 1 \\end{array}\\right) $$ $$ = \\left(\\begin{array}{ccc} \\frac{1}{4} &amp; \\frac{1}{4} &amp; 1 \\\\ -\\frac{1}{2} &amp; \\frac{1}{2} &amp; -1 \\\\ 1 &amp; 1 &amp; 1 \\end{array}\\right)\\left(\\begin{array}{ccc} (-2)^{n+1} &amp; 0 &amp; 0 \\\\ 0 &amp; 2^{n+1} &amp; 0 \\\\ 0 &amp; 0 &amp; (-1)^{n+1} \\end{array}\\right)\\left(\\begin{array}{ccc} -2 &amp; -1 &amp; 1 \\\\ \\frac{2}{3} &amp; 1 &amp; \\frac{1}{3} \\\\ \\frac{4}{3} &amp; 0 &amp; -\\frac{1}{3} \\end{array}\\right)\\left(\\begin{array}{l} 0 \\\\ 0 \\\\ 1 \\end{array}\\right) $$ $$ =\\left(\\begin{array}{c} -\\frac{-2\\left(2^{n-1}-(-1)^{n+1}\\right)+3(-2)^n}{6} \\\\ \\frac{2^n+(-1)^{n+1}+3(-2)^n}{3} \\\\ \\frac{3(-2)^{n+1}-2^{n+1}-(-1)^{n+1}}{3} \\end{array}\\right) \\] <p>Substituting the result to  \\(a_{n+3}=-a_{n+2}+4 a_{n+1}+4 a_n\\) gives</p> \\[ a_{n}=\\frac{-9(-2)^n+2^n-2^{n+2}+4(-1)^{n+1}+3(-2)^{n+1}}{12} \\]"},{"location":"Year%201%20Semester%202/MA2001/HW/MA2001_HW4/#55-is-boldsymbola-orthogonally-diagonalizable","title":"5.5 Is \\(\\boldsymbol{A}\\) orthogonally diagonalizable?","text":"<p>No because it is not symmetric.</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/01%20Linear%20Systems%20%26%20Gaussian%20Elimination/","title":"Linear Systems &amp; Gaussian Elimination","text":""},{"location":"Year%201%20Semester%202/MA2001/Notes/01%20Linear%20Systems%20%26%20Gaussian%20Elimination/#consistency","title":"Consistency","text":""},{"location":"Year%201%20Semester%202/MA2001/Notes/01%20Linear%20Systems%20%26%20Gaussian%20Elimination/#no-solution-inconsistent","title":"No Solution (Inconsistent)","text":"<p>There is a row in \\(\\boldsymbol{R}\\) with the form - \\(\\left(\\begin{array}{llll}0 &amp; 0 &amp; \\cdots &amp; 0\\end{array} \\mid \\otimes\\right)\\), where \\(\\otimes\\) is nonzero.</p> <p>Or equivalently, the last column is a pivot column. Note: Such a row must be the last nonzero row of \\(\\boldsymbol{R}\\).</p> <p>Example:</p> <p>\\(\\left(\\begin{array}{lll|l}3 &amp; 2 &amp; 3 &amp; 4 \\\\ 0 &amp; 0 &amp; 1 &amp; 1 \\\\ 0 &amp; 0 &amp; 0 &amp; 2\\end{array}\\right), \\quad\\left(\\begin{array}{lll|l}3 &amp; 2 &amp; 3 &amp; 4 \\\\ 0 &amp; 0 &amp; 0 &amp; 5 \\\\ 0 &amp; 0 &amp; 0 &amp; 0\\end{array}\\right)\\)</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/01%20Linear%20Systems%20%26%20Gaussian%20Elimination/#one-solution-consistent","title":"One Solution (Consistent)","text":"<ul> <li>The last column is a non-pivot column, and</li> <li>All other columns are pivot columns.</li> </ul> <p>Example: (Here \\(\\otimes\\) are pivot points, which are nonzero.)</p> <p>\\(\\left(\\begin{array}{ccccc|c}\\otimes &amp; * &amp; * &amp; \\cdots &amp; * &amp; * \\\\ 0 &amp; \\otimes &amp; * &amp; \\cdots &amp; * &amp; * \\\\ 0 &amp; 0 &amp; \\otimes &amp; \\cdots &amp; * &amp; * \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; * &amp; * \\\\ 0 &amp; 0 &amp; 0 &amp; \\cdots &amp; \\otimes &amp; * \\\\ 0 &amp; 0 &amp; 0 &amp; \\cdots &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; \\cdots &amp; 0 &amp; 0\\end{array}\\right)\\)</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/01%20Linear%20Systems%20%26%20Gaussian%20Elimination/#infinite-solution-consistent","title":"Infinite Solution (Consistent)","text":"<ul> <li>The last column is a non-pivot column, and</li> <li>Some other columns are non-pivot columns.</li> </ul> <p>Note: The number of arbitrary parameters is the same as the number of non-pivot columns (except the last column).</p> <p>Examples:</p> <p>\\(\\left(\\begin{array}{cccc|c}5 &amp; 1 &amp; 2 &amp; 3 &amp; 4 \\\\ 0 &amp; 0 &amp; -1 &amp; 0 &amp; 1 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 &amp; 2\\end{array}\\right),\\left(\\begin{array}{cccc|c}0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 \\\\ 0 &amp; 0 &amp; -1 &amp; 0 &amp; 1 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0\\end{array}\\right)\\)</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/02%20Matrices/","title":"Matrices","text":"<p>To show the \\(i,j^{th}\\) entry of a matrix for \\(E=(e_{ij})_{m\\times m}\\) times \\(A=(a_{ij})_{m\\times n}\\)</p> <ul> <li>Then the \\((i,j)\\)-entry of \\(EA\\) is</li> <li>\\(e_{i 1} a_{1 j}+\\cdots+e_{i m} a_{m j}\\)</li> </ul>"},{"location":"Year%201%20Semester%202/MA2001/Notes/02%20Matrices/#special-matrices","title":"Special Matrices","text":""},{"location":"Year%201%20Semester%202/MA2001/Notes/02%20Matrices/#diagonal-matrix","title":"Diagonal matrix","text":"<p>A square matrix is called a diagonal matrix if all its non-diagonal entries are zero.</p> <p>\\(\\boldsymbol{A}=\\left(\\begin{array}{cccc}a_{11} &amp; 0 &amp; \\cdots &amp; 0 \\\\ 0 &amp; a_{22} &amp; \\cdots &amp; 0 \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 0 &amp; 0 &amp; \\cdots &amp; a_{n n}\\end{array}\\right)\\)</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/02%20Matrices/#scalar-matrix","title":"Scalar matrix","text":"<p>A diagonal matrix is called a scalar matrix if all its diagonal entries are the same.</p> <p>\\(\\boldsymbol{A}=\\left(\\begin{array}{cccc}c &amp; 0 &amp; \\cdots &amp; 0 \\\\ 0 &amp; c &amp; \\cdots &amp; 0 \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 0 &amp; 0 &amp; \\cdots &amp; c\\end{array}\\right)\\), where \\(c\\) is a constant.</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/02%20Matrices/#identity-matrix","title":"Identity matrix","text":"<p>A scalar matrix is called an identity matrix if all its diagonal entries are 1. Denote the identity matrix of order \\(n\\) (size \\(n \\times n\\) ) by \\(\\boldsymbol{I}_n\\).</p> <p>\\(\\boldsymbol{A}=\\left(\\begin{array}{cccc}1 &amp; 0 &amp; \\cdots &amp; 0 \\\\ 0 &amp; 1 &amp; \\cdots &amp; 0 \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 0 &amp; 0 &amp; \\cdots &amp; 1\\end{array}\\right)\\)</p> <p>\\(\\boldsymbol{A}=\\left(a_{i j}\\right)_{n \\times n}\\) is identity \\(\\Leftrightarrow a_{i j}= \\begin{cases}1 &amp; \\text { if } i=j \\\\ 0 &amp; \\text { if } i \\neq j\\end{cases}\\)</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/02%20Matrices/#zero-matrix","title":"Zero matrix","text":"<p>A matrix with all entries equal to zero is a zero matrix. This does not have to be a square matrix as denoted by the absence of diagonal ... in the matrix.</p> <p>\\(\\boldsymbol{A}=\\left(\\begin{array}{cccccc}0 &amp; 0 &amp; 0 &amp; 0 &amp; \\cdots &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; \\cdots &amp; 0 \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; &amp; \\vdots \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; \\cdots &amp; 0\\end{array}\\right)\\)</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/02%20Matrices/#symmetric","title":"Symmetric","text":"<p>A square matrix is called symmetric if it is symmetric with respect to the diagonal.</p> <p>\\(\\boldsymbol{A}=\\left(\\begin{array}{cccccc}a_{11} &amp; a_{12} &amp; a_{13} &amp; a_{14} &amp; \\cdots &amp; a_{1 n} \\\\ a_{21} &amp; a_{22} &amp; a_{23} &amp; a_{24} &amp; \\cdots &amp; a_{2 n} \\\\ a_{31} &amp; a_{32} &amp; a_{33} &amp; a_{34} &amp; \\cdots &amp; a_{3 n} \\\\ a_{41} &amp; a_{42} &amp; a_{43} &amp; a_{44} &amp; \\cdots &amp; a_{4 n} \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ a_{n 1} &amp; a_{n 2} &amp; a_{n 3} &amp; a_{n 4} &amp; \\cdots &amp; a_{n n}\\end{array}\\right)\\)</p> <p>\\(\\boldsymbol{A}=\\left(a_{i j}\\right)_{n \\times n}\\) is symmetric \\(\\Leftrightarrow a_{i j}=a_{j i}\\) for all \\(i, j\\). (There is no restriction to the diagonal entries.)</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/02%20Matrices/#upper-triangular","title":"Upper triangular","text":"<p>A square matrix is called upper triangular if all the entries below the diagonal are zero.</p> <p>\\(\\boldsymbol{A}=\\left(\\begin{array}{cccccc}a_{11} &amp; a_{12} &amp; a_{13} &amp; a_{14} &amp; \\cdots &amp; a_{1 n} \\\\ 0 &amp; a_{22} &amp; a_{23} &amp; a_{24} &amp; \\cdots &amp; a_{2 n} \\\\ 0 &amp; 0 &amp; a_{33} &amp; a_{34} &amp; \\cdots &amp; a_{3 n} \\\\ 0 &amp; 0 &amp; 0 &amp; a_{44} &amp; \\cdots &amp; a_{4 n} \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; \\cdots &amp; a_{n n}\\end{array}\\right)\\)</p> <p>\\(\\boldsymbol{A}=\\left(a_{i j}\\right)_{n \\times n}\\) is upper triangular \\(\\Leftrightarrow a_{i j}=0\\) if \\(i&gt;j\\). (There is no restriction to the diagonal entries.)</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/02%20Matrices/#lower-triangular","title":"Lower triangular","text":"<p>A square matrix is called lower triangular if all the entries above the diagonal are zero.</p> <p>\\(\\boldsymbol{A}=\\left(\\begin{array}{cccccc}a_{11} &amp; 0 &amp; 0 &amp; 0 &amp; \\cdots &amp; 0 \\\\ a_{21} &amp; a_{22} &amp; 0 &amp; 0 &amp; \\cdots &amp; 0 \\\\ a_{31} &amp; a_{32} &amp; a_{33} &amp; 0 &amp; \\cdots &amp; 0 \\\\ a_{41} &amp; a_{42} &amp; a_{43} &amp; a_{44} &amp; \\cdots &amp; 0 \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ a_{n 1} &amp; a_{n 2} &amp; a_{n 3} &amp; a_{n 4} &amp; \\cdots &amp; a_{n n}\\end{array}\\right)\\)</p> <p>\\(\\boldsymbol{A}=\\left(a_{i j}\\right)_{n \\times n}\\) is lower triangular \\(\\Leftrightarrow a_{i j}=0\\) if \\(i&lt;j\\) (There is no restriction to the diagonal entries.)</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/02%20Matrices/#transpose-of-matrix","title":"Transpose of Matrix","text":""},{"location":"Year%201%20Semester%202/MA2001/Notes/02%20Matrices/#properties","title":"Properties","text":"<p>Let \\(\\boldsymbol{A}\\) be an \\(m \\times n\\) matrix.</p> <p>\\(\\left(\\boldsymbol{A}^{\\mathrm{T}}\\right)^{\\mathrm{T}}=\\boldsymbol{A}\\) \\(A\\) is symmetric \\(\\Leftrightarrow A=A^{\\mathrm{T}}\\). Let \\(c\\) be a scalar. Then \\((c \\boldsymbol{A})^{\\mathrm{T}}=c \\boldsymbol{A}^{\\mathrm{T}}\\). Let \\(\\boldsymbol{B}\\) be \\(m \\times n\\). Then \\((\\boldsymbol{A}+\\boldsymbol{B})^{\\mathrm{T}}=\\boldsymbol{A}^{\\mathrm{T}}+\\boldsymbol{B}^{\\mathrm{T}}\\). Let \\(\\boldsymbol{B}\\) be \\(n \\times p\\). Then \\((\\boldsymbol{A} \\boldsymbol{B})^{\\mathrm{T}}=\\boldsymbol{B}^{\\mathrm{T}} \\boldsymbol{A}^{\\mathrm{T}}\\).</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/02%20Matrices/#inverse-of-matrix","title":"Inverse of Matrix","text":"<p>If there exists a square matrix \\(\\boldsymbol{B}\\) of order \\(n\\) so that</p> <ul> <li>\\(\\boldsymbol{A B}=I_n\\) land \\(\\boldsymbol{B A}=I_n\\) then \\(\\boldsymbol{A}\\) is called invertible, and \\(\\boldsymbol{B}\\) is an inverse of \\(\\boldsymbol{A}\\).</li> </ul> <p>Let \\(\\boldsymbol{A}=\\left(\\begin{array}{ll}a &amp; b \\\\ c &amp; d\\end{array}\\right)\\)</p> <p>If \\(\\boldsymbol{A}\\) is invertible, then \\(\\boldsymbol{A}^{-1}=\\frac{1}{a d-b c}\\left(\\begin{array}{cc}d &amp; -b \\\\ -c &amp; a\\end{array}\\right)\\)</p> <p>If \\(ad-bc = 0\\) it is Inconsistent</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/02%20Matrices/#properties_1","title":"Properties","text":"<p>Let \\(\\boldsymbol{A}, \\boldsymbol{B}\\) be invertible matrices of same size.</p> <ul> <li>Let \\(c \\neq 0 . c \\boldsymbol{A}\\) is invertible, and \\((c \\boldsymbol{A})^{-1}=\\frac{1}{c} \\boldsymbol{A}^{-1}\\).</li> <li>\\(\\boldsymbol{A}^{\\mathrm{T}}\\) is invertible, and \\(\\left(\\boldsymbol{A}^{\\mathrm{T}}\\right)^{-1}=\\left(\\boldsymbol{A}^{-1}\\right)^{\\mathrm{T}}\\).</li> <li>\\(\\boldsymbol{A}^{-1}\\) is invertible, and \\(\\left(\\boldsymbol{A}^{-1}\\right)^{-1}=\\boldsymbol{A}\\).</li> <li>\\(A B\\) is invertible, and \\((A B)^{-1}=B^{-1} A^{-1}\\).</li> </ul> <p>Let \\(\\boldsymbol{A}_1, \\boldsymbol{A}_2, \\ldots, \\boldsymbol{A}_k\\) be invertible matrices of same size.</p> <ul> <li>\\(\\left(\\boldsymbol{A}_1 \\boldsymbol{A}_2 \\cdots \\boldsymbol{A}_k\\right)^{-1}=\\boldsymbol{A}_k^{-1} \\cdots \\boldsymbol{A}_2^{-1} \\boldsymbol{A}_1^{-1}\\).</li> <li>\\(\\left(\\boldsymbol{A}^k\\right)^{-1}=\\left(\\boldsymbol{A}^{-1}\\right)^k\\)</li> </ul> <p>Definition. Let \\(A\\) be an invertible matrix.</p> <ul> <li>For any positive integer \\(k, \\boldsymbol{A}^{-k}=\\left(\\boldsymbol{A}^{-1}\\right)^k\\)</li> </ul> <p>Let \\(A\\) be an invertible matrix.</p> <ul> <li>\\(\\boldsymbol{A}^{m+n}=\\boldsymbol{A}^m \\boldsymbol{A}^n\\) and \\(\\left(\\boldsymbol{A}^m\\right)^n=\\boldsymbol{A}^{m n}\\)</li> </ul>"},{"location":"Year%201%20Semester%202/MA2001/Notes/02%20Matrices/#elementary-row-operation-using-matrix-multiplication","title":"Elementary row operation using matrix multiplication","text":"<p>Important Note: \\(E_6 \\cdots E_2 E_1 A=I\\) Every elementary matrix is invertible</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/02%20Matrices/#from-one-matrix-to-another","title":"From one matrix to another","text":"<p>Suppose for elementary matrices \\(\\boldsymbol{E}_i\\),</p> <ul> <li>\\(\\boldsymbol{B}=\\boldsymbol{E}_k \\boldsymbol{E}_{k-1} \\cdots \\boldsymbol{E}_2 \\boldsymbol{E}_1 \\boldsymbol{A}\\)</li> <li>\\(\\boldsymbol{A} \\stackrel{\\boldsymbol{E}_1}{\\longrightarrow} \\bullet \\stackrel{\\boldsymbol{E}_2}{\\longrightarrow} \\bullet \\rightarrow \\cdots \\rightarrow \\bullet \\stackrel{\\boldsymbol{E}_{k-1}}{\\longrightarrow} \\bullet \\stackrel{\\boldsymbol{E}_k}{\\longrightarrow} \\boldsymbol{B}\\)</li> <li>\\(\\boldsymbol{A} \\stackrel{E_1^{-1}}{\\longleftarrow} \\bullet \\stackrel{E_2^{-1}}{\\longleftarrow} \\bullet \\leftarrow \\cdots \\leftarrow \\bullet \\stackrel{E_{k-1}^{-1}}{\\longleftarrow} \\bullet \\stackrel{E_k^{-1}}{\\longleftarrow} \\boldsymbol{B}\\)</li> </ul> <p>\\(\\therefore \\quad \\boldsymbol{A}=\\boldsymbol{E}_1^{-1} \\boldsymbol{E}_2^{-1} \\cdots \\boldsymbol{E}_{k-1}^{-1} \\boldsymbol{E}_k^{-1} \\boldsymbol{B}\\)</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/02%20Matrices/#theorem-for-invertible-matrices","title":"Theorem for Invertible Matrices","text":"<p>Let \\(\\boldsymbol{A}\\) be a square matrix. Then the followings are equivalent:</p> <ol> <li>\\(\\boldsymbol{A}\\) is an invertible matrix.</li> <li>Linear system \\(\\boldsymbol{A} \\boldsymbol{x}=\\boldsymbol{b}\\) has a unique solution.</li> <li>Linear system \\(\\boldsymbol{A} \\boldsymbol{x}=\\mathbf{0}\\) has only the trivial solution.</li> <li>The reduced row-echelon form of \\(\\boldsymbol{A}\\) is \\(\\boldsymbol{I}\\).</li> <li>\\(\\boldsymbol{A}\\) is the product of elementary matrices.</li> </ol> <p></p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/02%20Matrices/#find-inverse","title":"Find Inverse","text":"<p>From </p> <p>Let \\(A\\) be an invertible matrix of order \\(n\\). Its reduced row-echelon form is \\(I_n\\).</p> <p>There exist elementary matrices \\(\\boldsymbol{E}_i\\) such that</p> <ul> <li>\\(\\boldsymbol{E}_k \\cdots \\boldsymbol{E}_2 \\boldsymbol{E}_1 \\boldsymbol{A}=\\boldsymbol{I}_n\\). Then \\(\\boldsymbol{E}_k \\cdots \\boldsymbol{E}_2 \\boldsymbol{E}_1=\\boldsymbol{A}^{-1}\\).</li> </ul> <p>Consider the \\(n \\times 2 n\\) matrix \\((\\boldsymbol{A} \\mid \\boldsymbol{I})\\).</p> <p>Apply the ele. row oper. corresponding to \\(\\boldsymbol{E}_1, \\ldots, \\boldsymbol{E}_k\\) : $$ \\begin{aligned} \\left(\\boldsymbol{A} \\mid \\boldsymbol{I}_n\\right) &amp; \\stackrel{\\boldsymbol{E}_1}{\\longrightarrow}\\left(\\boldsymbol{E}_1 \\boldsymbol{A} \\mid \\boldsymbol{E}_1\\right) \\ &amp; \\stackrel{\\boldsymbol{E}_2}{\\longrightarrow}\\left(\\boldsymbol{E}_2 \\boldsymbol{E}_1 \\boldsymbol{A} \\mid \\boldsymbol{E}_2 \\boldsymbol{E}_1\\right) \\ &amp; \\rightarrow \\cdots \\rightarrow \\cdots \\ &amp; \\stackrel{\\boldsymbol{E}_k}{\\longrightarrow}\\left(\\boldsymbol{E}_k \\cdots \\boldsymbol{E}_2 \\boldsymbol{E}_1 \\boldsymbol{A} \\mid \\boldsymbol{E}_k \\cdots \\boldsymbol{E}_2 \\boldsymbol{E}_1\\right) \\ &amp; =\\left(\\boldsymbol{I}_n \\mid \\boldsymbol{A}^{-1}\\right) \\end{aligned} $$</p> <p>This is the reduced row-echelon form of \\((A|I )\\)</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/02%20Matrices/#column-operations","title":"Column Operations","text":"<p>Let \\(\\boldsymbol{A}\\) be an \\(m \\times n\\) matrix, and \\(\\boldsymbol{E}\\) an \\(n \\times n\\) elementary matrix. Then - The post-multiplication of \\(\\boldsymbol{E}\\) to \\(\\boldsymbol{A}\\) \\(\\Leftrightarrow\\) Corresponding elementary column operation to \\(\\boldsymbol{A}\\). - \\(\\boldsymbol{I} \\stackrel{k C_i}{\\longrightarrow} \\boldsymbol{E} \\Rightarrow \\boldsymbol{A} \\stackrel{k C_i}{\\longrightarrow} \\boldsymbol{A} \\boldsymbol{E}\\). - \\(\\boldsymbol{I} \\stackrel{C_i \\leftrightarrow C_j}{\\longrightarrow} \\boldsymbol{E} \\Rightarrow \\boldsymbol{A} \\stackrel{C_i \\leftrightarrow C_j}{\\longrightarrow} \\boldsymbol{A} \\boldsymbol{E}\\). - \\(\\boldsymbol{I} \\stackrel{C_i+k C_j}{\\longrightarrow} \\boldsymbol{E} \\Rightarrow \\boldsymbol{A} \\stackrel{C_i+k C_j}{\\longrightarrow} \\boldsymbol{A} \\boldsymbol{E}\\).</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/02%20Matrices/#determinant","title":"Determinant","text":""},{"location":"Year%201%20Semester%202/MA2001/Notes/02%20Matrices/#elementary-row-operation","title":"Elementary Row Operation","text":"<p>Get the determinant of \\(A\\) from multiplying the determinant of \\(E_{1},E_{2}\\dots\\) </p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/02%20Matrices/#properties_2","title":"Properties","text":"<ul> <li>Theorem. \\(\\operatorname{det}(\\boldsymbol{I})=1\\). For any square matrices,<ul> <li>If \\(\\boldsymbol{A} \\stackrel{c R_i}{\\longrightarrow} \\boldsymbol{B}\\), then \\(\\operatorname{det}(\\boldsymbol{B})=c \\operatorname{det}(\\boldsymbol{A})\\).<ul> <li>In particular, If \\(\\boldsymbol{I} \\stackrel{c R_i}{\\longrightarrow} \\boldsymbol{E}\\), then \\(\\operatorname{det}(\\boldsymbol{E})=c\\).</li> </ul> </li> <li>If \\(\\boldsymbol{A} \\stackrel{R_i \\leftrightarrow R_j}{\\longrightarrow} \\boldsymbol{B}\\), then \\(\\operatorname{det}(\\boldsymbol{B})=-\\operatorname{det}(\\boldsymbol{A})\\).<ul> <li>In particular, if \\(\\boldsymbol{I} \\stackrel{R_i \\leftrightarrow R_j}{\\longrightarrow} \\boldsymbol{E}\\), then \\(\\operatorname{det}(\\boldsymbol{E})=-1\\).</li> </ul> </li> <li>If \\(\\boldsymbol{A} \\stackrel{R_i+c R_j}{\\longrightarrow} \\boldsymbol{B}\\), then \\(\\operatorname{det}(\\boldsymbol{B})=\\operatorname{det}(\\boldsymbol{A})\\).<ul> <li>In particular, if \\(\\boldsymbol{I} \\stackrel{R_i+c R_j}{\\longrightarrow} \\boldsymbol{E}\\), then \\(\\operatorname{det}(\\boldsymbol{E})=1\\).</li> </ul> </li> </ul> </li> <li>Theorem. Let \\(\\boldsymbol{A}\\) be a square matrix.<ul> <li>For any elementary matrix \\(\\boldsymbol{E}\\) of the same order,<ul> <li>\\(\\operatorname{det}(\\boldsymbol{E} \\boldsymbol{A})=\\operatorname{det}(\\boldsymbol{E}) \\operatorname{det}(\\boldsymbol{A})\\).</li> </ul> </li> </ul> </li> </ul>"},{"location":"Year%201%20Semester%202/MA2001/Notes/02%20Matrices/#cofactor-expansion","title":"Cofactor Expansion","text":"<p>Theorem. Let \\(\\boldsymbol{A}\\) be a square matrix of order \\(n\\).</p> <ul> <li>Let \\(A_{i j}\\) denote the \\((i, j)\\)-cofactor of \\(\\boldsymbol{A}\\).</li> </ul> <p>Then for any \\(i\\) and \\(j\\),</p> <ul> <li>\\(\\operatorname{det}(\\boldsymbol{A})=a_{i 1} A_{i 1}+a_{i 2} A_{i 2}+\\cdots+a_{i n} A_{i n}\\).</li> <li>\\(\\operatorname{det}(\\boldsymbol{A})=a_{1 j} A_{1 j}+a_{2 j} A_{2 j}+\\cdots+a_{n j} A_{n j}\\)</li> </ul> <p>In evaluating the determinant using cofactor expansion, expand along the row or column with the most zeros. (for ease of calculation)</p> <p> Cofactor</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/02%20Matrices/#finding-determinant","title":"Finding Determinant","text":"<p>Find \\(\\operatorname{det}(\\boldsymbol{A})\\) if \\(\\boldsymbol{A}\\) is a square matrix of order \\(n\\).</p> <ul> <li>If \\(\\boldsymbol{A}\\) has a zero row/column, then \\(\\operatorname{det}(\\boldsymbol{A})=0\\). (This also applies to same rows)</li> <li>If \\(\\boldsymbol{A}\\) is triangular, \\(\\operatorname{det}(\\boldsymbol{A})=a_{11} \\cdots a_{n n}\\).</li> <li>Suppose that \\(\\boldsymbol{A}\\) is not triangular.<ul> <li>If \\(n=2\\), use formula \\(\\operatorname{det}(\\boldsymbol{A})=a_{11} a_{22}-a_{12} a_{21}\\). </li> <li>If a row/coln has many 0 , use cofactor expansion. </li> <li>Otherwise, use ele. row operations to get REF:<ul> <li>\\(\\operatorname{det}(\\boldsymbol{E} \\boldsymbol{A})=\\operatorname{det}(\\boldsymbol{E}) \\operatorname{det}(\\boldsymbol{A})\\)</li> </ul> </li> </ul> </li> </ul> <p>Note the following formulas:</p> <p>\\(\\begin{aligned} &amp; \\operatorname{det}(\\boldsymbol{A})=\\operatorname{det}\\left(\\boldsymbol{A}^{\\mathrm{T}}\\right) \\\\ &amp; \\operatorname{det}(\\boldsymbol{A} \\boldsymbol{B})=\\operatorname{det}(\\boldsymbol{A}) \\operatorname{det}(\\boldsymbol{B}) \\\\ &amp; \\operatorname{det}(c \\boldsymbol{A})=c^n \\operatorname{det}(\\boldsymbol{A}), \\text { where } \\boldsymbol{A} \\text { is } n \\times n \\\\ &amp; \\operatorname{det}\\left(\\boldsymbol{A}^{-1}\\right)=\\operatorname{det}(\\boldsymbol{A})^{-1} \\text { if } \\boldsymbol{A} \\text { is invertible. }\\end{aligned}\\)</p> <p></p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/02%20Matrices/#adjoint-matrix","title":"Adjoint Matrix","text":""},{"location":"Year%201%20Semester%202/MA2001/Notes/02%20Matrices/#cramers-rule","title":"Cramer's Rule","text":"<p>Let \\(\\boldsymbol{A}\\) be an invertible matrix of order \\(n\\).</p> <ul> <li>For every column matrix \\(\\boldsymbol{b}\\) of size \\(n \\times 1\\), the linear system \\(\\boldsymbol{A} \\boldsymbol{x}=\\boldsymbol{b}\\) has a unique solution</li> <li>\\(\\boldsymbol{x}=\\frac{1}{\\operatorname{det}(\\boldsymbol{A})}\\left(\\begin{array}{c}\\operatorname{det}\\left(\\boldsymbol{A}_1\\right) \\\\ \\vdots \\\\ \\operatorname{det}\\left(\\boldsymbol{A}_n\\right)\\end{array}\\right)\\)</li> <li>\\(\\boldsymbol{A}_j\\) is obtained from \\(\\boldsymbol{A}\\) by replacing its \\(j\\) th column by \\(\\boldsymbol{b}\\).</li> </ul> <p>Example. Let \\(\\boldsymbol{A}=\\left(\\begin{array}{ll}a_{11} &amp; a_{12} \\\\ a_{21} &amp; a_{22}\\end{array}\\right)\\) and \\(\\boldsymbol{b}=\\left(\\begin{array}{l}b_1 \\\\ b_2\\end{array}\\right)\\). - Suppose that \\(\\boldsymbol{A}\\) is invertible. \\(\\boldsymbol{A} \\boldsymbol{x}=\\boldsymbol{b}\\) implies \\(\\boldsymbol{x}=\\frac{1}{\\left|\\begin{array}{ll}a_{11} &amp; a_{12} \\\\ a_{21} &amp; a_{22}\\end{array}\\right|}\\left(\\begin{array}{ll}\\left|\\begin{array}{ll}b_1 &amp; a_{12} \\\\ b_2 &amp; a_{22}\\end{array}\\right| \\\\ \\left|\\begin{array}{ll}a_{11} &amp; b_1 \\\\ a_{21} &amp; b_2\\end{array}\\right|\\end{array}\\right)\\)</p> <p></p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/02%20Matrices/#appendix","title":"Appendix","text":""},{"location":"Year%201%20Semester%202/MA2001/Notes/02%20Matrices/#cofactor","title":"Cofactor","text":""},{"location":"Year%201%20Semester%202/MA2001/Notes/03%20Vector%20Spaces/","title":"Vector Spaces","text":"<p>MA2001-Chapter3</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/03%20Vector%20Spaces/#vector","title":"Vector","text":"<p>The arrow from the origin \\(O\\) to the point \\(P\\) is called a vector, denoted by \\(\\overrightarrow{O P}=v=(a, b)\\).</p> <p>Its length is \\(\\|\\boldsymbol{v}\\|=\\sqrt{v_1^2+v_2^2}\\)</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/03%20Vector%20Spaces/#euclidean-spaces","title":"Euclidean Spaces","text":"<p>The Euclidean \\(n\\)-space (or simply \\(n\\)-space) is the set of all \\(n\\)-vectors of real numbers.</p> <p>\\(\\mathbb{R}^n=\\left\\{\\left(v_1, v_2, \\ldots, v_n\\right) \\mid v_1, v_2, \\ldots, v_n \\in \\mathbb{R}\\right\\}\\) \\(\\boldsymbol{v} \\in \\mathbb{R}^n\\) if and only if \\(\\boldsymbol{v}\\) is of the form \\(\\boldsymbol{v}=\\left(v_1, v_2, \\ldots, v_n\\right)\\) for real numbers \\(v_1, v_2, \\ldots, v_n\\).</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/03%20Vector%20Spaces/#implicit-and-explicit-forms","title":"Implicit and Explicit Forms","text":"<p>Visit </p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/03%20Vector%20Spaces/#linear-combination","title":"Linear Combination","text":"<p>Visit </p> <p></p> <p>Treat the vectors as column vectors.</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/03%20Vector%20Spaces/#linear-span","title":"Linear Span","text":"<p>The set of all linear combination</p> <p>Visit </p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/03%20Vector%20Spaces/#criterion-for-operatornamespansmathbbrn","title":"Criterion for \\(\\operatorname{span}(S)=\\mathbb{R}^n\\)","text":"<p>Visit </p> <p>Let \\(S=\\left\\{\\boldsymbol{v}_1, \\boldsymbol{v}_2, \\ldots, \\boldsymbol{v}_k\\right\\} \\subseteq \\mathbb{R}^n\\). 1. View each \\(\\boldsymbol{v}_j\\) as a column vector. 2. Let \\(\\boldsymbol{A}=\\left(\\begin{array}{llll}\\boldsymbol{v}_1 &amp; \\boldsymbol{v}_2 &amp; \\cdots &amp; \\boldsymbol{v}_k\\end{array}\\right)\\). 3. Find a row-echelon form \\(\\boldsymbol{R}\\) of \\(\\boldsymbol{A}\\).     - If \\(\\boldsymbol{R}\\) has a zero row, then \\(\\operatorname{span}(S) \\neq \\mathbb{R}^n\\).     - If \\(\\boldsymbol{R}\\) has no zero row, then \\(\\operatorname{span}(S)=\\mathbb{R}^n\\).</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/03%20Vector%20Spaces/#properties-of-linear-spans","title":"Properties of Linear Spans","text":"<p>Visit </p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/03%20Vector%20Spaces/#to-show-span-u_1u_2dotsspanv_1v_2dots","title":"To show \\(span ({u_{1},u_{2},\\dots)=span({v_{1},v_{2}\\dots})}\\)","text":""},{"location":"Year%201%20Semester%202/MA2001/Notes/03%20Vector%20Spaces/#subspaces","title":"Subspaces","text":"<p>Visit </p> <p>In the form Let \\(V_1=\\{(a+4 b, a) \\mid a, b \\in \\mathbb{R}\\}\\). </p> <p>In the form Let \\(V_2=\\{(x, y, z) \\mid x+y-z=0\\}\\).</p> <p>Important Recall that a subspace \\(V\\) is of the form \\(\\operatorname{span}(S)\\). Then</p> <ul> <li>\\(\\mathbf{0} \\in V\\),</li> <li>\\(c \\in \\mathbb{R} \\&amp; \\boldsymbol{v} \\in V \\Rightarrow c \\boldsymbol{v} \\in V\\),</li> <li>\\(\\boldsymbol{u} \\in V \\&amp; v \\in V \\Rightarrow \\boldsymbol{u}+\\boldsymbol{v} \\in V\\).</li> </ul> <p>If any of the above fails, then \\(V\\) is not a subspace (of \\(\\mathbb{R}^n\\) ). </p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/03%20Vector%20Spaces/#solution-space","title":"Solution Space","text":"<p>Visit </p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/03%20Vector%20Spaces/#linear-independence","title":"Linear Independence","text":"<p>Visit </p> <p></p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/03%20Vector%20Spaces/#vector-spaces_1","title":"Vector Spaces","text":"<p>Visit </p> <p>Definition. A set \\(V\\) is called a vector space if</p> <ul> <li>\\(V\\) is a subspace of \\(\\mathbb{R}^n\\) for some positive integer \\(n\\).</li> </ul> <p>If \\(W\\) and \\(V\\) are vector spaces such that \\(W \\subseteq V\\),</p> <ul> <li>then \\(W\\) is a subspace of \\(V\\).</li> </ul>"},{"location":"Year%201%20Semester%202/MA2001/Notes/03%20Vector%20Spaces/#bases","title":"Bases","text":"<p>Visit </p> <p>Definition. Let \\(S=\\left\\{\\boldsymbol{v}_1, \\ldots, \\boldsymbol{v}_k\\right\\}\\) be a subset of a vector space \\(V\\). Then \\(S\\) is called a basis (plural bases) for \\(V\\) if</p> <ul> <li>\\(S\\) is linearly independent, and \\(\\operatorname{span}(S)=V\\).</li> </ul> <p>Example Let \\(S=\\{(1,1,1,1),(0,0,1,2),(-1,0,0,1)\\}\\).</p> <ul> <li>Let \\(|S|\\) be the number of vectors in \\(S\\). Then \\(|S|=3\\).</li> <li>So \\(\\operatorname{span}(S) \\neq \\mathbb{R}^4\\); thus \\(S\\) is NOT a basis for \\(\\mathbb{R}^4\\).</li> </ul> <p></p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/03%20Vector%20Spaces/#coordinate-vector","title":"Coordinate Vector","text":"<p>Visit </p> <p>Definition. Let \\(S=\\left\\{\\boldsymbol{v}_1, \\boldsymbol{v}_2, \\ldots, \\boldsymbol{v}_k\\right\\}\\) be a basis for a vector space \\(V\\).</p> <ul> <li>For every \\(\\boldsymbol{v} \\in V\\), there exist unique \\(c_1, \\ldots, c_k \\in \\mathbb{R}\\) s.t.<ul> <li>\\(\\boldsymbol{v}=c_1 \\boldsymbol{v}_1+c_2 \\boldsymbol{v}_2+\\cdots+c_k \\boldsymbol{v}_k\\).   \\(c_1, c_2, \\ldots, c_k\\) are the coordinates of \\(v\\) relative to \\(S\\).</li> <li>\\(\\left(c_1, c_2, \\ldots, c_k\\right)\\) is the coordinate vector of \\(\\boldsymbol{v}\\) relative to the basis \\(S\\), denoted by \\((\\boldsymbol{v})_S\\).</li> </ul> </li> </ul> <p>The order matters</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/03%20Vector%20Spaces/#standard-basis","title":"Standard Basis","text":"<p>Visit </p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/03%20Vector%20Spaces/#criterion-for-bases","title":"Criterion for Bases","text":"<p>Visit </p> <p>Theorem. Let \\(\\boldsymbol{A}\\) be a square matrix of order \\(n\\). Then the following are equivalent:</p> <ol> <li>\\(\\boldsymbol{A}\\) is invertible.</li> <li>\\(\\boldsymbol{A x}=\\boldsymbol{b}\\) has a unique solution.</li> <li>\\(\\boldsymbol{A x}=\\mathbf{0}\\) has only the trivial solution.</li> <li>The reduced row-echelon form of \\(A\\) is \\(I_n\\).</li> <li>\\(\\boldsymbol{A}\\) is a product of elementary matrices.</li> <li>\\(\\operatorname{det}(\\boldsymbol{A}) \\neq 0\\).</li> <li>The rows of \\(\\boldsymbol{A}\\) form a basis for \\(\\mathbb{R}^n\\).</li> <li>The columns of \\(\\boldsymbol{A}\\) form a basis for \\(\\mathbb{R}^n\\).</li> </ol>"},{"location":"Year%201%20Semester%202/MA2001/Notes/03%20Vector%20Spaces/#dimension","title":"Dimension","text":"<p>\\(\\operatorname{dim}(V+W)=\\operatorname{dim}(V)+\\operatorname{dim}(W)-\\operatorname{dim}(V \\cap W)\\). See example </p> <p>Visit </p> <p>Number of non pivots.</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/03%20Vector%20Spaces/#transition-matrices","title":"Transition Matrices","text":"<p>Visit </p> <p> of using transition matrix to get the coordinate vector relative to... </p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/03%20Vector%20Spaces/#row-spaces-and-column-spaces","title":"Row Spaces and Column Spaces","text":"<p>Visit </p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/03%20Vector%20Spaces/#how-to-find-basis","title":"How to find basis","text":"<p>Visit </p> <p>Using Row Space: View the vectors as row vector. Turn it into REF. The non zero rows of REF form the basis. However the basis are now different vectors.</p> <p>Using Column Space:</p> <p></p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/03%20Vector%20Spaces/#how-to-extend-s-to-a-basis-for-rn","title":"How to extend \\(S\\) to a basis for \\(R^n\\)","text":"<p>Visit </p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/03%20Vector%20Spaces/#consistency","title":"Consistency","text":"<p>Visit </p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/03%20Vector%20Spaces/#rank","title":"Rank","text":"<p>Visit </p> <p>Theorem: The dimension of the row space of \\(A\\) = the dimension of the column space of \\(A\\).</p> <p>Rank of A, denoted by rank(\\(A\\)): the dimension of the row (or column) space of \\(A\\)</p> <ul> <li>rank (\\(A\\)) = rank(\\(A^T\\))</li> <li>rank(\\(A\\)) = 0</li> <li>\\(\\operatorname{rank}(\\boldsymbol{A}) \\leq m\\) and \\(\\operatorname{rank}(\\boldsymbol{A}) \\leq n\\)<ul> <li>\\(\\operatorname{rank}(\\boldsymbol{A}) \\leq \\min \\{m, n\\}\\).</li> <li>\\(\\boldsymbol{A}\\) is called full rank if \\(\\operatorname{rank}(\\boldsymbol{A})=\\min \\{m, n\\}\\).</li> </ul> </li> <li>A square matrix \\(A\\) is of full rank \\(\\Leftrightarrow A\\) is invertible.</li> </ul>"},{"location":"Year%201%20Semester%202/MA2001/Notes/03%20Vector%20Spaces/#rank-consistency-of-linear-system","title":"Rank &amp; Consistency of Linear System","text":"<p>The inconsistency can also be determined by the rank.</p> <p>Suppose \\(Ax=b\\).  - If \\(b\\) belong to the column space of \\(A\\) then, rank(\\(A\\)) = rank(\\(A|b\\)) - Else rank(\\(A\\)) = rank(\\(A|b\\))+1</p> <p>Visit </p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/03%20Vector%20Spaces/#properties","title":"Properties","text":"<p>Visit </p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/03%20Vector%20Spaces/#null-space-and-nullity","title":"Null Space and Nullity","text":"<p>The nullspace of \\(A\\) is the solution space of \\(\\boldsymbol{A x}=\\mathbf{0}\\) </p> <p>The dimension of the nullspace is called the nullity of \\(\\boldsymbol{A}\\), denoted by nullity \\((\\boldsymbol{A})\\).</p> <p>Notation. From now on, unless otherwise stated, vectors in nullspace are viewed as column vectors.</p> <p>Visit </p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/03%20Vector%20Spaces/#dimension-theorem","title":"Dimension Theorem","text":"<p>Theorem. Let \\(\\boldsymbol{A}\\) be an \\(m \\times n\\) matrix. Then $$ \\operatorname{rank}(\\boldsymbol{A})+\\operatorname{nullity}(\\boldsymbol{A})=n \\text {. } $$</p> <p>Visit </p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/03%20Vector%20Spaces/#inhomogeneous-linear-system","title":"Inhomogeneous Linear System","text":"<p>Visit </p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/04%20Orthogonality/","title":"Orthogonality","text":"Resources <p>MA2001-Chapter5</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/04%20Orthogonality/#angle-between-vectors","title":"Angle Between Vectors","text":"<p>Visit PDF</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/04%20Orthogonality/#dot-product-and-matrix-multiplication","title":"Dot Product and Matrix Multiplication","text":"<p>Let \\(\\boldsymbol{u}\\) and \\(\\boldsymbol{v}\\) be vectors in \\(\\mathbb{R}^n\\).</p> <p>Suppose they are viewed as row vectors: \\(\\(\\boldsymbol{u}=\\left(u_1, \\ldots, u_n\\right), \\boldsymbol{v}=\\left(v_1, \\ldots, v_n\\right)\\)\\). $$ \\boldsymbol{u} \\cdot \\boldsymbol{v}=\\left(u_1, \\ldots, u_n\\right)\\left(\\begin{array}{c} v_1 \\ \\vdots \\ v_n \\end{array}\\right)=\\boldsymbol{u} \\boldsymbol{v}^{\\mathrm{T}} $$ Suppose they are viewed as column vectors: $$ \\boldsymbol{u}=\\left(\\begin{array}{c} u_1 \\ \\vdots \\ u_n \\end{array}\\right), \\boldsymbol{v}=\\left(\\begin{array}{c} v_1 \\ \\vdots \\ v_n \\end{array}\\right) \\text {. } $$ $$ \\boldsymbol{u} \\cdot \\boldsymbol{v}=\\left(u_1, \\ldots, u_n\\right)\\left(\\begin{array}{c} v_1 \\ \\vdots \\ v_n \\end{array}\\right)=\\boldsymbol{u}^{\\mathrm{T}} \\boldsymbol{v} $$</p> <p>Visit PDF</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/04%20Orthogonality/#properties","title":"Properties","text":"<p>Visit PDF</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/04%20Orthogonality/#orthogonal-and-orthonormal-bases","title":"Orthogonal and Orthonormal Bases","text":"<p>\\(S\\) is called orthogonal if every pair of distinct vectors in \\(S\\) are orthogonal:</p> <ul> <li>\\(\\boldsymbol{v}_i \\cdot \\boldsymbol{v}_j=0\\) for all \\(i \\neq j\\).</li> </ul> <p>\\(S\\) is called orthonormal if \\(S\\) is orthogonal and every vector in \\(S\\) is a unit vector.</p> <ul> <li>\\(\\boldsymbol{v}_i \\cdot \\boldsymbol{v}_j= \\begin{cases}0 &amp; \\text { if } i \\neq j \\\\ 1 &amp; \\text { if } i=j\\end{cases}\\)</li> </ul> <p>If \\(S\\) is orthonormal, then \\(S\\) is orthogonal. If \\(S\\) is orthogonal, then a subset of \\(S\\) is orthogonal.  If \\(S\\) is orthonormal, then a subset of \\(S\\) is orthonormal.  If \\(S\\) is orthogonal, then \\(S \\cup\\{\\mathbf{0}\\}\\) is also orthogonal.  If \\(S\\) is orthonormal, then \\(0 \\notin S\\).</p> <p>Visit PDF</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/04%20Orthogonality/#normalizing","title":"Normalizing","text":"<p>The process of converting an orthogonal set of nonzero vectors to an orthonormal set of vectors, \\(\\boldsymbol{u}_i \\mapsto \\boldsymbol{v}_i=\\frac{\\boldsymbol{u}_i}{\\left\\|\\boldsymbol{u}_i\\right\\|}\\), is called normalizing.</p> <p>Visit </p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/04%20Orthogonality/#how-to-check-orthogonal-and-orthonormal","title":"How to check Orthogonal and Orthonormal","text":"<p>Let \\(\\left\\{v_1, \\ldots, v_k\\right\\}\\) (column vectors) be a subset of \\(\\mathbb{R}^n\\).</p> <p>Let \\(\\boldsymbol{A}=\\left(\\begin{array}{lll}\\boldsymbol{v}_1 &amp; \\cdots &amp; \\boldsymbol{v}_k\\end{array}\\right)\\). Then \\(\\boldsymbol{A}^{\\mathrm{T}}=\\left(\\begin{array}{c}\\boldsymbol{v}_1^{\\mathrm{T}} \\\\ \\vdots \\\\ \\boldsymbol{v}_k^{\\mathrm{T}}\\end{array}\\right)\\).</p> <p>\\(\\boldsymbol{A}^{\\mathrm{T}} \\boldsymbol{A}=\\left(\\begin{array}{ccc}\\boldsymbol{v}_1 \\cdot \\boldsymbol{v}_1 &amp; \\cdots &amp; \\boldsymbol{v}_1 \\cdot \\boldsymbol{v}_k \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ \\boldsymbol{v}_k \\cdot \\boldsymbol{v}_1 &amp; \\cdots &amp; \\boldsymbol{v}_k \\cdot \\boldsymbol{v}_k\\end{array}\\right)=\\left(\\boldsymbol{v}_i \\cdot \\boldsymbol{v}_j\\right)_{k \\times k}\\).</p> <p>\\(\\left\\{\\boldsymbol{v}_1, \\ldots, \\boldsymbol{v}_k\\right\\}\\) is orthogonal \\(\\Leftrightarrow \\boldsymbol{v}_i \\cdot \\boldsymbol{v}_j=0\\) for all \\(i \\neq j\\) \\(\\Leftrightarrow \\boldsymbol{A}^{\\mathrm{T}} \\boldsymbol{A}\\) is diagonal.</p> <p>\\(\\begin{aligned}\\left\\{\\boldsymbol{v}_1, \\ldots, \\boldsymbol{v}_k\\right\\} \\text { is orthonormal } &amp; \\Leftrightarrow \\boldsymbol{v}_i \\cdot \\boldsymbol{v}_j= \\begin{cases}0 &amp; \\text { if } i \\neq j \\\\ 1 &amp; \\text { if } i=j,\\end{cases} \\\\ &amp; \\Leftrightarrow \\boldsymbol{A}^{\\mathrm{T}} \\boldsymbol{A}=\\boldsymbol{I}_k .\\end{aligned}\\) Identity.</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/04%20Orthogonality/#linear-independency","title":"Linear Independency","text":"<p>Theorem. Let \\(S=\\left\\{\\boldsymbol{v}_1, \\boldsymbol{v}_2, \\ldots, \\boldsymbol{v}_k\\right\\}\\) be an orthogonal set of nonzero vectors in \\(\\mathbb{R}^n\\).</p> <ul> <li>Then \\(S\\) is linearly independent.</li> </ul> <p>Definition. Let \\(S\\) be a basis for a vector space.</p> <ul> <li>\\(S\\) is an orthogonal basis if it is orthogonal.</li> <li>\\(S\\) is an orthonormal basis if it is orthonormal.</li> </ul> <p>Visit PDF</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/04%20Orthogonality/#properties_1","title":"Properties","text":"<p>What are the advantages of orthogonal basis?</p> <p>Visit PDF</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/04%20Orthogonality/#finding-the-coordinate-vector-using-orthogonal-set","title":"Finding the coordinate vector using orthogonal set","text":"<p>Visit PDF</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/04%20Orthogonality/#orthogonality_1","title":"Orthogonality","text":""},{"location":"Year%201%20Semester%202/MA2001/Notes/04%20Orthogonality/#how-to-check-if-a-vector-is-orthogonal-to-a-spanning-set","title":"How to check if a vector is orthogonal to a spanning set","text":"<p>Visit PDF</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/04%20Orthogonality/#projection","title":"Projection","text":"<p>Visit PDF</p> <p>Theorem. Let \\(\\left\\{\\boldsymbol{v}_1, \\boldsymbol{v}_2, \\ldots, \\boldsymbol{v}_k\\right\\}\\) be an orthonormal basis for a vector space \\(V\\). The projection of \\(\\boldsymbol{w}\\) onto \\(V\\) is</p> \\[\\left(\\boldsymbol{w} \\cdot \\boldsymbol{v}_1\\right) \\boldsymbol{v}_1+\\left(\\boldsymbol{w} \\cdot \\boldsymbol{v}_2\\right) \\boldsymbol{v}_2+\\cdots+\\left(\\boldsymbol{w} \\cdot \\boldsymbol{v}_k\\right) \\boldsymbol{v}_k\\] <p>Theorem. Let \\(\\left\\{\\boldsymbol{u}_1, \\boldsymbol{u}_2, \\ldots, \\boldsymbol{u}_k\\right\\}\\) be an orthogonal basis for a vector space \\(V\\). The projection of \\(\\boldsymbol{w}\\) onto \\(V\\) is</p> \\[\\left(\\frac{\\boldsymbol{w} \\cdot \\boldsymbol{u}_1}{\\boldsymbol{u}_1 \\cdot \\boldsymbol{u}_1}\\right) \\boldsymbol{u}_1+\\left(\\frac{\\boldsymbol{w} \\cdot \\boldsymbol{u}_2}{\\boldsymbol{u}_2 \\cdot \\boldsymbol{u}_2}\\right) \\boldsymbol{u}_2+\\cdots+\\left(\\frac{\\boldsymbol{w} \\cdot \\boldsymbol{u}_k}{\\boldsymbol{u}_k \\cdot \\boldsymbol{u}_k}\\right) \\boldsymbol{u}_k\\] <p>Visit PDF</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/04%20Orthogonality/#gram-schmidt-process","title":"Gram-Schmidt Process","text":"<p>How to find an orthogonal basis for a given vector space? Make sure that the vectors are linearly independent. Otherwise just do the gram-schmidt process and ignore zero vector.</p> <p>Visit PDF</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/04%20Orthogonality/#decomposition","title":"Decomposition","text":"<p>Theorem. Let \\(\\boldsymbol{A}\\) be an \\(m \\times n\\) matrix whose columns are linearly independent. Then there exist</p> <ul> <li>An \\(m \\times n\\) matrix \\(\\boldsymbol{Q}\\) whose columns form an orthonormal set, and</li> <li>An invertible \\(n \\times n\\) upper triangular matrix \\(\\boldsymbol{R}\\)</li> </ul> <p>such that \\(A=Q R\\).</p> <p>Application: Solve linear system \\(\\boldsymbol{A x}=\\boldsymbol{b}\\).</p> <ol> <li>\\((\\boldsymbol{Q R}) \\boldsymbol{x}=\\boldsymbol{b}\\).</li> <li>\\(\\boldsymbol{Q}^{\\mathrm{T}} \\boldsymbol{Q} \\boldsymbol{R} \\boldsymbol{x}=\\boldsymbol{Q}^{\\mathrm{T}} \\boldsymbol{b} \\Rightarrow \\boldsymbol{R} \\boldsymbol{x}=\\boldsymbol{Q}^{\\mathrm{T}} \\boldsymbol{b}\\).</li> <li>Solve \\(\\boldsymbol{x}\\) by back-substitution.</li> </ol>"},{"location":"Year%201%20Semester%202/MA2001/Notes/04%20Orthogonality/#best-approximations","title":"Best Approximations","text":"<p>Find the orthogonal basis first. Then use it to calculate P. Visit PDF</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/04%20Orthogonality/#finding-the-shortest-distance-from-a-point-and-a-plane","title":"Finding the shortest distance from a point and a plane","text":"<p>Visit PDF</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/04%20Orthogonality/#least-squares-solution","title":"Least Squares Solution","text":"<p>Finding the best approximation of Ax = b where b is not in V (column space of A). Visit PDF PDF</p> <p>Find a least squares solution to \\(A x=b\\) :</p> <ol> <li>Find an orthogonal (orthonormal) basis for \\(V\\), the column space of \\(\\boldsymbol{A}\\).</li> <li>Find the projection \\(p\\) of \\(b\\) onto \\(V\\).</li> <li>Solve the linear system \\(\\boldsymbol{A x}=\\boldsymbol{p}\\).</li> </ol> <p>Then a solution to \\(\\boldsymbol{A x}=\\boldsymbol{p}\\) is a least squares solution to \\(\\boldsymbol{A x}=\\boldsymbol{b}\\).</p> <ul> <li>If \\(\\boldsymbol{A x}=\\boldsymbol{b}\\) is already consistent, what is the least squares solution?<ul> <li>\\(\\boldsymbol{b}=\\boldsymbol{p} \\in V\\). Solution = Least squares solution.</li> </ul> </li> </ul> <p>Easier method Example</p> <p>Theorem. (Find the least squares solutions)</p> <ul> <li>\\(\\boldsymbol{u}\\) is a least squares solution to \\(\\boldsymbol{A x}=\\boldsymbol{b}\\) \\(\\Leftrightarrow \\boldsymbol{u}\\) is a solution to \\(\\boldsymbol{A}^{\\mathrm{T}} \\boldsymbol{A} \\boldsymbol{x}=\\boldsymbol{A}^{\\mathrm{T}} \\boldsymbol{b}\\).</li> </ul> <p>This can also be used to find the projection. \\(\\boldsymbol{p}=\\boldsymbol{A} \\boldsymbol{u}\\). Example</p> <p>In summary:</p> <p>\\(x\\) is a LSS to \\(Ax=b\\) iff \\(x\\) is a solution to \\(Ax=p\\) (projection) iff \\(x\\) is a solution to \\(A^TAx=A^Tb\\)</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/04%20Orthogonality/#orthogonal-matrices","title":"Orthogonal Matrices","text":"<p>\\(\\boldsymbol{A}\\) is an orthogonal matrix \\(\\Leftrightarrow\\) columns of \\(\\boldsymbol{A}\\) form an orthonormal basis for \\(\\mathbb{R}^n\\). \\(\\Leftrightarrow\\) rows of \\(\\boldsymbol{A}\\) form an orthonormal basis for \\(\\mathbb{R}^n\\). \\(\\Leftrightarrow\\) \\(A^T=A^-1\\)</p> <p>Advantages: Visit PDF</p> <p>Visit PDF</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/04%20Orthogonality/#properties_2","title":"Properties","text":"<p>Visit PDF </p> <p>More generally, for any \\(m \\times n\\) matrix \\(\\boldsymbol{A}\\) : - \\(\\boldsymbol{A}^{\\mathrm{T}} \\boldsymbol{A}=\\boldsymbol{I}_n\\) \\(\\Leftrightarrow\\) the columns of \\(\\boldsymbol{A}\\) form an orthonormal set. - \\(\\boldsymbol{A} \\boldsymbol{A}^{\\mathrm{T}}=\\boldsymbol{I}_m\\) \\(\\Leftrightarrow\\) the rows of \\(\\boldsymbol{A}\\) form an orthonormal set.</p> <p>Let \\(S=\\left\\{\\boldsymbol{u}_1, \\ldots, \\boldsymbol{u}_k\\right\\}\\) be an orthonormal subset of \\(\\mathbb{R}^n\\). - Let \\(\\boldsymbol{A}=\\left(\\begin{array}{lll}\\boldsymbol{u}_1 &amp; \\cdots &amp; \\boldsymbol{u}_k\\end{array}\\right)\\). Then \\(\\boldsymbol{A}^{\\mathrm{T}} \\boldsymbol{A}=\\boldsymbol{I}_k\\).     - Let \\(\\boldsymbol{P}\\) be an \\(n \\times n\\) orthogonal matrix.       \\((\\boldsymbol{P} \\boldsymbol{A})^{\\mathrm{T}}(\\boldsymbol{P} \\boldsymbol{A})=\\boldsymbol{A}^{\\mathrm{T}} \\boldsymbol{P}^{\\mathrm{T}} \\boldsymbol{P} \\boldsymbol{A}=\\boldsymbol{A}^{\\mathrm{T}} \\boldsymbol{A}=\\boldsymbol{I}_k\\). - \\(\\boldsymbol{P A}=\\left(\\begin{array}{lll}\\boldsymbol{P} \\boldsymbol{u}_1 &amp; \\cdots &amp; \\boldsymbol{P} \\boldsymbol{u}_k\\end{array}\\right)\\). \\(\\circ \\quad\\left\\{\\boldsymbol{P} \\boldsymbol{u}_1, \\ldots, \\boldsymbol{P} \\boldsymbol{u}_k\\right\\}\\) is also an orthonormal set.</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/04%20Orthogonality/#properties-transition-matrix","title":"Properties Transition matrix","text":"<p>Visit PDF </p> <p>IMPORTANT EXAMPLES: Visit PDF </p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/04%20Orthogonality/#classification","title":"Classification","text":"<p>Visit PDF </p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/04%20Orthogonality/#geometric-representation","title":"Geometric Representation","text":"<p>Visit  </p> <p>Rotation PDF</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/05%20Diagonalization/","title":"Diagonalization","text":""},{"location":"Year%201%20Semester%202/MA2001/Notes/05%20Diagonalization/#motivation","title":"Motivation","text":"<p>Let \\(\\boldsymbol{A}\\) be a square matrix.</p> <ul> <li>Suppose there exists an invertible matrix \\(\\boldsymbol{P}\\) such that</li> <li>\\(\\boldsymbol{P}^{-1} \\boldsymbol{A P}=\\boldsymbol{D}\\) is a diagonal matrix.   Then \\(\\boldsymbol{A}=\\boldsymbol{P} \\boldsymbol{D} \\boldsymbol{P}^{-1}\\). $$ \\begin{aligned} \\boldsymbol{A}^m &amp; =\\left(\\boldsymbol{P} \\boldsymbol{D} \\boldsymbol{P}{-1}\\right)m \\ &amp; =\\underbrace{\\left(\\boldsymbol{P} \\boldsymbol{D} \\boldsymbol{P}^{-1}\\right)\\left(\\boldsymbol{P D} \\boldsymbol{P}^{-1}\\right) \\cdots\\left(\\boldsymbol{P} \\boldsymbol{D} \\boldsymbol{P}^{-1}\\right)}{m \\text { times }} \\ &amp; =\\boldsymbol{P} \\boldsymbol{D}\\left(\\boldsymbol{P}^{-1} \\boldsymbol{P}\\right) \\boldsymbol{D}\\left(\\boldsymbol{P}^{-1} \\boldsymbol{P}\\right) \\cdots\\left(\\boldsymbol{P}^{-1} \\boldsymbol{P}\\right) \\boldsymbol{D} \\boldsymbol{P}^{-1} \\ &amp; =\\boldsymbol{P} \\underbrace{\\boldsymbol{D} \\cdots \\boldsymbol{D} \\boldsymbol{D} \\boldsymbol{P}^{-1}}} \\ &amp; =\\boldsymbol{P} \\boldsymbol{D}^m \\boldsymbol{P}^{-1} . \\end{aligned} $$</li> </ul> <p>Visit PDF Example</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/05%20Diagonalization/#definition","title":"Definition","text":"<p>See PDF First</p> <p>Let \\(\\boldsymbol{A}\\) be a square matrix of order \\(n\\).</p> <p>Suppose that for some \\(\\lambda \\in \\mathbb{R}\\) and nonzero \\(v \\in \\mathbb{R}^n\\)</p> <ul> <li>\\(\\boldsymbol{A v}=\\lambda v\\)</li> </ul> <p>\\(\\lambda\\) is called an eigenvalue of \\(\\boldsymbol{A}\\). \\(\\boldsymbol{v}\\) is called an eigenvector of \\(\\boldsymbol{A}\\) associated with \\(\\lambda\\).</p> <p>Example</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/05%20Diagonalization/#characteristic-equation","title":"Characteristic Equation","text":"<p>Theorem. Let \\(\\boldsymbol{A}\\) be a square matrix.</p> <ul> <li>Then the eigenvalues of \\(A\\) are precisely all the roots to the characteristic equation \\(\\operatorname{det}(\\lambda \\boldsymbol{I}-\\boldsymbol{A})=0\\)</li> </ul> <p>Example</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/05%20Diagonalization/#main-theorem-for-invertible-matrices","title":"Main theorem for invertible matrices","text":"<p>Theorem. Let \\(\\boldsymbol{A}\\) be a square matrix of order \\(n\\). Then the following are equivalent:</p> <ol> <li>\\(A\\) is invertible.</li> <li>The reduced row-echelon form of \\(\\boldsymbol{A}\\) is \\(\\boldsymbol{I}_n\\).</li> <li>The homogeneous linear system \\(\\boldsymbol{A x}=\\mathbf{0}\\) has only the trivial solution.</li> <li>The linear system \\(\\boldsymbol{A} \\boldsymbol{x}=\\boldsymbol{b}\\) has exactly one solution.</li> <li>\\(A\\) is the product of elementary matrices.</li> <li>\\(\\operatorname{det}(\\boldsymbol{A}) \\neq 0\\).</li> <li>The rows of \\(A\\) form a basis for \\(\\mathbb{R}^n\\).</li> <li>The columns of \\(\\boldsymbol{A}\\) form a basis for \\(\\mathbb{R}^n\\).</li> <li>\\(\\operatorname{rank}(\\boldsymbol{A})=n\\).</li> <li>0 is not an eigenvalue of \\(\\boldsymbol{A}\\).</li> </ol> <p>Proof of number 10</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/05%20Diagonalization/#upper-triangular-matrices","title":"Upper Triangular Matrices","text":"<p>It is easier to find the eigenvalue for upper triangular matrices. See why</p> <p>Theorem. Let \\(\\boldsymbol{A}\\) be an upper (or lower) triangular matrix. Then its eigenvalues are all the diagonal entries of \\(\\boldsymbol{A}\\).</p> <ul> <li>More precisely, if \\(\\boldsymbol{A}=\\left(a_{i j}\\right)_{n \\times n}\\) is upper triangular \\(\\left(a_{i j}=0\\right.\\) if \\(\\left.i&gt;j\\right)\\) or lower triangular \\(\\left(a_{i j}=0\\right.\\) if \\(\\left.i&lt;j\\right)\\)<ul> <li>then the eigenvalues of \\(\\boldsymbol{A}\\) are \\(a_{11}, a_{22}, \\ldots, a_{n n}\\).</li> </ul> </li> </ul>"},{"location":"Year%201%20Semester%202/MA2001/Notes/05%20Diagonalization/#eigenspace","title":"Eigenspace","text":"<p>Let \\(\\boldsymbol{A}\\) be a square matrix of order \\(n\\).</p> <ul> <li>Let \\(\\lambda\\) be an eigenvalue of \\(\\boldsymbol{A}\\).</li> </ul> <p>Let \\(0 \\neq v \\in \\mathbb{R}^n\\). Then</p> <ul> <li>\\(\\boldsymbol{v}\\) is an eigenvector of \\(\\boldsymbol{A}\\) associated to \\(\\lambda\\) $$ \\begin{aligned} &amp; \\Leftrightarrow \\boldsymbol{A} \\boldsymbol{v}=\\lambda \\boldsymbol{v} \\ &amp; \\Leftrightarrow(\\lambda \\boldsymbol{I}-\\boldsymbol{A}) \\boldsymbol{v}=\\mathbf{0} \\ &amp;\\Leftrightarrow v \\text{is a nonzero vector in the nullspace of} \\lambda \\boldsymbol{I}-\\boldsymbol{A} \\end{aligned} $$</li> </ul> <p>Definition. Let \\(\\boldsymbol{A}\\) be a square matrix and \\(\\lambda\\) an eigenvalue of \\(\\boldsymbol{A}\\). (Then \\(\\lambda \\boldsymbol{I}-\\boldsymbol{A}\\) is singular.)</p> <ul> <li>The eigenspace of \\(\\boldsymbol{A}\\) associated to \\(\\lambda\\) is the nullspace of \\(\\lambda \\boldsymbol{I}-\\boldsymbol{A}\\), denoted by \\(E_\\lambda\\) (or \\(E_{\\boldsymbol{A}, \\lambda}\\) ).</li> <li>\\(E_\\lambda\\) consists of all the eigenvectors of \\(A\\) associated to \\(\\lambda\\), and the zero vector 0 . Note that \\(\\operatorname{dim} E_\\lambda \\geq 1\\)</li> </ul> <p>Example</p> <p>SEE IMPORTANT TIP: Example</p> <ul> <li>Here, \\(\\left(\\begin{array}{ccc}2 &amp; -1 &amp; -1 \\\\ -1 &amp; 2 &amp; -1 \\\\ -1 &amp; -1 &amp; 2\\end{array}\\right)\\) is singular. Also we see that \\(R_{1}\\) and \\(R_{2}\\) are linearly independent (They are not a constant multiple of each other). Thus we can just ignore \\(R_{3}\\) during the calculation.</li> </ul> <p>NOTE: If \\(\\boldsymbol{A}\\) is singular, then 0 is an eigenvalue of \\(\\boldsymbol{A}\\), then the eigenspace \\(E_0\\) is the nullspace of \\(\\boldsymbol{A}\\).  Example</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/05%20Diagonalization/#diagonalizable-matrices","title":"Diagonalizable Matrices","text":"<p>Definition. Let \\(\\boldsymbol{A}\\) be a square matrix.</p> <ul> <li>\\(\\boldsymbol{A}\\) is called diagonalizable if there exists an invertible matrix \\(\\boldsymbol{P}\\) such that \\(\\boldsymbol{P}^{-1} \\boldsymbol{A P}\\) is a diagonal matrix.</li> </ul> <p>Examples.</p> <p>\\(\\boldsymbol{A}=\\left(\\begin{array}{cc}0.96 &amp; 0.01 \\\\ 0.04 &amp; 0.99\\end{array}\\right)\\) and \\(\\boldsymbol{P}=\\left(\\begin{array}{cc}0.25 &amp; -1 \\\\ 1 &amp; 1\\end{array}\\right)\\) - Then \\(\\boldsymbol{P}^{-1} \\boldsymbol{A P}=\\boldsymbol{D}=\\left(\\begin{array}{cc}1 &amp; 0 \\\\ 0 &amp; 0.95\\end{array}\\right)\\). Then \\(\\boldsymbol{A}\\) is diagonalizable. - Note that the diagonal entries of \\(\\boldsymbol{D}\\) are the eigenvalues of \\(\\boldsymbol{A}\\). - The columns of \\(\\boldsymbol{P}\\) are eigenvectors of \\(\\boldsymbol{A}\\) associated to these eigenvalues.</p> <p>Example</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/05%20Diagonalization/#criterion-of-diagonalizability","title":"Criterion of Diagonalizability","text":"<p>\\(\\boldsymbol{A}\\) is diagonalizable \\(\\Leftrightarrow A\\) has \\(n\\) linearly independent eigenvectors.</p> <p>Remark. Suppose that \\(\\boldsymbol{P}^{-1} \\boldsymbol{A P}=\\boldsymbol{D}\\) is diagonal. - The diagonal entries of \\(\\boldsymbol{D}\\) are eigenvalues of \\(\\boldsymbol{A}\\) :     - \\(\\lambda_1, \\ldots, \\lambda_n\\), which may be repeated.       \\(\\boldsymbol{D}\\) is not unique unless \\(\\boldsymbol{A}\\) has only one eigenvalue. - The columns of \\(\\boldsymbol{P}\\) are eigenvectors of \\(\\boldsymbol{A}\\) :     - \\(\\boldsymbol{v}_1, \\ldots, \\boldsymbol{v}_n\\), which are linearly independent.     - \\(\\boldsymbol{v}_i\\) is an eigenvector of \\(\\boldsymbol{A}\\) associated to \\(\\lambda_i\\).       \\(\\boldsymbol{P}\\) is not unique. For instance,     - \\(v_i\\) can be replaced by a nonzero multiple of \\(v_i\\).</p> <p>PDF</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/05%20Diagonalization/#algorithm-of-diagonalization","title":"Algorithm of Diagonalization","text":"<p>PDF - PDF</p> <p>Let \\(\\boldsymbol{A}\\) be a square matrix of order \\(n\\).</p> <p>Case 1. If \\(\\operatorname{det}(\\lambda \\boldsymbol{I}-\\boldsymbol{A})\\) cannot be completely factorized,</p> <ul> <li>then \\(\\boldsymbol{A}\\) is not diagonalizable.</li> </ul> <p>Case 2. If \\(\\operatorname{det}(\\lambda \\boldsymbol{I}-\\boldsymbol{A})\\) can be completely factorized,</p> <ul> <li>for each \\(\\lambda_i\\), find a basis \\(S_i\\) for its eigenspace.</li> <li>2a. If \\(\\left|S_i\\right|&lt;a\\left(\\lambda_i\\right)\\) for some \\(i\\),<ul> <li>then \\(\\boldsymbol{A}\\) is not diagonalizable.</li> </ul> </li> <li>2b. If \\(\\left|S_i\\right|=a\\left(\\lambda_i\\right)\\) for all \\(i\\),<ul> <li>then \\(\\boldsymbol{A}\\) is diagonalizable.</li> <li>\\(S_1 \\cup \\cdots \\cup S_k=\\left\\{\\boldsymbol{v}_1, \\ldots, \\boldsymbol{v}_n\\right\\}\\) is a basis for \\(\\mathbb{R}^n\\).</li> <li>\\(\\boldsymbol{P}=\\left(\\begin{array}{lll}\\boldsymbol{v}_1 &amp; \\cdots &amp; \\boldsymbol{v}_n\\end{array}\\right)\\) diagonalizes \\(\\boldsymbol{A}\\).</li> </ul> </li> </ul> <p>Remarks: PDF</p> <p>Example. Here we seem that the diagonal entries of \\(\\boldsymbol{P}^{-1} \\boldsymbol{B P}\\) is the eigenvalue. There is no need to calcuate.</p> <p>Example Here we see that \\(A\\) is lower triangular. Hence the eigenvalue are 1,2,2</p> <p>Full Working Example We see that to show \\(A\\) is not diagonizable, we start with \\(\\lambda=2\\) for faster calculation.</p> <p>Theorem: Let \\(\\boldsymbol{A}\\) be a square matrix of order \\(n\\).</p> <ul> <li>If \\(\\boldsymbol{A}\\) has \\(n\\) distinct eigenvalues,</li> <li>then \\(\\boldsymbol{A}\\) is diagonalizable.</li> </ul> <p>Proof</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/05%20Diagonalization/#application","title":"Application","text":"<p>PDF</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/05%20Diagonalization/#orthogonal-diagonalization","title":"Orthogonal Diagonalization","text":"<p>PDF</p> <p>Definition. A square matrix \\(A\\) is called orthogonally diagonalizable if it can be diagonalized by an orthogonal matrix. That is,</p> <ul> <li>there exists an orthogonal matrix \\(\\boldsymbol{P}\\) such that</li> <li>\\(\\boldsymbol{P}^{\\mathrm{T}} \\boldsymbol{A P}\\left(=\\boldsymbol{P}^{-1} \\boldsymbol{A P}\\right)\\) is a diagonal matrix.</li> </ul> <p>\\(\\boldsymbol{P}\\) is said to orthogonally diagonalize \\(\\boldsymbol{A}\\). This makes it easy to find \\(P^{-1}\\) which is \\(P^T\\) PDF</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/05%20Diagonalization/#classification","title":"Classification","text":"<p>Theorem. A square matrix is orthogonally diagonalizable \\(\\Leftrightarrow\\) it is a symmetric matrix.</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/05%20Diagonalization/#algorithm","title":"Algorithm","text":"<p>Let \\(\\boldsymbol{A}\\) be a symmetric matrix of order \\(n\\).</p> <ol> <li>Find all distinct eigenvalues \\(\\lambda_1, \\lambda_2, \\ldots, \\lambda_k\\).</li> <li>For each eigenvalue \\(\\lambda_i\\), find an orthonormal basis for the eigenspace \\(E_{\\lambda_i}\\).    (i) Find a basis \\(S_{\\lambda_i}\\) for \\(E_{\\lambda_i}\\).    (ii) Use Gram-Schmidt process to transfer \\(S_{\\lambda_i}\\) to an orthonormal basis \\(T_{\\lambda_i}\\) for \\(E_{\\lambda_i}\\).</li> <li>Let \\(T=T_{\\lambda_1} \\cup T_{\\lambda_2} \\cup \\cdots \\cup T_{\\lambda_k}\\),    \u0966 \\(T=\\left\\{\\boldsymbol{v}_1, \\ldots, \\boldsymbol{v}_n\\right\\}\\) is an orthonormal basis for \\(\\mathbb{R}^n\\).    \\(\\boldsymbol{P}=\\left(\\begin{array}{lll}\\boldsymbol{v}_1 &amp; \\cdots &amp; \\boldsymbol{v}_n\\end{array}\\right)\\) orthogonally diagonalizes \\(\\boldsymbol{A}\\).</li> </ol> <p>If A is symmetric, the eigenvectors are orthogonal. So just normalized to get orthonormal vectors.</p> <p>PDF Example Example 2</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/05%20Diagonalization/#quadratic-forms-and-conic-sections","title":"Quadratic Forms and Conic Sections","text":"<p>PDF</p> <p>\\(Q(x, y)=2 x^2+3 y^2\\) is a quadratic form in \\(x\\) and \\(y\\).</p> <ul> <li>Let \\(\\boldsymbol{x}=\\left(\\begin{array}{l}x \\\\ y\\end{array}\\right)\\) and \\(\\boldsymbol{A}=\\left(\\begin{array}{ll}2 &amp; 0 \\\\ 0 &amp; 3\\end{array}\\right)\\).</li> <li>Then \\(Q(x, y)=\\boldsymbol{x}^{\\mathrm{T}} \\boldsymbol{A} \\boldsymbol{x}\\).</li> </ul> <p>\\(Q(x, y)=x^2+y^2-x y\\) is a quadratic form in \\(x\\) and \\(y\\).</p> <ul> <li>Let \\(\\boldsymbol{x}=\\left(\\begin{array}{l}x \\\\ y\\end{array}\\right)\\) and \\(\\boldsymbol{A}=\\left(\\begin{array}{cc}1 &amp; -\\frac{1}{2} \\\\ -\\frac{1}{2} &amp; 1\\end{array}\\right)\\).</li> <li>Then \\(Q(x, y)=\\boldsymbol{x}^{\\mathrm{T}} \\boldsymbol{A} \\boldsymbol{x}\\).</li> </ul> <p>PDF</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/05%20Diagonalization/#simplification","title":"Simplification","text":"<p>PDF Example</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/05%20Diagonalization/#quadratic-equation","title":"Quadratic Equation","text":"<p>PDF</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/05%20Diagonalization/#classification-of-conics","title":"Classification of Conics","text":"<p>PDF</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/05%20Diagonalization/#standard-forms","title":"Standard Forms","text":"<p>PDF</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/05%20Diagonalization/#classification_1","title":"Classification","text":"<p>PDF</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/05%20Diagonalization/#examples","title":"Examples","text":"<p>PDF</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/06%20Linear%20Transformations/","title":"Linear Transformations","text":""},{"location":"Year%201%20Semester%202/MA2001/Notes/06%20Linear%20Transformations/#linear-transformations-from-mathbbrn-text-to-mathbbrm","title":"Linear Transformations from \\(\\mathbb{R}^n \\text{ to } \\mathbb{R}^m\\)","text":"<p>Definition: PDF. Example</p> <p>Key points:</p> <ul> <li>Linear transformation</li> <li>Linear operator</li> <li>Standard matrix (unique)</li> <li>Identity transformation</li> <li>Identity operator</li> <li>Zero transformation</li> </ul> <p>Example</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/06%20Linear%20Transformations/#linearity","title":"Linearity","text":"<p>To show that a mapping \\(T\\) is not a linear transformation. Example</p> <ul> <li>Show that \\(T(0) \\neq 0\\); or</li> <li>Find \\(v \\in \\mathbb{R}^n, c \\in \\mathbb{R}\\) such that \\(T(c v) \\neq c T(v)\\); or</li> <li>Find \\(\\boldsymbol{u}, \\boldsymbol{v} \\in \\mathbb{R}^n\\) such that \\(T(\\boldsymbol{u}+\\boldsymbol{v}) \\neq T(\\boldsymbol{u})+T(\\boldsymbol{v})\\).</li> </ul> <p>PDF </p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/06%20Linear%20Transformations/#representation","title":"Representation","text":"<p>PDF</p> <p>$$ T\\left(\\left(\\begin{array}{l} 1 \\ 0 \\end{array}\\right)\\right)=\\left(\\begin{array}{l} 1 \\ 2 \\ 3 \\end{array}\\right), T\\left(\\left(\\begin{array}{l} 0 \\ 1 \\end{array}\\right)\\right)=\\left(\\begin{array}{l} 4 \\ 5 \\ 6 \\end{array}\\right) $$ The standard matrix for \\(T\\) is \\(\\left(\\begin{array}{ll}1 &amp; 4 \\\\ 2 &amp; 5 \\\\ 3 &amp; 6\\end{array}\\right)\\).</p> <p>PDF</p> <p>General Definition. Let \\(V\\) and \\(W\\) be vector spaces.</p> <ul> <li>A mapping \\(T: V \\rightarrow W\\) is a linear transformation if $$ T(c u+d v)=c T(u)+d T(v) $$</li> <li>for all \\(\\boldsymbol{u}, \\boldsymbol{v} \\in \\mathbb{R}^n\\) and \\(c, d \\in \\mathbb{R}\\).</li> </ul> <p>Obtaining the standard matrix using v. Example. This is a long method. It can be done in a simpler method (Changes of Bases).</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/06%20Linear%20Transformations/#change-of-bases","title":"Change of Bases","text":"<p>PDF</p> <p>Use of Diagonalization: PDF</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/06%20Linear%20Transformations/#composition","title":"Composition","text":"<p>PDF</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/06%20Linear%20Transformations/#ranges-and-kernels","title":"Ranges and Kernels","text":""},{"location":"Year%201%20Semester%202/MA2001/Notes/06%20Linear%20Transformations/#range-of-linear-transformation","title":"Range of Linear Transformation","text":"<p>PDF Let \\(T: \\mathbb{R}^n \\rightarrow \\mathbb{R}^m\\) be a linear transformation. The range of \\(T\\) is the set of all images of \\(T\\) :</p> <ul> <li>\\(\\mathrm{R}(T)=\\left\\{T(v) \\mid v \\in \\mathbb{R}^n\\right\\} \\subseteq \\mathbb{R}^m\\)</li> </ul> <p>How to determine the rage of \\(T\\)? PDF</p> <ul> <li>The rage is given by \\(\\mathrm{R}(T)=\\operatorname{span}\\left\\{T\\left(\\boldsymbol{v}_1\\right), \\ldots, T\\left(\\boldsymbol{v}_n\\right)\\right\\}\\)   where \\(\\left\\{\\boldsymbol{v}_1, \\ldots, \\boldsymbol{v}_n\\right\\}\\) is any basis for \\(\\mathbb{R}^n\\).</li> <li>In particular. \\(R(T)\\) is a subspace of \\(\\mathbb{R}^m\\).</li> <li>\\(R(T)=\\) column space of \\(A\\) (standard matrix)</li> </ul> <p>Dimension of \\(R(T)\\): PDF</p> <ul> <li>\\(\\operatorname{rank}(T)=\\operatorname{dim} \\mathrm{R}(T)\\)</li> </ul> <p>Complex Examples</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/06%20Linear%20Transformations/#kernel-of-linear-transformation","title":"Kernel of Linear Transformation","text":"<ul> <li>Let \\(T: \\mathbb{R}^n \\rightarrow \\mathbb{R}^m\\) be a linear transformation.</li> <li>The kernel of \\(T\\) is the set of all vectors in \\(\\mathbb{R}^n\\) whose image is the zero vector in \\(\\mathbb{R}^m\\).</li> <li>\\(\\operatorname{Ker}(T)=\\left\\{\\boldsymbol{v} \\in \\mathbb{R}^n \\mid T(v)=\\boldsymbol{v}\\right\\} \\subseteq \\mathbb{R}^n\\)</li> <li>Recall that \\(T(0)=0\\).<ul> <li>\\(\\operatorname{Ker}(T)\\) contains the zero vector in \\(\\mathbb{R}^n\\).</li> </ul> </li> <li>PDF</li> </ul> <p>Theorem: Let \\(T: \\mathbb{R}^n \\rightarrow \\mathbb{R}^m\\) be a linear transformation and \\(\\boldsymbol{A}\\) the standard matrix for \\(T\\). \\(\\operatorname{Ker}(T)=\\) nullspace of \\(\\boldsymbol{A}\\). PDF</p> <ul> <li>The nullity of \\(T\\) is defined as the dimension of \\(\\operatorname{Ker}(T)\\). \\(\\operatorname{nullity}(T)=\\operatorname{dim} \\operatorname{Ker}(T)\\) \\(=\\operatorname{nullity}(\\boldsymbol{A})\\).</li> </ul>"},{"location":"Year%201%20Semester%202/MA2001/Notes/06%20Linear%20Transformations/#properties","title":"Properties","text":"<p>We have proved that</p> <ol> <li>\\(\\mathrm{R}(T)=\\) column space of \\(\\boldsymbol{A}\\).<ul> <li>\\(\\operatorname{rank}(T)=\\operatorname{rank}(\\boldsymbol{A})\\).</li> </ul> </li> <li>\\(\\operatorname{Ker}(T)=\\) nullspace of \\(\\boldsymbol{A}\\).<ul> <li>\\(\\operatorname{nullity}(T)=\\operatorname{nullity}(\\boldsymbol{A})\\).</li> </ul> </li> </ol> <p>Recall Dimension Theorem for Matrices. Let \\(T: \\mathbb{R}^n \\rightarrow \\mathbb{R}^m\\) be a linear transformation. Then</p> <ul> <li>\\(\\operatorname{rank}(T)+\\operatorname{nullity}(T)=n\\).</li> </ul>"},{"location":"Year%201%20Semester%202/MA2001/Notes/MA2001%20Midterm%20note/","title":"Chapter 1","text":""},{"location":"Year%201%20Semester%202/MA2001/Notes/MA2001%20Midterm%20note/#consistency","title":"Consistency","text":""},{"location":"Year%201%20Semester%202/MA2001/Notes/MA2001%20Midterm%20note/#no-solution-inconsistent","title":"No Solution (Inconsistent)","text":"<p>There is a row in \\(\\boldsymbol{R}\\) with the form - \\(\\left(\\begin{array}{llll}0 &amp; 0 &amp; \\cdots &amp; 0\\end{array} \\mid \\otimes\\right)\\), where \\(\\otimes\\) is nonzero.</p> <p>Or equivalently, the last column is a pivot column. Note: Such a row must be the last nonzero row of \\(\\boldsymbol{R}\\).</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/MA2001%20Midterm%20note/#one-solution-consistent","title":"One Solution (Consistent)","text":"<ul> <li>The last column is a non-pivot column, and</li> <li>All other columns are pivot columns.</li> </ul>"},{"location":"Year%201%20Semester%202/MA2001/Notes/MA2001%20Midterm%20note/#infinite-solution-consistent","title":"Infinite Solution (Consistent)","text":"<ul> <li>The last column is a non-pivot column, and</li> <li>Some other columns are non-pivot columns.</li> </ul>"},{"location":"Year%201%20Semester%202/MA2001/Notes/MA2001%20Midterm%20note/#matrices","title":"Matrices","text":""},{"location":"Year%201%20Semester%202/MA2001/Notes/MA2001%20Midterm%20note/#properties","title":"Properties","text":""},{"location":"Year%201%20Semester%202/MA2001/Notes/MA2001%20Midterm%20note/#basic","title":"Basic","text":"<ul> <li>Associative Law: \\(\\boldsymbol{A}(\\boldsymbol{B} \\boldsymbol{C})=(\\boldsymbol{A B}) \\boldsymbol{C}\\)</li> <li>Distributive Law: \\(\\boldsymbol{A}\\left(\\boldsymbol{B}_1+\\boldsymbol{B}_2\\right)=\\boldsymbol{A B _ { 1 }}+\\boldsymbol{A B _ { 2 }}\\)</li> <li>\\(c(\\boldsymbol{A} \\boldsymbol{B})=(c \\boldsymbol{A}) \\boldsymbol{B}=\\boldsymbol{A}(c \\boldsymbol{B})\\)</li> <li>\\(\\boldsymbol{A}^m \\boldsymbol{A}^n=\\boldsymbol{A}^{m+n},\\left(\\boldsymbol{A}^m\\right)^n=\\boldsymbol{A}^{m n}\\)</li> </ul>"},{"location":"Year%201%20Semester%202/MA2001/Notes/MA2001%20Midterm%20note/#transpose","title":"Transpose","text":"<ul> <li>\\(\\left(A^{\\mathrm{T}}\\right)^{\\mathrm{T}}=A\\).</li> <li>\\(A\\) is symmetric \\(\\Leftrightarrow A=A^{\\mathrm{T}}\\).</li> <li>Let \\(c\\) be a scalar. Then \\((c \\boldsymbol{A})^{\\mathrm{T}}=c \\boldsymbol{A}^{\\mathrm{T}}\\).</li> <li>Let \\(\\boldsymbol{B}\\) be \\(m \\times n\\). Then \\((\\boldsymbol{A}+\\boldsymbol{B})^{\\mathrm{T}}=\\boldsymbol{A}^{\\mathrm{T}}+\\boldsymbol{B}^{\\mathrm{T}}\\).</li> <li>Let \\(\\boldsymbol{B}\\) be \\(n \\times p\\). Then \\((\\boldsymbol{A} \\boldsymbol{B})^{\\mathrm{T}}=\\boldsymbol{B}^{\\mathrm{T}} \\boldsymbol{A}^{\\mathrm{T}}\\).</li> </ul>"},{"location":"Year%201%20Semester%202/MA2001/Notes/MA2001%20Midterm%20note/#inverse","title":"Inverse","text":"<p>Let \\(\\boldsymbol{A}, \\boldsymbol{B}\\) be invertible matrices of same size.</p> <ul> <li>Let \\(c \\neq 0 . c \\boldsymbol{A}\\) is invertible, and \\((c \\boldsymbol{A})^{-1}=\\frac{1}{c} \\boldsymbol{A}^{-1}\\).</li> <li>\\(\\boldsymbol{A}^{\\mathrm{T}}\\) is invertible, and \\(\\left(\\boldsymbol{A}^{\\mathrm{T}}\\right)^{-1}=\\left(\\boldsymbol{A}^{-1}\\right)^{\\mathrm{T}}\\).</li> <li>\\(\\boldsymbol{A}^{-1}\\) is invertible, and \\(\\left(\\boldsymbol{A}^{-1}\\right)^{-1}=\\boldsymbol{A}\\).</li> <li>\\(A B\\) is invertible, and \\((A B)^{-1}=B^{-1} A^{-1}\\).</li> </ul> <p>Let \\(\\boldsymbol{A}\\) be a square matrix. Then the followings are equivalent:</p> <ol> <li>\\(\\boldsymbol{A}\\) is an invertible matrix.</li> <li>Linear system \\(\\boldsymbol{A} \\boldsymbol{x}=\\boldsymbol{b}\\) has a unique solution.</li> <li>Linear system \\(\\boldsymbol{A} \\boldsymbol{x}=\\mathbf{0}\\) has only the trivial solution.</li> <li>The reduced row-echelon form of \\(\\boldsymbol{A}\\) is \\(\\boldsymbol{I}\\).</li> <li>\\(\\boldsymbol{A}\\) is the product of elementary matrices.</li> </ol>"},{"location":"Year%201%20Semester%202/MA2001/Notes/MA2001%20Midterm%20note/#elementary-matrices","title":"Elementary matrices","text":"<p>Important Note: \\(E_6 \\cdots E_2 E_1 A=I\\) Every elementary matrix is invertible</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/MA2001%20Midterm%20note/#column-operations","title":"Column Operations","text":"<p>\\(\\boldsymbol{I} \\stackrel{k C_i}{\\longrightarrow} \\boldsymbol{E} \\Rightarrow \\boldsymbol{A} \\stackrel{k C_i}{\\longrightarrow} \\boldsymbol{A} \\boldsymbol{E}\\). \\(\\boldsymbol{I} \\stackrel{C_i \\leftrightarrow C_j}{\\longrightarrow} \\boldsymbol{E} \\Rightarrow \\boldsymbol{A} \\stackrel{C_i \\leftrightarrow C_j}{\\longrightarrow} \\boldsymbol{A} \\boldsymbol{E}\\). \\(\\boldsymbol{I} \\stackrel{C_i+k C_j}{\\longrightarrow} \\boldsymbol{E} \\Rightarrow \\boldsymbol{A} \\stackrel{C_i+k C_j}{\\longrightarrow} \\boldsymbol{A E}\\).</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/MA2001%20Midterm%20note/#determinant","title":"Determinant","text":""},{"location":"Year%201%20Semester%202/MA2001/Notes/MA2001%20Midterm%20note/#cofactor-expansion","title":"Cofactor Expansion","text":"<p>Theorem. Let \\(\\boldsymbol{A}\\) be a square matrix of order \\(n\\).</p> <ul> <li>Let \\(A_{i j}\\) denote the \\((i, j)\\)-cofactor of \\(\\boldsymbol{A}\\).</li> </ul> <p>Then for any \\(i\\) and \\(j\\),</p> <ul> <li>\\(\\operatorname{det}(\\boldsymbol{A})=a_{i 1} A_{i 1}+a_{i 2} A_{i 2}+\\cdots+a_{i n} A_{i n}\\).</li> <li>\\(\\operatorname{det}(\\boldsymbol{A})=a_{1 j} A_{1 j}+a_{2 j} A_{2 j}+\\cdots+a_{n j} A_{n j}\\)</li> </ul> <p>In evaluating the determinant using cofactor expansion, expand along the row or column with the most zeros. (for ease of calculation)</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/MA2001%20Midterm%20note/#finding-determinant","title":"Finding Determinant","text":"<p>Find \\(\\operatorname{det}(\\boldsymbol{A})\\) if \\(\\boldsymbol{A}\\) is a square matrix of order \\(n\\).</p> <ul> <li>If \\(\\boldsymbol{A}\\) has a zero row/column, then \\(\\operatorname{det}(\\boldsymbol{A})=0\\). (This also applies to same rows)</li> <li>If \\(\\boldsymbol{A}\\) is triangular, \\(\\operatorname{det}(\\boldsymbol{A})=a_{11} \\cdots a_{n n}\\).</li> <li>Suppose that \\(\\boldsymbol{A}\\) is not triangular.<ul> <li>If \\(n=2\\), use formula \\(\\operatorname{det}(\\boldsymbol{A})=a_{11} a_{22}-a_{12} a_{21}\\). </li> <li>If a row/coln has many 0 , use cofactor expansion. </li> <li>Otherwise, use ele. row operations to get REF:<ul> <li>\\(\\operatorname{det}(\\boldsymbol{E} \\boldsymbol{A})=\\operatorname{det}(\\boldsymbol{E}) \\operatorname{det}(\\boldsymbol{A})\\)</li> </ul> </li> </ul> </li> </ul> <p>Note the following formulas:</p> <p>\\(\\begin{aligned} &amp; \\operatorname{det}(\\boldsymbol{A})=\\operatorname{det}\\left(\\boldsymbol{A}^{\\mathrm{T}}\\right) \\\\ &amp; \\operatorname{det}(\\boldsymbol{A} \\boldsymbol{B})=\\operatorname{det}(\\boldsymbol{A}) \\operatorname{det}(\\boldsymbol{B}) \\\\ &amp; \\operatorname{det}(c \\boldsymbol{A})=c^n \\operatorname{det}(\\boldsymbol{A}), \\text { where } \\boldsymbol{A} \\text { is } n \\times n \\\\ &amp; \\operatorname{det}\\left(\\boldsymbol{A}^{-1}\\right)=\\operatorname{det}(\\boldsymbol{A})^{-1} \\text { if } \\boldsymbol{A} \\text { is invertible. }\\end{aligned}\\) Suppose a square matrix \\(\\boldsymbol{A}\\) has a zero row. Then \\(\\operatorname{det}(\\boldsymbol{A})=0\\).</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/MA2001%20Midterm%20note/#properties_1","title":"Properties","text":"<p>If \\(\\boldsymbol{A} \\stackrel{c R_i}{\\longrightarrow} \\boldsymbol{B}\\), then \\(\\operatorname{det}(\\boldsymbol{B})=c \\operatorname{det}(\\boldsymbol{A})\\). If \\(\\boldsymbol{A} \\stackrel{R_i \\leftrightarrow R_j}{\\longrightarrow} \\boldsymbol{B}\\), then \\(\\operatorname{det}(\\boldsymbol{B})=-\\operatorname{det}(\\boldsymbol{A})\\). If \\(\\boldsymbol{A} \\stackrel{R_i+c R_j}{\\longrightarrow} \\boldsymbol{B}\\), then \\(\\operatorname{det}(\\boldsymbol{B})=\\operatorname{det}(\\boldsymbol{A})\\).</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/MA2001%20Midterm%20note/#adjoint-matrix","title":"Adjoint Matrix","text":""},{"location":"Year%201%20Semester%202/MA2001/Notes/MA2001%20Midterm%20note/#cramers-rule","title":"Cramer's Rule","text":"<p>Note 60 here is the determinant.</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/MA2001%20Midterm%20note/#vector-spaces","title":"Vector Spaces","text":""},{"location":"Year%201%20Semester%202/MA2001/Notes/MA2001%20Midterm%20note/#implicit-explicit-forms","title":"Implicit &amp; Explicit Forms","text":""},{"location":"Year%201%20Semester%202/MA2001/Notes/MA2001%20Midterm%20note/#implicit-form-example","title":"Implicit form example","text":"<p>\\(V=\\{(t, 2 t, 3 t-1) \\mid t \\in \\mathbb{R}\\}\\)</p> <p>Let \\(x = t\\), \\(y=2t\\), \\(z=3t-1\\).</p> \\[\\left(\\begin{array}{c|c}1 &amp; x \\\\ 1 &amp; \\frac{y}{2} \\\\ 1 &amp; \\frac{{z+1}}{3} \\end{array}\\right) \\underset{\\text { elimination }}{\\stackrel{\\text { Gaussian }}{\\longrightarrow}}\\left(\\begin{array}{c|c}1 &amp; x \\\\ 0 &amp; \\frac{y}{2}-x \\\\ 0 &amp; \\frac{{z+1}}{3}-x \\end{array}\\right)\\] <p>The system is consistent. Therefore \\(\\frac{y}{2}-x=0\\), \\(\\frac{{z+1}}{3}-x=0\\)</p> <p>Implicit form: \\(\\{(x, y, z) \\mid y-2x=0\\text{ } \\&amp;\\text{ } z-3x=-1\\}\\)</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/MA2001%20Midterm%20note/#explicit-form-example","title":"Explicit form example","text":"<p>\\(\\left\\{\\begin{array}{l}x+y+z=0 \\\\ x-y+2 z=1\\end{array}\\right.\\)</p> <p>\\(\\left(\\begin{array}{ccc|c}1 &amp; 1 &amp; 1 &amp; 0 \\\\ 1 &amp; -1 &amp; 2 &amp; 1\\end{array}\\right) \\stackrel{R_2+(-1) R_1}{\\longrightarrow}\\left(\\begin{array}{ccc|c}1 &amp; 1 &amp; 1 &amp; 0 \\\\ 0 &amp; -2 &amp; 1 &amp; 1\\end{array}\\right)\\)</p> <p>\\(x=\\frac{1}{2}-\\frac{3}{2} t, y=-\\frac{1}{2}+\\frac{1}{2} t, z=t\\), where \\(t \\in \\mathbb{R}\\).</p> <p>An explicit form of the solution set is</p> <ul> <li>\\(\\left\\{\\left(\\frac{1}{2}-\\frac{3}{2} t,-\\frac{1}{2}+\\frac{1}{2} t, t\\right) \\mid t \\in \\mathbb{R}\\right\\}\\).</li> </ul>"},{"location":"Year%201%20Semester%202/MA2001/Notes/MA2001%20Midterm%20note/#criterion-for-operatornamespansmathbbrn","title":"Criterion for \\(\\operatorname{span}(S)=\\mathbb{R}^n\\)","text":"<p>Let \\(S=\\left\\{\\boldsymbol{v}_1, \\boldsymbol{v}_2, \\ldots, \\boldsymbol{v}_k\\right\\} \\subseteq \\mathbb{R}^n\\).</p> <ol> <li>View each \\(\\boldsymbol{v}_j\\) as a column vector.</li> <li>Let \\(\\boldsymbol{A}=\\left(\\begin{array}{llll}\\boldsymbol{v}_1 &amp; \\boldsymbol{v}_2 &amp; \\cdots &amp; \\boldsymbol{v}_k\\end{array}\\right)\\).</li> <li>Find a row-echelon form \\(\\boldsymbol{R}\\) of \\(\\boldsymbol{A}\\).<ul> <li>If \\(\\boldsymbol{R}\\) has a zero row, then \\(\\operatorname{span}(S) \\neq \\mathbb{R}^n\\).</li> <li>If \\(\\boldsymbol{R}\\) has no zero row, then \\(\\operatorname{span}(S)=\\mathbb{R}^n\\).</li> </ul> </li> </ol> <p>Example. $$ \\begin{aligned} &amp; \\left(\\begin{array}{lll} 1 &amp; 1 &amp; 0 \\ 0 &amp; 1 &amp; 1 \\ 1 &amp; 0 &amp; 1 \\end{array}\\right) \\underset{\\text { Elimination }}{\\stackrel{\\text { Gaussian }}{\\longrightarrow}}\\left(\\begin{array}{lll} 1 &amp; 1 &amp; 0 \\ 0 &amp; 1 &amp; 1 \\ 0 &amp; 0 &amp; 2 \\end{array}\\right) . \\ &amp; \\therefore \\operatorname{span}{(1,0,1),(1,1,0),(0,1,1)}=\\mathbb{R}^3 . \\end{aligned} $$</p> <p>Also if \\(k&lt;n\\), then \\(\\operatorname{span}(S) \\neq \\mathbb{R}^n\\).</p>"},{"location":"Year%201%20Semester%202/MA2001/Notes/MA2001%20Midterm%20note/#properties-of-linear-spans","title":"Properties of Linear Spans","text":"<ul> <li>Since \\(\\mathbf{0} \\in \\operatorname{span}(S), \\operatorname{span}(S) \\neq \\varnothing\\).</li> <li>\\(v \\in \\operatorname{span}(S)\\) and \\(c \\in \\mathbb{R} \\Rightarrow c \\boldsymbol{v} \\in \\operatorname{span}(S)\\).<ul> <li>\\(\\operatorname{span}(S)\\) is closed under scalar multiplication.</li> </ul> </li> <li>\\(\\boldsymbol{u} \\in \\operatorname{span}(S)\\) and \\(\\boldsymbol{v} \\in \\operatorname{span}(S) \\Rightarrow \\boldsymbol{u}+\\boldsymbol{v} \\in \\operatorname{span}(S)\\).<ul> <li>\\(\\operatorname{span}(S)\\) is closed under addition.</li> </ul> </li> </ul>"},{"location":"Year%201%20Semester%202/MA2001/Notes/MA2001%20Midterm%20note/#example","title":"Example","text":""},{"location":"Year%201%20Semester%202/MA2001/Notes/MA2001%20Midterm%20note/#subspaces","title":"Subspaces","text":"<p>Recall that a subspace \\(V\\) is of the form \\(\\operatorname{span}(S)\\). Then - \\(\\mathbf{0} \\in V\\), - \\(c \\in \\mathbb{R} \\&amp; \\boldsymbol{v} \\in V \\Rightarrow c \\boldsymbol{v} \\in V\\), - \\(\\boldsymbol{u} \\in V \\&amp; \\boldsymbol{v} \\in V \\Rightarrow \\boldsymbol{u}+\\boldsymbol{v} \\in V\\). If any of the above fails, then \\(V\\) is not a subspace (of \\(\\mathbb{R}^n\\) ).</p>"}]}